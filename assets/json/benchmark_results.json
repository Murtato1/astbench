[
    {
        "notebook": {
            "assignment": "orig_5_colloquial/01_EmLineGalaxies_SpectraStack_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/EmLineGalaxies/01_EmLineGalaxies_SpectraStack.ipynb",
            "prefix": "emlinegalaxies_0"
        },
        "model": {
            "name": "gpt-4o",
            "model": "gpt-4o",
            "library": "OA"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "notebook_id = \"SDSS_Spectra_Stacking_001\"\nauthors = {\n    \"Alice Smith\": \"alice.smith@example.com\",\n    \"Bob Johnson\": \"bob.johnson@example.com\"\n}\nversion_date = \"20231005\"\ndatasets = [\"SDSS Data Release 12\", \"SDSS Data Release 16\"]\nkeywords = [\"SDSS\", \"Spectra\", \"Stacking\", \"SPARCL\", \"Astronomy\"]",
                "true_code": "__nbid__ = '0011'\n__author__ = 'Ragadeepika Pucha <rpucha@arizona.edu>, Stephanie Juneau <stephanie.juneau@noirlab.edu>'\n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['sdss_dr12', 'sdss_dr16']\n__keywords__ = ['sdss spectra', 'spectra stacking', 'sparcl']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 11,
                "codebleu": {
                    "codebleu": 0.3417176217294936,
                    "ngram_match_score": 0.008447063994683927,
                    "weighted_ngram_match_score": 0.010438074937942448,
                    "syntax_match_score": 0.8095238095238095,
                    "dataflow_match_score": 0.5384615384615384
                },
                "codebertscore": {
                    "precision": 0.7649409770965576,
                    "recall": 0.7369223833084106,
                    "F1": 0.750670313835144,
                    "F3": 0.7396314740180969
                },
                "codebertscore_rescaled": {
                    "precision": 0.5298819541931152,
                    "recall": 0.4738447666168213,
                    "F1": 0.5013406276702881,
                    "F3": 0.47926294803619385
                }
            },
            {
                "ind": 10,
                "gen_code": "# Credentials (provide when needed)\n# username = input(\"Enter your Data Lab username: \")\n# password = getpass(\"Enter your Data Lab password: \")\n\n# Optional login function (activate when needed)\n# def login(username, password):\n#     try:\n#         token = ac.login(username, password)\n#         print(\"Login successful.\")\n#     except Exception as e:\n#         print(f\"Login failed: {e}\")\n\n# Login when necessary\n# login(username, password)",
                "true_code": "#token = ac.login(input(\"Enter user name: (+ENTER) \"),getpass(\"Enter password: (+ENTER) \"))\n#ac.whoAmI()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.5065081346104865,
                    "ngram_match_score": 0.003615604940023951,
                    "weighted_ngram_match_score": 0.022416933501922302,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.7118173837661743,
                    "recall": 0.7785618901252747,
                    "F1": 0.7436951398849487,
                    "F3": 0.771329402923584
                },
                "codebertscore_rescaled": {
                    "precision": 0.42363476753234863,
                    "recall": 0.5571237802505493,
                    "F1": 0.48739027976989746,
                    "F3": 0.542658805847168
                }
            },
            {
                "ind": 12,
                "gen_code": "# Set the font size and other plotting parameters for clarity\nmatplotlib.rc('font', size=14)\nmatplotlib.rc('axes', linewidth=1.2)\nmatplotlib.rc('xtick', direction='in', top=True)\nmatplotlib.rc('ytick', direction='in', right=True)\n\n# For more detailed matplotlib customization you can uncomment and modify below \n# matplotlib.rc('xtick.major', size=8, width=1.2)\n# matplotlib.rc('ytick.major', size=8, width=1.2)\n# matplotlib.rc('xtick.minor', size=4, width=1.1)\n# matplotlib.rc('ytick.minor', size=4, width=1.1)\n",
                "true_code": "## Setting up plots\n\n# Font size\nfont = {'size':22}\nmatplotlib.rc('font', **font)\n\n# Axes width\nwidth = {'linewidth':3.0}\nmatplotlib.rc('axes', **width)\n\n# x- and y- ticks\nticks = {'major.size':6.0, 'minor.size':4.0, 'major.width':3.0, 'minor.width':1.5, 'direction':'in',\\\n        'minor.visible':True}\nmatplotlib.rc('xtick', **ticks)\nmatplotlib.rc('ytick', **ticks)\n\n# Include top and right ticks \nplt.rcParams['xtick.top'] = True\nplt.rcParams['ytick.right'] = True",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.10888358150530453,
                    "ngram_match_score": 0.006969827983266752,
                    "weighted_ngram_match_score": 0.007379126032907228,
                    "syntax_match_score": 0.3442622950819672,
                    "dataflow_match_score": 0.07692307692307693
                },
                "codebertscore": {
                    "precision": 0.8564114570617676,
                    "recall": 0.8290866613388062,
                    "F1": 0.8425275683403015,
                    "F3": 0.8317404389381409
                },
                "codebertscore_rescaled": {
                    "precision": 0.7128229141235352,
                    "recall": 0.6581733226776123,
                    "F1": 0.685055136680603,
                    "F3": 0.6634808778762817
                }
            },
            {
                "ind": 14,
                "gen_code": "# Initialize SPARCL Client\nsparcl = SparclClient()",
                "true_code": "## SPARCL Client\nclient = SparclClient()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 78,
                "codebleu": {
                    "codebleu": 0.5552205928646161,
                    "ngram_match_score": 0.09878765474230743,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9027405381202698,
                    "recall": 0.9586640000343323,
                    "F1": 0.9298622012138367,
                    "F3": 0.9527618288993835
                },
                "codebertscore_rescaled": {
                    "precision": 0.8054810762405396,
                    "recall": 0.9173280000686646,
                    "F1": 0.8597244024276733,
                    "F3": 0.9055236577987671
                }
            },
            {
                "ind": 16,
                "gen_code": "# Define column list and selection criteria for accessing the catalog\ncolumns = [\n    'specobjid', 'plate', 'mjd', 'fiberid', # Basic identifiers\n    'oii_3726_flux', 'oii_3726_flux_err',   # [O II] \u03bb3726\n    'oiii_4959_flux', 'oiii_4959_flux_err', # [O III] \u03bb4959\n    'oiii_5007_flux', 'oiii_5007_flux_err', # [O III] \u03bb5007\n    'nii_6548_flux', 'nii_6548_flux_err',   # [N II] \u03bb6548\n    'nii_6583_flux', 'nii_6583_flux_err',   # [N II] \u03bb6583\n    'sii_6717_flux', 'sii_6717_flux_err',   # [S II] \u03bb6717\n    'sii_6731_flux', 'sii_6731_flux_err',   # [S II] \u03bb6731\n    'h_alpha_flux', 'h_alpha_flux_err',     # H\u03b1\n    'h_beta_flux', 'h_beta_flux_err',       # H\u03b2\n    'nii_6583_flux_sn',                     # Signal-to-noise ratio for [N II] \u03bb6583\n    'h_alpha_flux_sn'                       # Signal-to-noise ratio for H\u03b1\n]\n\nconditions = [\n    \"oiii_5007_flux_sn > 3\",   # S/N > 3 for [O III] \u03bb5007\n    \"nii_6583_flux_sn > 3\",    # S/N > 3 for [N II] \u03bb6583\n    \"h_alpha_flux_sn > 3\",     # S/N > 3 for H\u03b1\n    \"h_beta_flux_sn > 3\"       # S/N > 3 for H\u03b2\n]\n\ncolumns_str = ', '.join(columns)\nconditions_str = ' AND '.join(conditions)\n\n# The query string is prepared but not executed here. It will be used later to get data from the catalog.\nquery_string = f\"SELECT {columns_str} FROM emission_lines_catalog WHERE {conditions_str}\"",
                "true_code": "# List of emission lines we are interested in - \nemission_lines = ('Hb_4861', 'OIII_5006', 'Ha_6562', 'NII_6583')\n\n# Creating a list of columns for all the emission lines for Flux, Flux_Err and Aon for each - \nselected_columns_sdss = ', \\n'.join(['E.Flux_{0}, E.Flux_{0}_Err, E.Aon_{0}'.format(e) for e in emission_lines])\n\n# Conditions - \n# Conditions on flux errors (flux errors > 0 and flux errors != Infinity)\nerr_cond_sdss = ' AND \\n'.join(['(E.Flux_{0}_Err > 0) AND (E.Flux_{0}_Err != \\'Infinity\\')'.format(e) for e in emission_lines])\n# Conditions on Signal to Noise ratio of all the emission lines\nsn_cond_sdss = ' AND \\n'.join(['(E.Flux_{0}/E.Flux_{0}_Err > 5)'.format(e) for e in emission_lines])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 7,
                "codebleu": {
                    "codebleu": 0.1697511917266693,
                    "ngram_match_score": 0.010225048466577076,
                    "weighted_ngram_match_score": 0.018636040279180636,
                    "syntax_match_score": 0.2708333333333333,
                    "dataflow_match_score": 0.3793103448275862
                },
                "codebertscore": {
                    "precision": 0.7234798669815063,
                    "recall": 0.7299575805664062,
                    "F1": 0.7267042994499207,
                    "F3": 0.7293046116828918
                },
                "codebertscore_rescaled": {
                    "precision": 0.4469597339630127,
                    "recall": 0.4599151611328125,
                    "F1": 0.4534085988998413,
                    "F3": 0.4586092233657837
                }
            },
            {
                "ind": 18,
                "gen_code": "import pandas as pd\n\n# Query to combine emission line data with primary spectra info from specobj table\nquery = f\"\"\"\nSELECT P.specobjid, \n       S.z, \n       {selected_columns_sdss}\nFROM lasr.aaaa_dr16_specobj AS S\nJOIN vac.emissionlinesport AS E\nON S.specobjid = E.specobjid\nJOIN vac.portsmouth_stellarkinematics_starforming AS P\nON E.specobjid = P.specobjid\nWHERE S.isprimary = 1\nAND S.class = 'GALAXY'\nAND S.z BETWEEN 0.02 AND 0.2\nAND {err_cond_sdss}\nAND {sn_cond_sdss}\n\"\"\"\n\n# Execute the query and fetch the result as a DataFrame\nresult = qc.query(sql=query)\ndata = pd.DataFrame(result)\nprint(data.head())",
                "true_code": "# Write a query for the emission lines from the SDSS DR12 emissionlinesport catalog\n# Applying the S/N cut of >= 5 for all the four emission lines\n# Also applying the conditions that all the flux errors are >0 and != infinity.\n# Applying condition on redshift - only selecting galaxies with 0.02 <= z <= 0.2\n# We add bpt column - which marks the class of the galaxy based on its position on the BPT Diagram\n# We use sdss_joinid to JOIN with SDSS DR16\n# This is to get the SDSS DR16 specobjid of objects - which is used to access the spectra\n\nquery = \"\"\"\nSELECT \nE.ra as ra_sdss, E.dec as dec_sds, E.z, E.bpt,\nE.mjd, E.plate, E.fiberid,\n%s,\nS.specobjid\nFROM sdss_dr12.emissionlinesport as E\nJOIN sdss_dr16.specobj as S\nON (E.sdss_joinid = S.sdss_joinid) AND (E.mjd = S.mjd)\nWHERE (E.z > 0.02) AND (E.z < 0.2) AND\n%s AND\n%s\n\"\"\" %(selected_columns_sdss, err_cond_sdss, sn_cond_sdss)",
                "error_ind": 18,
                "direct_match": false,
                "fuzzy_match": 12,
                "codebleu": {
                    "codebleu": 0.15225278572396755,
                    "ngram_match_score": 0.003847613619309142,
                    "weighted_ngram_match_score": 0.005163529276561062,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.6
                },
                "codebertscore": {
                    "precision": 0.764538586139679,
                    "recall": 0.7521746754646301,
                    "F1": 0.7583062648773193,
                    "F3": 0.7533929944038391
                },
                "codebertscore_rescaled": {
                    "precision": 0.5290771722793579,
                    "recall": 0.5043493509292603,
                    "F1": 0.5166125297546387,
                    "F3": 0.5067859888076782
                }
            },
            {
                "ind": 20,
                "gen_code": "# Print the constructed query\nprint(query)",
                "true_code": "print(query)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 44,
                "codebleu": {
                    "codebleu": 0.5399363851366646,
                    "ngram_match_score": 0.040824829046386304,
                    "weighted_ngram_match_score": 0.11892071150027214,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.8022806644439697,
                    "recall": 0.909947395324707,
                    "F1": 0.8527289628982544,
                    "F3": 0.897897481918335
                },
                "codebertscore_rescaled": {
                    "precision": 0.6045613288879395,
                    "recall": 0.8198947906494141,
                    "F1": 0.7054579257965088,
                    "F3": 0.7957949638366699
                }
            },
            {
                "ind": 22,
                "gen_code": "## Execute query\nemission_data = qc.query(sql=query, fmt='table')\nemission_data",
                "true_code": "final_table = qc.query(sql=query, fmt = 'table')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 63,
                "codebleu": {
                    "codebleu": 0.5084905954932315,
                    "ngram_match_score": 0.05873949094699214,
                    "weighted_ngram_match_score": 0.08633400213704504,
                    "syntax_match_score": 0.8888888888888888,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8476179838180542,
                    "recall": 0.9395096302032471,
                    "F1": 0.8912013173103333,
                    "F3": 0.9294335246086121
                },
                "codebertscore_rescaled": {
                    "precision": 0.6952359676361084,
                    "recall": 0.8790192604064941,
                    "F1": 0.7824026346206665,
                    "F3": 0.8588670492172241
                }
            },
            {
                "ind": 26,
                "gen_code": "# Function to retrieve SDSS spectra using SPARCL\ndef get_sdss_spectra(specobjid, rest_frame=True):\n    \"\"\"\n    Retrieve SDSS spectra using SPARCL client.\n    \n    Parameters:\n    specobjid : int\n        The unique identifier for the SDSS spectrum.\n    \n    rest_frame : bool, optional\n        If True, returns rest-frame wavelengths, else observed-frame.\n\n    Returns:\n    tuple\n        Wavelength, Flux, Model, and Inverse Variance arrays.\n    \"\"\"\n    response = client.get_spectrum(specobjid)\n    data = response.data()\n    \n    if rest_frame:\n        wavelength = data['wavelength_rest']\n    else:\n        wavelength = data['wavelength']\n    \n    flux = data['flux']\n    model = data['model']\n    ivar = data['ivar']\n    \n    return wavelength, flux, model, ivar\n\n# Function to annotate plots with emission/absorption lines\ndef annotate_lines(ax, lines_wavelengths, lines_labels, y_position=0.95, line_type='emission'):\n    \"\"\"\n    Annotate emission/absorption lines on a plot.\n    \n    Parameters:\n    ax : matplotlib.axes.Axes\n        The axis on which to annotate the lines.\n        \n    lines_wavelengths : array-like\n        The wavelengths of the lines.\n        \n    lines_labels : array-like\n        The labels for the lines.\n        \n    y_position : float, optional\n        Normalized vertical position in the plot to place the labels.\n        \n    line_type : str, optional\n        Type of lines: 'emission' or 'absorption'.\n    \"\"\"\n    for wave, label in zip(lines_wavelengths, lines_labels):\n        ax.axvline(wave, color='r' if line_type == 'emission' else 'b', linestyle='--', lw=1)\n        ax.text(wave, y_position, label, rotation=90, verticalalignment='center', color='r' if line_type == 'emission' else 'b')\n\n# Function to plot spectra\ndef plot_sdss_spectra(wavelength, flux, model, ivar, z=None, xlim=None, plot_lines=False, emission_lines=None, absorption_lines=None):\n    \"\"\"\n    Plot SDSS spectra with optional emission/absorption line overlays.\n    \n    Parameters:\n    wavelength : array-like\n        The spectral wavelengths.\n        \n    flux : array-like\n        The spectral fluxes.\n        \n    model : array-like\n        The model fluxes.\n        \n    ivar : array-like\n        The inverse variance of the fluxes.\n        \n    z : float, optional\n        Redshift value for the spectrum, for potential adjustments.\n        \n    xlim : tuple, optional\n        Limits for the x-axis (wavelength).\n        \n    plot_lines : bool, optional\n        Whether to plot emission/absorption lines.\n        \n    emission_lines : dict, optional\n        Wavelengths and labels for emission lines to be plotted.\n        \n    absorption_lines : dict, optional\n        Wavelengths and labels for absorption lines to be plotted.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(14, 8))\n    ax.plot(wavelength, flux, label='Flux', color='black')\n    ax.plot(wavelength, model, label='Model', color='red', alpha=0.7)\n    ax.set_xlabel('Wavelength [\u00c5]')\n    ax.set_ylabel('Flux')\n    \n    if xlim is not None:\n        ax.set_xlim(xlim)\n        \n    if plot_lines:\n        if emission_lines:\n            annotate_lines(ax, emission_lines['wavelengths'], emission_lines['labels'], line_type='emission')\n        if absorption_lines:\n            annotate_lines(ax, absorption_lines['wavelengths'], absorption_lines['labels'], line_type='absorption')\n    \n    ax.legend()\n    plt.show()\n",
                "true_code": "# Assigning variables for the columns required to plot the spectra -\nz = final_table['z'].data\n\n## We need to convert the numpy array of specobjid into a int list to work with SPARCL\nspecobjid = [int(s) for s in final_table['specobjid'].data]",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 1,
                "codebleu": {
                    "codebleu": 0.248577863447506,
                    "ngram_match_score": 0.002458122652488427,
                    "weighted_ngram_match_score": 0.022156361440565795,
                    "syntax_match_score": 0.3333333333333333,
                    "dataflow_match_score": 0.6363636363636364
                },
                "codebertscore": {
                    "precision": 0.5817378163337708,
                    "recall": 0.7518347501754761,
                    "F1": 0.6559383273124695,
                    "F3": 0.7304759621620178
                },
                "codebertscore_rescaled": {
                    "precision": 0.1634756326675415,
                    "recall": 0.5036695003509521,
                    "F1": 0.31187665462493896,
                    "F3": 0.46095192432403564
                }
            },
            {
                "ind": 28,
                "gen_code": "# Count unique entries\nunique_entries_count = len(specobjid)\nprint(f\"Number of unique entries available for plotting: {unique_entries_count}\")",
                "true_code": "# Print number of objects in table\nN_table = len(final_table)\nprint(N_table)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 33,
                "codebleu": {
                    "codebleu": 0.38508832146056415,
                    "ngram_match_score": 0.017395797375642234,
                    "weighted_ngram_match_score": 0.022957488466614332,
                    "syntax_match_score": 0.75,
                    "dataflow_match_score": 0.75
                },
                "codebertscore": {
                    "precision": 0.7874135971069336,
                    "recall": 0.8263291120529175,
                    "F1": 0.8064021468162537,
                    "F3": 0.8222652673721313
                },
                "codebertscore_rescaled": {
                    "precision": 0.5748271942138672,
                    "recall": 0.652658224105835,
                    "F1": 0.6128042936325073,
                    "F3": 0.6445305347442627
                }
            },
            {
                "ind": 30,
                "gen_code": "# Example function for plotting a sample SDSS spectrum using the plot_sdss_spectra() function\n\n# Choose an index to plot a specific spectrum\nindex_to_plot = 10\n\n# Retrieve specobjid and redshift for the selected index\nspec_id = specobjid[index_to_plot]\nredshift = z[index_to_plot]\n\n# Function to plot the sample spectrum\ndef plot_sample_spectrum(specobjid, z):\n    # Use the client to access SDSS spectrum with the given specobjid\n    spectrum_data = client.search_spectrum(specobjid)\n    \n    # Extract data arrays needed for plotting\n    wavelength = spectrum_data['wavelength']\n    flux = spectrum_data['flux']\n    model = spectrum_data.get('model', None)  # Optional model data if available\n    ivar = spectrum_data.get('ivar', None)  # Optional inverse variance data\n\n    # Plot the spectrum\n    plt.figure(figsize=(14, 8))\n    plt.plot(wavelength, flux, label='Flux', color='b')\n    \n    # Overlay model if available\n    if model is not None:\n        plt.plot(wavelength, model, label='Model', color='r', linestyle='--')\n    \n    # Configure plot labels and limits\n    plt.xlabel('Wavelength (\u00c5)')\n    plt.ylabel('Flux')\n    plt.title(f'SDSS Spectrum for SpecobjID: {specobjid}')\n    plt.legend()\n    plt.show()\n\n# Plot the selected spectrum\nplot_sample_spectrum(spec_id, redshift)",
                "true_code": "# We will first plot with all the default values - \n# Requires specobjid and z\n\nindex = 10     # Change the value between 0 and N_table-1 to plot different spectra in rest-frame \n\n# Getting the wavelength, flux, model and ivar arrays for the given source\nwavelength, flux, model, ivar = get_sdss_spectra(specobjid[index], rest_frame = True)\nplot_sdss_spectra(wavelength, flux, model, ivar, z[index])",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 7,
                "codebleu": {
                    "codebleu": 0.2092650899444825,
                    "ngram_match_score": 0.014530371964797261,
                    "weighted_ngram_match_score": 0.03681570209884708,
                    "syntax_match_score": 0.2857142857142857,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.7114776968955994,
                    "recall": 0.7901046276092529,
                    "F1": 0.7487325668334961,
                    "F3": 0.7814684510231018
                },
                "codebertscore_rescaled": {
                    "precision": 0.42295539379119873,
                    "recall": 0.5802092552185059,
                    "F1": 0.4974651336669922,
                    "F3": 0.5629369020462036
                }
            },
            {
                "ind": 32,
                "gen_code": "# First, we define the function to access the spectra\ndef get_sdss_spectra(specobjid, rest_frame=True):\n    # Query the SPARCL client for the spectra\n    spectra_data = client.fetch(specobjid)\n    \n    # Extract arrays\n    wavelength = spectra_data['wavelength']\n    flux = spectra_data['flux']\n    model = spectra_data['model']\n    ivar = spectra_data['ivar']\n    \n    # Adjust for rest-frame if needed\n    if rest_frame:\n        redshift = spectra_data['redshift']\n        wavelength = wavelength / (1 + redshift)\n    \n    return wavelength, flux, model, ivar\n\n# Function to annotate plots with emission and absorption lines\ndef plot_lines(ax, rest_wavelengths, z=0, line_labels=None, line_color='red', label_emission=True):\n    for i, lam in enumerate(rest_wavelengths):\n        obs_wavelength = lam * (1 + z)\n        ax.axvline(x=obs_wavelength, color=line_color, linestyle='--')\n        if line_labels and label_emission:\n            ax.text(obs_wavelength, 0.9, line_labels[i], rotation=90, verticalalignment='bottom', fontsize=10)\n\n# Comprehensive plotting routine for spectra\ndef plot_sdss_spectra(wavelength, flux, model, ivar, z=0, xlim=None, plot_model=True, line_labels=None,\n                      plot_lines_flag=True, emission_lines=None, absorption_lines=None):\n    \n    fig, ax = plt.subplots(figsize=(12, 6))\n    ax.plot(wavelength, flux, label='Flux', color='black')\n    \n    if plot_model:\n        ax.plot(wavelength, model, label='Model', color='red', linestyle='--')\n    \n    if plot_lines_flag:\n        if emission_lines is not None:\n            plot_lines(ax, emission_lines, z=z, line_labels=line_labels)\n        if absorption_lines is not None:\n            plot_lines(ax, absorption_lines, z=z, line_labels=line_labels, line_color='blue', label_emission=False)\n    \n    ax.set_xlabel('Wavelength (angstroms)')\n    ax.set_ylabel('Flux')\n    \n    if xlim is not None:\n        ax.set_xlim(xlim)\n    \n    ax.legend()\n    plt.show()\n\n# Define a custom configuration for demonstration\ncustom_xlim = (3800, 9200)  # Example wavelength limits\ncustom_emission_lines = [4861.33, 5006.84, 6562.80, 6583.41]  # Example lines: Hb, OIII, Ha, NII\nline_labels = ['H\u03b2', '[OIII]', 'H\u03b1', '[NII]']\n\n# Plot using custom configurations\nplot_sdss_spectra(wavelength, flux, model, ivar, z[index], xlim=custom_xlim, plot_model=True, \n                  emission_lines=custom_emission_lines, line_labels=line_labels)",
                "true_code": "# Changing the default values for the plotting function\n\nindex = 10           # Change the value between 0 and N_table-1 to plot different spectra in rest-frame \n\nplot_sdss_spectra(wavelength, flux, model, ivar, z[index], rest_frame = True, \\\n                      xlim = [4500, 7000], ylim = None, \\\n                      spectra_kwargs = {'color': 'grey', 'alpha': 0.5}, \\\n                      model_kwargs = {'color': 'k', 'linewidth': 2.0},\\\n                      emission_lines = True, absorption_lines = True, \\\n                      em_lines = None,  abs_lines = [])\n\n# The actual spectra from the SDSS is shown in grey and the model is shown in black.\n# You can change it to any color that you want by using the spectra_kwargs and model_kwargs keywords.",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.18828152328744535,
                    "ngram_match_score": 0.027228439654895843,
                    "weighted_ngram_match_score": 0.05923098682821896,
                    "syntax_match_score": 0.3333333333333333,
                    "dataflow_match_score": 0.3333333333333333
                },
                "codebertscore": {
                    "precision": 0.739348292350769,
                    "recall": 0.7845788598060608,
                    "F1": 0.7612923383712769,
                    "F3": 0.7798083424568176
                },
                "codebertscore_rescaled": {
                    "precision": 0.4786965847015381,
                    "recall": 0.5691577196121216,
                    "F1": 0.5225846767425537,
                    "F3": 0.5596166849136353
                }
            },
            {
                "ind": 34,
                "gen_code": "# Calculating logarithmic line ratios for BPT diagram\n# log([NII]/Halpha) and log([OIII]/Hbeta)\nnii_ha_ratio = np.log10(final_table['E.Flux_NII_6583'] / final_table['E.Flux_Ha_6562'])\noiii_hb_ratio = np.log10(final_table['E.Flux_OIII_5006'] / final_table['E.Flux_Hb_4861'])",
                "true_code": "# Computing the logarithm of line ratios for the BPT Diagram - \nNii_Ha = np.log10(final_table['flux_nii_6583']/final_table['flux_ha_6562'])\nOiii_Hb = np.log10(final_table['flux_oiii_5006']/final_table['flux_hb_4861'])",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 38,
                "codebleu": {
                    "codebleu": 0.5308754941011834,
                    "ngram_match_score": 0.05314049749131566,
                    "weighted_ngram_match_score": 0.07036147891341805,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9017031192779541,
                    "recall": 0.9280156493186951,
                    "F1": 0.9146701693534851,
                    "F3": 0.9253154397010803
                },
                "codebertscore_rescaled": {
                    "precision": 0.8034062385559082,
                    "recall": 0.8560312986373901,
                    "F1": 0.8293403387069702,
                    "F3": 0.8506308794021606
                }
            },
            {
                "ind": 36,
                "gen_code": "# BPT classification assignment\nbpt_classification = final_table['bpt'].data\n\n# Creating boolean conditions for each BPT galaxy type\nis_star_forming = (bpt_classification == 'StarForming')\nis_seyfert = (bpt_classification == 'Seyfert')\nis_liner = (bpt_classification == 'LINER')\nis_composite = (bpt_classification == 'Composite')",
                "true_code": "# Assigning a variable for the bpt column\nbpt = final_table['bpt']   # BPT Classification\n\n# Creating labels for the different classes based on BPT Column - \nis_sf = (bpt == 'Star Forming')\nis_sy = (bpt == 'Seyfert')\nis_comp = (bpt == 'Composite')\nis_liner = (bpt == 'LINER')",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 29,
                "codebleu": {
                    "codebleu": 0.26457998677028693,
                    "ngram_match_score": 0.022076705823916454,
                    "weighted_ngram_match_score": 0.022909907923897868,
                    "syntax_match_score": 0.88,
                    "dataflow_match_score": 0.13333333333333333
                },
                "codebertscore": {
                    "precision": 0.8856257796287537,
                    "recall": 0.8857382535934448,
                    "F1": 0.8856820464134216,
                    "F3": 0.8857269883155823
                },
                "codebertscore_rescaled": {
                    "precision": 0.7712515592575073,
                    "recall": 0.7714765071868896,
                    "F1": 0.7713640928268433,
                    "F3": 0.7714539766311646
                }
            },
            {
                "ind": 38,
                "gen_code": "# Compute 2D histogram density for Nii_Ha and Oiii_Hb\nH, xedges, yedges = np.histogram2d(Nii_Ha, Oiii_Hb, bins=100, range=[[-2, 1.5], [-1.5, 1.5]])\n\n# X and Y bins centers\nx_bin_centers = (xedges[:-1] + xedges[1:]) / 2\ny_bin_centers = (yedges[:-1] + yedges[1:]) / 2\n\n# Convert to plot extents\nx_extent = [x_bin_centers.min(), x_bin_centers.max()]\ny_extent = [y_bin_centers.min(), y_bin_centers.max()]",
                "true_code": "# 2-d histogram density of all the galaxies\ndens_all,_,_ = np.histogram2d(Nii_Ha, Oiii_Hb, range=[[-2.0, 0.75],[-1.2, 1.2]], bins=100, density=True)\ndens_all = dens_all.T",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 25,
                "codebleu": {
                    "codebleu": 0.2655841970691074,
                    "ngram_match_score": 0.02417396906483826,
                    "weighted_ngram_match_score": 0.06740258529346294,
                    "syntax_match_score": 0.4444444444444444,
                    "dataflow_match_score": 0.5263157894736842
                },
                "codebertscore": {
                    "precision": 0.7191413044929504,
                    "recall": 0.8363972902297974,
                    "F1": 0.7733498811721802,
                    "F3": 0.8229786157608032
                },
                "codebertscore_rescaled": {
                    "precision": 0.4382826089859009,
                    "recall": 0.6727945804595947,
                    "F1": 0.5466997623443604,
                    "F3": 0.6459572315216064
                }
            },
            {
                "ind": 40,
                "gen_code": "# Initializing plot for BPT Diagram\nplt.figure(figsize=(10, 8))\n\n# Plot the density countours\nplt.contour(dens_all, levels=np.arange(0.05, 0.95, 0.1), extent=[-2.0, 0.75,-1.2, 1.2], linewidths=3, cmap='Greys')\n\n# Plot each class of galaxy using different markers and colors\nplt.scatter(Nii_Ha[is_sf], Oiii_Hb[is_sf], s=10, color='b', label='Star Forming', alpha=0.5)\nplt.scatter(Nii_Ha[is_sy], Oiii_Hb[is_sy], s=10, color='r', label='Seyfert', alpha=0.5)\nplt.scatter(Nii_Ha[is_liner], Oiii_Hb[is_liner], s=10, color='g', label='LINER', alpha=0.5)\nplt.scatter(Nii_Ha[is_comp], Oiii_Hb[is_comp], s=10, color='orange', label='Composite', alpha=0.5)\n\n# Adding labels and limits\nplt.xlabel(r\"[NII] / H$\\alpha$\")\nplt.ylabel(r\"[OIII] / H$\\beta$\")\nplt.xlim(-2.0, 0.75)\nplt.ylim(-1.2, 1.2)\nplt.legend(markerscale=3)\nplt.title('BPT Diagram for Galaxy Classification')\n\nplt.show()",
                "true_code": "# BPT Diagram color-coded based on the class\nplt.figure(figsize = (8,8))\nplt.scatter(Nii_Ha[is_sy], Oiii_Hb[is_sy], color = 'r', s = 1.0)             # Seyferts in red (r)\nplt.scatter(Nii_Ha[is_sf], Oiii_Hb[is_sf], color = 'b', s = 1.0)             # SF in blue (b)\nplt.scatter(Nii_Ha[is_comp], Oiii_Hb[is_comp], color = 'g', s = 1.0)         # Composites in green (g)\nplt.scatter(Nii_Ha[is_liner], Oiii_Hb[is_liner], color = 'purple', s = 1.0)  # LINERs in purple\nplt.contour(dens_all, colors = 'white', extent = (-2.0, 0.75, -1.2, 1.2), levels = [0.0, 0.1, 0.2, 0.3, 0.5, 1.5, 3.0, 6.0])\nplt.xlim([-2, 0.75])\nplt.ylim([-1.2, 1.2])\nplt.text(-1.0, -0.5, 'SF', color = 'blue', fontsize = 18)\nplt.text(0.0, -1.0, 'Composite', color = 'green', fontsize = 18)\nplt.text(0.5, 0.2, 'LINER', color = 'purple', fontsize = 18, rotation = 90)\nplt.text(-0.9, 1.0, 'Seyfert', color = 'r', fontsize = 18)\nplt.xlabel('log ([NII]/H$\\\\alpha$)')\nplt.ylabel('log ([OIII]/H$\\\\beta$)')\nplt.show()",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 18,
                "codebleu": {
                    "codebleu": 0.3519225353022538,
                    "ngram_match_score": 0.006732420730399826,
                    "weighted_ngram_match_score": 0.007775902296797091,
                    "syntax_match_score": 0.575,
                    "dataflow_match_score": 0.8181818181818182
                },
                "codebertscore": {
                    "precision": 0.8537605404853821,
                    "recall": 0.8658850193023682,
                    "F1": 0.8597800731658936,
                    "F3": 0.8646570444107056
                },
                "codebertscore_rescaled": {
                    "precision": 0.7075210809707642,
                    "recall": 0.7317700386047363,
                    "F1": 0.7195601463317871,
                    "F3": 0.7293140888214111
                }
            },
            {
                "ind": 45,
                "gen_code": "def align_and_stack_spectra(specobjid_list, z_list, min_wavelength=3700, max_wavelength=9200, step=1):\n    \"\"\"\n    Function to align and stack spectra for a given list of SDSS objects.\n    \n    Parameters:\n    specobjid_list : list\n        A list of specobjid numbers for the SDSS objects to stack.\n    z_list : list\n        A list of redshifts corresponding to each specobjid.\n    min_wavelength : float\n        Minimum rest-frame wavelength to include in stack.\n    max_wavelength : float\n        Maximum rest-frame wavelength to include in stack.\n    step : float\n        Wavelength bin width for resampling before stacking.\n\n    Returns:\n    wavelength_stacked : numpy array\n        Wavelength array for the stack.\n    flux_stacked : numpy array\n        Flux array of the stacked spectra.\n    model_stacked : numpy array\n        Model array of the stacked spectra.\n    \"\"\"\n    # Define wavelength range for stacking\n    wavelength_stacked = np.arange(min_wavelength, max_wavelength, step)\n    \n    # Arrays to accumulate stacked flux and variance\n    sum_flux = np.zeros_like(wavelength_stacked)\n    sum_weights = np.zeros_like(wavelength_stacked)\n    \n    for i, specobjid in enumerate(specobjid_list):\n        try:\n            # Get the spectrum from SPARCL\n            wavelength, flux, model, ivar = get_sdss_spectra(specobjid)\n\n            # Convert observed wavelength to rest-frame using redshift\n            wavelength_rest = wavelength / (1 + z_list[i])\n\n            # Re-sample the spectra to match the stacking wavelength grid\n            flux_resampled = np.interp(wavelength_stacked, wavelength_rest, flux, left=np.nan, right=np.nan)\n            ivar_resampled = np.interp(wavelength_stacked, wavelength_rest, ivar, left=np.nan, right=np.nan)\n            \n            # Calculate weights for stacking using inverse variance\n            weights = ivar_resampled\n            \n            # Accumulate weighted flux and weights\n            mask = np.isfinite(flux_resampled) & np.isfinite(weights) & (weights > 0)\n            sum_flux[mask] += flux_resampled[mask] * weights[mask]\n            sum_weights[mask] += weights[mask]\n            \n        except Exception as e:\n            print(f\"Failed to retrieve spectrum for specobjid {specobjid}: {e}\")\n            continue\n    \n    # Finalize stacked flux as weighted average\n    flux_stacked = sum_flux / sum_weights\n    flux_stacked[sum_weights == 0] = np.nan\n\n    # Model stacking can follow similar processing if needed\n    # For simplicity, assume stacked model is similar to stacked flux\n    model_stacked = np.copy(flux_stacked)\n    \n    return wavelength_stacked, flux_stacked, model_stacked\n",
                "true_code": "## Function 4 -\n\ndef stack_spectra(table):\n    \"\"\"\n    Function to Stack the spectra of all the sources in the given table.\n    Uses SPARCL to retrieve spectra\n    \n    Returns an inverse variance weighted mean of the input spectra.\n    \n    Parameters\n    ----------\n    table : table\n        Table of sources whose spectra need to be stacked\n    \n    Returns\n    -------\n    wavelength_stack : array\n        Wavelength array of the stacked spectra\n        \n    flux_stack : array\n        Flux array of the stacked spectra\n    \n    model_stack : array\n        Model array of the stacked spectra\n    \n    \"\"\"\n    \n    # Create an array with the targeted loglam values - reference array\n    loglam_ref = np.arange(3.5000, 3.9000, 0.0001).astype('float32')\n    \n    # Create empty lists for flux, ivar and model - \n    flux_array = []\n    model_array = []\n    ivar_array = []\n    \n    # Extract the necessary columns from the table\n    # redshift = table['z']\n    specobjid = [int(s) for s in table['specobjid'].data]\n    \n    # Number of spectra - \n    n = len(table)\n    \n    ## Retrieve the spectra\n    res = client.retrieve_by_specid(specid_list = specobjid, \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    ## All the spectra have the same spacing in log wavelength.\n    ## We shift the spectra in the observed wavelength range to fill the same log wavelength range\n    ## Join the different arrays of the individual spectra into a single array\n    \n    ## Compared the number of retrieved spectra to the number of requested spectra\n    ## NOTE: some datasets have missing spectra with inconsistent data models, which will be added at the \n    ##       next re-ingestion. Stats available here: https://astrosparcl.datalab.noirlab.edu/sparc/datasetnotes/\n    n_res = res.count\n    n_use = np.min([n_res, n])\n    if n_res!=n:\n        print(f\"WARNING: {n_res} spectra were retrieved from the requested {n}! Will proceed with {n_use} spectra.\")\n        \n    for ii in range(n_use):   \n                \n        ## Get rest-frame spectra of each object\n        res_rec = res.records[ii]\n        z = res_rec.redshift\n        lam = res_rec.wavelength/(1+z)\n        flux = res_rec.flux*(1+z)\n        model = res_rec.model*(1+z)\n        ivar = res_rec.ivar/((1+z)**2)\n        \n        loglam = np.around(np.log10(lam), 4).astype('float32')\n        # The log of reference wavelength and log of wavelength range of each spectra are converted to 'float32'\n        # This helps in avoiding the rounding errors\n        \n        # Creating empty arrays for flux, inverse variance and model \n        # with the same length as the reference loglam array\n        fl = np.zeros(len(loglam_ref))\n        iv = np.zeros(len(loglam_ref))\n        ml = np.zeros(len(loglam_ref))\n        \n        # Truth_array - A boolen array which will define what pixels the spectra have been shifted to\n        truth_array = np.zeros(len(loglam_ref), dtype = bool)\n        \n        # Find common elements between the reference and spectra wavelengths - \n        ll_common = np.intersect1d(loglam_ref, loglam)\n        \n        # Finding the indices of the first pixel in the common array in both reference and spectrum arrays\n        ref_start = np.where(loglam_ref == ll_common[0])[0][0]\n        spec_start = np.where(loglam == ll_common[0])[0][0]\n        \n        m = min(len(loglam_ref[ref_start:]), len(loglam[spec_start:]))\n        \n        # Match the first pixel of the common loglam values with the reference array \n        # Mark the number of pixels with the spectra starting from the first pixel to be True\n        truth_array[ref_start:ref_start+m] = True\n\n        # Fill the flux, inverse variance and model arrays\n        fl[truth_array] = flux[spec_start:spec_start+m]\n        iv[truth_array] = ivar[spec_start:spec_start+m]\n        ml[truth_array] = model[spec_start:spec_start+m]\n        \n        # Where the reference array is empty, fill the flux and model with nan values\n        # Set inverse variance to zero for these pixels\n        fl[~truth_array] = np.nan\n        iv[~truth_array] = 0.0\n        ml[~truth_array] = np.nan\n        \n        # Create a masked array with 'nan' values marked\n        # This avoids the pixels filled with 'nan' when stacking\n        fl = np.ma.masked_array(fl, np.isnan(fl))\n        iv = np.ma.masked_array(iv, np.isnan(iv))\n        ml = np.ma.masked_array(ml, np.isnan(ml))\n        \n        flux_array.append(fl)\n        model_array.append(ml)\n        ivar_array.append(iv)\n        \n    # Stack the spectra by weighted average \n    wavelength_stack = 10**(loglam_ref)\n    flux_stack = np.ma.average(flux_array, axis = 0, weights = ivar_array)\n    model_stack = np.ma.average(model_array, axis = 0, weights = ivar_array)\n    \n    flux_stack = flux_stack.filled(np.nan)\n    model_stack = model_stack.filled(np.nan)\n    \n    return (wavelength_stack, flux_stack, model_stack)",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.10697883364866738,
                    "ngram_match_score": 0.0263366304904879,
                    "weighted_ngram_match_score": 0.03907870410418164,
                    "syntax_match_score": 0.25,
                    "dataflow_match_score": 0.1125
                },
                "codebertscore": {
                    "precision": 0.8087524175643921,
                    "recall": 0.7722360491752625,
                    "F1": 0.7900725603103638,
                    "F3": 0.7757385969161987
                },
                "codebertscore_rescaled": {
                    "precision": 0.6175048351287842,
                    "recall": 0.5444720983505249,
                    "F1": 0.5801451206207275,
                    "F3": 0.5514771938323975
                }
            },
            {
                "ind": 47,
                "gen_code": "# Define the square regions in the BPT diagram for sampling galaxy types\n\nwidth = 0.2  # Width of the sampling box\nheight = 0.15  # Height of the sampling box\n\n# Coordinates for each class's sampling region\ncorner_comp = (-0.1, 0.2)  # Composite galaxies\ncorner_sf = (-0.8, -0.5)   # Star Forming galaxies\ncorner_sy = (0.2, 0.4)     # Seyfert galaxies\ncorner_liner = (0.3, -0.5) # LINER galaxies",
                "true_code": "## Defining vertices the lower-left corners of the four squares\nsy_x, sy_y = -0.15, 0.55\nsf_x, sf_y = -0.65, -0.05\nliner_x, liner_y = 0.0, 0.05\ncomp_x, comp_y = -0.25, 0.0\n\n# Defining the width and height size\nwidth = 0.1\nheight = 0.1",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 8,
                "codebleu": {
                    "codebleu": 0.1751742318498707,
                    "ngram_match_score": 0.012066689414595974,
                    "weighted_ngram_match_score": 0.018630237984886725,
                    "syntax_match_score": 0.32,
                    "dataflow_match_score": 0.35
                },
                "codebertscore": {
                    "precision": 0.7607738971710205,
                    "recall": 0.799757719039917,
                    "F1": 0.7797788977622986,
                    "F3": 0.7956805229187012
                },
                "codebertscore_rescaled": {
                    "precision": 0.521547794342041,
                    "recall": 0.599515438079834,
                    "F1": 0.5595577955245972,
                    "F3": 0.5913610458374023
                }
            },
            {
                "ind": 49,
                "gen_code": "# Plots with sample squares from where galaxies will be selected for stacking\nplt.figure(figsize = (8,8))\n\nplt.scatter(Nii_Ha[is_sy], Oiii_Hb[is_sy], color = 'r', s = 1.0, label='Seyfert')             # Seyferts in red (r)\nplt.scatter(Nii_Ha[is_sf], Oiii_Hb[is_sf], color = 'b', s = 1.0, label='Star Forming')         # SF in blue (b)\nplt.scatter(Nii_Ha[is_comp], Oiii_Hb[is_comp], color = 'g', s = 1.0, label='Composite')       # Composites in green (g)\nplt.scatter(Nii_Ha[is_liner], Oiii_Hb[is_liner], color = 'purple', s = 1.0, label='LINER')    # LINERs in purple\n\n# Plotting rectangles\nrect_sy = Rectangle((sy_x, sy_y), width, height, fill=False, color='r', linewidth=2, label='Seyfert Region')\nplt.gca().add_patch(rect_sy)\n\nrect_sf = Rectangle((sf_x, sf_y), width, height, fill=False, color='b', linewidth=2, label='SF Region')\nplt.gca().add_patch(rect_sf)\n\nrect_comp = Rectangle((comp_x, comp_y), width, height, fill=False, color='g', linewidth=2, label='Composite Region')\nplt.gca().add_patch(rect_comp)\n\nrect_liner = Rectangle((liner_x, liner_y), width, height, fill=False, color='purple', linewidth=2, label='LINER Region')\nplt.gca().add_patch(rect_liner)\n\nplt.xlim([-2, 0.75])\nplt.ylim([-1.2, 1.2])\nplt.xlabel('log ([NII]/H$\\\\alpha$)')\nplt.ylabel('log ([OIII]/H$\\\\beta$)')\nplt.legend()\nplt.show()",
                "true_code": "s1= Rectangle(xy = (sy_x, sy_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\ns2 = Rectangle(xy = (sf_x, sf_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\ns3 = Rectangle(xy = (liner_x, liner_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\ns4 = Rectangle(xy = (comp_x, comp_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\n\nplt.figure(figsize = (8,8))\n\nplt.scatter(Nii_Ha[is_sy], Oiii_Hb[is_sy], color = 'r', s = 1.0)\nplt.scatter(Nii_Ha[is_sf], Oiii_Hb[is_sf], color = 'b', s = 1.0)\nplt.scatter(Nii_Ha[is_comp], Oiii_Hb[is_comp], color = 'g', s = 1.0)\nplt.scatter(Nii_Ha[is_liner], Oiii_Hb[is_liner], color = 'purple', s = 1.0)\nplt.gca().add_patch(s1)\nplt.gca().add_patch(s2)\nplt.gca().add_patch(s3)\nplt.gca().add_patch(s4)\nplt.text(-1.0, -0.5, 'SF', color = 'blue', fontsize = 18)\nplt.text(0.0, -1.0, 'Composite', color = 'green', fontsize = 18)\nplt.text(0.5, 0.2, 'LINER', color = 'purple', fontsize = 18, rotation = 90)\nplt.text(-0.9, 1.0, 'Seyfert', color = 'r', fontsize = 18)\nplt.xlim([-2, 0.75])\nplt.ylim([-1.2, 1.2])\nplt.xlabel('log ([NII]/H$\\\\alpha$)')\nplt.ylabel('log ([OIII]/H$\\\\beta$)')\n\nplt.show()",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.3910716596845573,
                    "ngram_match_score": 0.19622843148084693,
                    "weighted_ngram_match_score": 0.20225553167209817,
                    "syntax_match_score": 0.7119565217391305,
                    "dataflow_match_score": 0.45384615384615384
                },
                "codebertscore": {
                    "precision": 0.8688284754753113,
                    "recall": 0.8896511793136597,
                    "F1": 0.8791165947914124,
                    "F3": 0.8875241279602051
                },
                "codebertscore_rescaled": {
                    "precision": 0.7376569509506226,
                    "recall": 0.7793023586273193,
                    "F1": 0.7582331895828247,
                    "F3": 0.7750482559204102
                }
            },
            {
                "ind": 51,
                "gen_code": "## Identifying sources that are within the rectangles\n## Extract index within the squares on the BPT Diagram - \n\nindex_sy = np.where((Nii_Ha > sy_x) & (Nii_Ha < sy_x + width) & (Oiii_Hb > sy_y) & (Oiii_Hb < sy_y + height))[0]\nindex_sf = np.where((Nii_Ha > sf_x) & (Nii_Ha < sf_x + width) & (Oiii_Hb > sf_y) & (Oiii_Hb < sf_y + height))[0]\nindex_liner = np.where((Nii_Ha > liner_x) & (Nii_Ha < liner_x + width) & (Oiii_Hb > liner_y) & (Oiii_Hb < liner_y + height))[0]\nindex_comp = np.where((Nii_Ha > comp_x) & (Nii_Ha < comp_x + width) & (Oiii_Hb > comp_y) & (Oiii_Hb < comp_y + height))[0]",
                "true_code": "# Regions of the white boxes - \n# Getting the indices of the sources within the four boxes\nsy_box = np.where((Nii_Ha >= sy_x) & (Nii_Ha <= sy_x+width) & (Oiii_Hb >= sy_y) & (Oiii_Hb <= sy_y+height))[0]\nsf_box = np.where((Nii_Ha >= sf_x) & (Nii_Ha <= sf_x+width) & (Oiii_Hb >= sf_y) & (Oiii_Hb <= sf_y+height))[0]\nliner_box = np.where((Nii_Ha >= liner_x) & (Nii_Ha <= liner_x+width) & (Oiii_Hb >= liner_y) & (Oiii_Hb <= liner_y+height))[0]\ncomp_box = np.where((Nii_Ha >= comp_x) & (Nii_Ha <= comp_x+width) & (Oiii_Hb >= comp_y) & (Oiii_Hb <= comp_y+height))[0]",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 54,
                "codebleu": {
                    "codebleu": 0.5298613801820988,
                    "ngram_match_score": 0.05426343276852928,
                    "weighted_ngram_match_score": 0.065182087959866,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.942035973072052,
                    "recall": 0.9521218538284302,
                    "F1": 0.947052001953125,
                    "F3": 0.9511035084724426
                },
                "codebertscore_rescaled": {
                    "precision": 0.884071946144104,
                    "recall": 0.9042437076568604,
                    "F1": 0.89410400390625,
                    "F3": 0.9022070169448853
                }
            },
            {
                "ind": 53,
                "gen_code": "# Printing number of sources within the four white boxes\nN_sy = len(sy_box)\nN_sf = len(sf_box)\nN_liner = len(liner_box)\nN_comp = len(comp_box)\n\nprint(f\"Number of Seyferts: {N_sy}\")\nprint(f\"Number of Star-Forming: {N_sf}\")\nprint(f\"Number of LINERs: {N_liner}\")\nprint(f\"Number of Composites: {N_comp}\")",
                "true_code": "len(final_table[sy_box]), len(final_table[sf_box]), len(final_table[comp_box]), len(final_table[liner_box])",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.15625,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.625
                },
                "codebertscore": {
                    "precision": 0.696127712726593,
                    "recall": 0.8019149899482727,
                    "F1": 0.7452861070632935,
                    "F3": 0.7899109721183777
                },
                "codebertscore_rescaled": {
                    "precision": 0.39225542545318604,
                    "recall": 0.6038299798965454,
                    "F1": 0.4905722141265869,
                    "F3": 0.5798219442367554
                }
            },
            {
                "ind": 55,
                "gen_code": "# Randomly selecting sources for stacking spectra\n\nnum_select = 100  # Number of galaxies to be selected for stacking in each class\n\nsy_selected = final_table[random.sample(list(sy_box), num_select)]\nsf_selected = final_table[random.sample(list(sf_box), num_select)]\ncomp_selected = final_table[random.sample(list(comp_box), num_select)]\nliner_selected = final_table[random.sample(list(liner_box), num_select)]",
                "true_code": "# Selecting 100 sources from each box and joining their rows into a table\nn = 100\n\n# Indices of 100 objects within each box\nsy_sel = np.sort(random.sample(list(sy_box), n))\nsf_sel = np.sort(random.sample(list(sf_box), n))\nliner_sel = np.sort(random.sample(list(liner_box), n))\ncomp_sel = np.sort(random.sample(list(comp_box), n))\n\n# Tables of the selections\ntab_sy = final_table[sy_sel]\ntab_sf = final_table[sf_sel]\ntab_liner = final_table[liner_sel]\ntab_comp = final_table[comp_sel]",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.2533307928112537,
                    "ngram_match_score": 0.019721532547011218,
                    "weighted_ngram_match_score": 0.020874365970730748,
                    "syntax_match_score": 0.4727272727272727,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.8651394248008728,
                    "recall": 0.8419167995452881,
                    "F1": 0.8533701300621033,
                    "F3": 0.8441827297210693
                },
                "codebertscore_rescaled": {
                    "precision": 0.7302788496017456,
                    "recall": 0.6838335990905762,
                    "F1": 0.7067402601242065,
                    "F3": 0.6883654594421387
                }
            },
            {
                "ind": 57,
                "gen_code": "# Stacking the spectra of different classes of galaxies\nwavelength_sf, flux_sf, model_sf = stack_spectra(tab_sf)\nwavelength_sy, flux_sy, model_sy = stack_spectra(tab_sy)\nwavelength_liner, flux_liner, model_liner = stack_spectra(tab_liner)\nwavelength_comp, flux_comp, model_comp = stack_spectra(tab_comp)",
                "true_code": "# Stacked spectra for the 100 sources within each white box\nlam_sy, flux_sy, model_sy = stack_spectra(tab_sy)\nlam_sf, flux_sf, model_sf = stack_spectra(tab_sf)\nlam_liner, flux_liner, model_liner = stack_spectra(tab_liner)\nlam_comp, flux_comp, model_comp = stack_spectra(tab_comp)",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 40,
                "codebleu": {
                    "codebleu": 0.6545219702818701,
                    "ngram_match_score": 0.3139399446791828,
                    "weighted_ngram_match_score": 0.3041479364482976,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.933791995048523,
                    "recall": 0.9352688789367676,
                    "F1": 0.9345298409461975,
                    "F3": 0.9351209402084351
                },
                "codebertscore_rescaled": {
                    "precision": 0.8675839900970459,
                    "recall": 0.8705377578735352,
                    "F1": 0.869059681892395,
                    "F3": 0.8702418804168701
                }
            },
            {
                "ind": 59,
                "gen_code": "# Creating subplots for visualizing stacked spectra for each galaxy type\n\nfig, axs = plt.subplots(2, 2, figsize=(15, 10))\n\n# Seyfert galaxies\naxs[0, 0].plot(lam_sy, model_sy, color='r', label='Model')\naxs[0, 0].plot(lam_sy, flux_sy, color='grey', alpha=0.5, label='Stacked Spectra')\naxs[0, 0].set_title('Seyfert Galaxies')\naxs[0, 0].set_xlabel('Wavelength [\u00c5]')\naxs[0, 0].set_ylabel('Flux')\naxs[0, 0].legend()\n\n# Star Forming galaxies\naxs[0, 1].plot(lam_sf, model_sf, color='b', label='Model')\naxs[0, 1].plot(lam_sf, flux_sf, color='grey', alpha=0.5, label='Stacked Spectra')\naxs[0, 1].set_title('Star Forming Galaxies')\naxs[0, 1].set_xlabel('Wavelength [\u00c5]')\naxs[0, 1].set_ylabel('Flux')\naxs[0, 1].legend()\n\n# LINER galaxies\naxs[1, 0].plot(lam_liner, model_liner, color='purple', label='Model')\naxs[1, 0].plot(lam_liner, flux_liner, color='grey', alpha=0.5, label='Stacked Spectra')\naxs[1, 0].set_title('LINER Galaxies')\naxs[1, 0].set_xlabel('Wavelength [\u00c5]')\naxs[1, 0].set_ylabel('Flux')\naxs[1, 0].legend()\n\n# Composite galaxies\naxs[1, 1].plot(lam_comp, model_comp, color='g', label='Model')\naxs[1, 1].plot(lam_comp, flux_comp, color='grey', alpha=0.5, label='Stacked Spectra')\naxs[1, 1].set_title('Composite Galaxies')\naxs[1, 1].set_xlabel('Wavelength [\u00c5]')\naxs[1, 1].set_ylabel('Flux')\naxs[1, 1].legend()\n\nplt.tight_layout()\nplt.show()",
                "true_code": "fig, axs = plt.subplots(4,1, figsize = (12, 12), sharex = True, sharey = True)\nplt.subplots_adjust(wspace = 0., hspace = 0.)\n\naxs[0].plot(lam_sy, flux_sy, color = 'r', label = 'Seyferts')\naxs[0].legend(fontsize = 14, loc = 'upper left')\naxs[0].set_ylabel('$F_{\\lambda}$')\n\naxs[1].plot(lam_sf, flux_sf, color = 'b', label = 'Star-Forming')\naxs[1].legend(fontsize = 14, loc = 'upper left')\naxs[1].set_ylabel('$F_{\\lambda}$')\n\naxs[2].plot(lam_liner, flux_liner, color = 'purple', label = 'LINERs')\naxs[2].legend(fontsize = 14, loc = 'upper left')\naxs[2].set_ylabel('$F_{\\lambda}$')\n\naxs[3].plot(lam_comp, flux_comp, color = 'g', label = 'Composite')\naxs[3].legend(fontsize = 14, loc = 'upper left')\naxs[3].set_xlim([3510, 7010])\naxs[3].set_xlabel('$\\lambda$')\naxs[3].set_ylabel('$F_{\\lambda}$');",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.28668770393903287,
                    "ngram_match_score": 0.009027420173890412,
                    "weighted_ngram_match_score": 0.012723395582241028,
                    "syntax_match_score": 0.35714285714285715,
                    "dataflow_match_score": 0.7678571428571429
                },
                "codebertscore": {
                    "precision": 0.8405798673629761,
                    "recall": 0.8521591424942017,
                    "F1": 0.846329927444458,
                    "F3": 0.8509868383407593
                },
                "codebertscore_rescaled": {
                    "precision": 0.6811597347259521,
                    "recall": 0.7043182849884033,
                    "F1": 0.692659854888916,
                    "F3": 0.7019736766815186
                }
            },
            {
                "ind": 62,
                "gen_code": "fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(14, 10), constrained_layout=True)\nplt.subplots_adjust(wspace=0.3, hspace=0.4)\n\n# Define spectral line landmarks\noiii_hb_range = [4800, 5050]  # around OIII 5007 and Hb\nnii_ha_range = [6450, 6650]   # around NII 6583 and Ha\n\n# Define colors for different classifications\ncolors = {'Seyfert': 'r', 'Star-Forming': 'b', 'LINER': 'purple', 'Composite': 'g'}\n\n# Plotting subplots with annotations\nfor i, (name, color, lam, flux) in enumerate(zip(['Seyfert', 'Star-Forming', 'LINER', 'Composite'],\n                                                 ['r', 'b', 'purple', 'g'],\n                                                 [lam_sy, lam_sf, lam_liner, lam_comp],\n                                                 [flux_sy, flux_sf, flux_liner, flux_comp])):\n    # OIII and Hb range\n    axs[i, 0].plot(lam, flux, color=color)\n    axs[i, 0].set_xlim(oiii_hb_range)\n    axs[i, 0].set_title(f\"[OIII] and H\u03b2: {name}\", fontsize=12)\n    axs[i, 0].set_ylabel('$F_{\\\\lambda}$')\n\n    # NII and Ha range\n    axs[i, 1].plot(lam, flux, color=color)\n    axs[i, 1].set_xlim(nii_ha_range)\n    axs[i, 1].set_title(f\"[NII] and H\u03b1: {name}\", fontsize=12)\n    axs[i, 1].set_ylabel('$F_{\\\\lambda}$')\n\n    # Labels for important lines\n    for ax in axs[i]:\n        add_lines(ax, [4861, 5007, 6563, 6583], \n                  ['H\u03b2', '[OIII]', 'H\u03b1', '[NII]'],\n                  [4861, 5007, 6563, 6583],\n                  colors={'H\u03b2': 'orange', '[OIII]': 'cyan', 'H\u03b1': 'orange', '[NII]': 'cyan'})\n    \n    if i == 3:  # Last row, add xlabel to axes\n        axs[i, 0].set_xlabel('$\\lambda$ (\u00c5)')\n        axs[i, 1].set_xlabel('$\\lambda$ (\u00c5)')\n\nplt.show()",
                "true_code": "fig, axs = plt.subplots(4,2, figsize = (16,12), sharey = True, sharex = 'col')\nplt.subplots_adjust(wspace = 0.05, hspace = 0.0)\n\naxs[0][0].plot(lam_sy, flux_sy, color = 'r', label = 'Seyferts')\naxs[0][0].legend(fontsize = 14, loc = 'upper left')\naxs[0][0].set_ylabel('$F_{\\lambda}$')\naxs[0][0].set_xlim([4810, 5090])\nadd_lines(ax = axs[0][0], z=0, abs_lines = [])\n\naxs[1][0].plot(lam_sf, flux_sf, color = 'b', label = 'Star-Forming')\naxs[1][0].legend(fontsize = 14, loc = 'upper left')\naxs[1][0].set_ylabel('$F_{\\lambda}$')\nadd_lines(ax = axs[1][0], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[2][0].plot(lam_liner, flux_liner, color = 'purple', label = 'LINERs')\naxs[2][0].legend(fontsize = 14, loc = 'upper left')\naxs[2][0].set_ylabel('$F_{\\lambda}$')\naxs[2][0].set_xlabel('$\\lambda$')\nadd_lines(ax = axs[2][0], z=0, rest_frame = True, abs_lines = [], em_label = False)\n                \naxs[3][0].plot(lam_comp, flux_comp, color = 'g', label = 'Composite')\naxs[3][0].legend(fontsize = 14, loc = 'upper left')\naxs[3][0].set_ylabel('$F_{\\lambda}$')\naxs[3][0].set_xlabel('$\\lambda$')\nadd_lines(ax = axs[3][0], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[0][1].plot(lam_sy, flux_sy, color = 'r', label = 'Seyferts')\naxs[0][1].set_xlim([6250, 6900])\nadd_lines(ax = axs[0][1], z=0, rest_frame = True, abs_lines = [])\n\naxs[1][1].plot(lam_sf, flux_sf, color = 'b', label = 'Star-Forming')\nadd_lines(ax = axs[1][1], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[2][1].plot(lam_liner, flux_liner, color = 'purple', label = 'LINERs')\nadd_lines(ax = axs[2][1], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[3][1].plot(lam_comp, flux_comp, color = 'g', label = 'Composite')\naxs[3][1].set_xlabel('$\\lambda$')\nadd_lines(ax = axs[3][1], z=0, rest_frame = True, abs_lines = [], em_label = False)",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 8,
                "codebleu": {
                    "codebleu": 0.1558299437166516,
                    "ngram_match_score": 0.00566718213157395,
                    "weighted_ngram_match_score": 0.005892531426656066,
                    "syntax_match_score": 0.2560553633217993,
                    "dataflow_match_score": 0.35570469798657717
                },
                "codebertscore": {
                    "precision": 0.7889449596405029,
                    "recall": 0.8284839987754822,
                    "F1": 0.8082311749458313,
                    "F3": 0.8243525624275208
                },
                "codebertscore_rescaled": {
                    "precision": 0.5778899192810059,
                    "recall": 0.6569679975509644,
                    "F1": 0.6164623498916626,
                    "F3": 0.6487051248550415
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.0,
            "fuzzy_match": 21.32,
            "codebleu": 0.32146569665149066,
            "syntax_match_score": 0.5713286295433782,
            "codebertscore": 0.8194124341011048,
            "codebertscore_rescaled": 0.6388248682022095,
            "code_success": 0.36,
            "total_code_cell_count": 25
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/02_DESI_EDR_SDSS_Comparison_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/DESI/02_DESI_EDR_SDSS_Comparison.ipynb",
            "prefix": "desi_1"
        },
        "model": {
            "name": "gpt-4o",
            "model": "gpt-4o",
            "library": "OA"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "notebook_id = \"astro_notebook_001\"\nauthor_name = \"John Doe\"\nauthor_email = \"john.doe@example.com\"\nversion = \"1.0\"\n\ndatasets = [\n    \"SDSS DR16\",\n    \"DESI Early Data Release\"\n]\n\nkeywords = [\n    \"astronomy\",\n    \"datasets\",\n    \"SDSS\",\n    \"DESI\",\n    \"data analysis\"\n]",
                "true_code": "__nbid__ = '0006'\n__author__ = 'Ragadeepika Pucha <rpucha@arizona.edu>, Stephanie Juneau <stephanie.juneau@noirlab.edu>' \n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['sdss_dr16', 'desi_edr']  \n__keywords__ = ['sparcl', 'spectra', 'database'] ",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 8,
                "codebleu": {
                    "codebleu": 0.3804017315701467,
                    "ngram_match_score": 0.008447063994683927,
                    "weighted_ngram_match_score": 0.011328360454400999,
                    "syntax_match_score": 0.8095238095238095,
                    "dataflow_match_score": 0.6923076923076923
                },
                "codebertscore": {
                    "precision": 0.7576096653938293,
                    "recall": 0.7104652523994446,
                    "F1": 0.7332804799079895,
                    "F3": 0.7149139046669006
                },
                "codebertscore_rescaled": {
                    "precision": 0.5152193307876587,
                    "recall": 0.42093050479888916,
                    "F1": 0.466560959815979,
                    "F3": 0.42982780933380127
                }
            },
            {
                "ind": 9,
                "gen_code": "plt.rcParams.update({\n    'font.size': 12,           # Set default font size\n    'axes.titlesize': 14,      # Set the title size\n    'axes.labelsize': 12,      # Set the axes label size\n    'lines.linewidth': 2,      # Set the line width\n    'xtick.labelsize': 10,     # Set x-tick label size\n    'ytick.labelsize': 10,     # Set y-tick label size\n    'axes.grid': True,         # Enable grid by default\n    'axes.edgecolor': 'gray',  # Set edge color for axes\n    'axes.linewidth': 1.2,     # Set line width for axes\n    'legend.fontsize': 10      # Set legend font size\n})",
                "true_code": "## Making the matplotlib plots look nicer\nsettings = {\n    'font.size':20,\n    'axes.linewidth':2.0,\n    'xtick.major.size':6.0,\n    'xtick.minor.size':4.0,\n    'xtick.major.width':2.0,\n    'xtick.minor.width':1.5,\n    'xtick.direction':'in', \n    'xtick.minor.visible':True,\n    'xtick.top':True,\n    'ytick.major.size':6.0,\n    'ytick.minor.size':4.0,\n    'ytick.major.width':2.0,\n    'ytick.minor.width':1.5,\n    'ytick.direction':'in', \n    'ytick.minor.visible':True,\n    'ytick.right':True\n}\n\nplt.rcParams.update(**settings)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.4568294994954971,
                    "ngram_match_score": 0.002419707747815489,
                    "weighted_ngram_match_score": 0.006716472052354862,
                    "syntax_match_score": 0.8181818181818182,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.757326602935791,
                    "recall": 0.7802563905715942,
                    "F1": 0.7686205506324768,
                    "F3": 0.7779011130332947
                },
                "codebertscore_rescaled": {
                    "precision": 0.514653205871582,
                    "recall": 0.5605127811431885,
                    "F1": 0.5372411012649536,
                    "F3": 0.5558022260665894
                }
            },
            {
                "ind": 11,
                "gen_code": "sparcl_client = SparclClient()",
                "true_code": "## Load the SPARCL client for data discovery and spectral access\n\nclient = SparclClient()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 44,
                "codebleu": {
                    "codebleu": 0.5082801867179065,
                    "ngram_match_score": 0.006141954375138051,
                    "weighted_ngram_match_score": 0.026978792496488383,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8964844346046448,
                    "recall": 0.8110854029655457,
                    "F1": 0.8516494631767273,
                    "F3": 0.8188860416412354
                },
                "codebertscore_rescaled": {
                    "precision": 0.7929688692092896,
                    "recall": 0.6221708059310913,
                    "F1": 0.7032989263534546,
                    "F3": 0.6377720832824707
                }
            },
            {
                "ind": 13,
                "gen_code": "# Ensure the SPARCL client is properly initialized\nprint(client)",
                "true_code": "client",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 17,
                "codebleu": {
                    "codebleu": 0.2857252520655248,
                    "ngram_match_score": 0.023980296761827107,
                    "weighted_ngram_match_score": 0.11892071150027214,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.6285295486450195,
                    "recall": 0.8152162432670593,
                    "F1": 0.7098029255867004,
                    "F3": 0.791701078414917
                },
                "codebertscore_rescaled": {
                    "precision": 0.25705909729003906,
                    "recall": 0.6304324865341187,
                    "F1": 0.4196058511734009,
                    "F3": 0.583402156829834
                }
            },
            {
                "ind": 16,
                "gen_code": "## Specify the required fields and constraints for data discovery\nfields = ['TARGETID', 'RA', 'DEC', 'Z', 'SPECTYPE']\nconstraints = {\n    'RA': ('208.4', '210.2'),\n    'DEC': ('4.8', '6.4'),\n    'Z': ('0.1', '0.15'),\n    'SPECTYPE': 'GALAXY'\n}\ndatasets = ['sdss_dr16', 'desi_edr']\n\n## Execute SPARCL data discovery for both SDSS and DESI datasets\nselection_sdss = client.discover(fields=fields, constraints=constraints, datasets='sdss_dr16')\nselection_desi = client.discover(fields=fields, constraints=constraints, datasets='desi_edr')",
                "true_code": "## The outfields that are required as output from SPARCL\nout = ['sparcl_id', 'specid', 'ra', 'dec', 'redshift'] \n\n## Constraints\n## SPECTYPE = 'GALAXY'\n## 208.4 <= RA <= 210.2\n## 4.8 <= DEC <= 6.4\n## 0.1 <= Redshift <= 0.15\n## SPECPRIMARY = True -- consider only primary spectra\n## \"datasetgroup\" denotes the required survey (SDSS_BOSS for SDSS-DR16 (SDSS+BOSS data), and DESI for DESI EDR data (will be updated with future releases))\n\nsdss_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['SDSS_BOSS'], 'redshift': [0.1, 0.15]}\ndesi_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['DESI'], 'redshift': [0.1, 0.15]} ",
                "error_ind": 16,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.2442804810775439,
                    "ngram_match_score": 0.006263798786911636,
                    "weighted_ngram_match_score": 0.00817869968594352,
                    "syntax_match_score": 0.43636363636363634,
                    "dataflow_match_score": 0.5263157894736842
                },
                "codebertscore": {
                    "precision": 0.7931498885154724,
                    "recall": 0.7722463011741638,
                    "F1": 0.7825585007667542,
                    "F3": 0.7742869257926941
                },
                "codebertscore_rescaled": {
                    "precision": 0.5862997770309448,
                    "recall": 0.5444926023483276,
                    "F1": 0.5651170015335083,
                    "F3": 0.5485738515853882
                }
            },
            {
                "ind": 18,
                "gen_code": "## Retrieve the spectra for SDSS and DESI\n\nlimit = 1000 ## Adjust limit as suitable\n\nsdss_spec = client.search(spec_cons=sdss_cons, outfields=out, limit=limit)\ndesi_spec = client.search(spec_cons=desi_cons, outfields=out, limit=limit)",
                "true_code": "rec_sdss = client.find(outfields=out, constraints=sdss_cons, limit = 5000)\nrec_desi = client.find(outfields=out, constraints=desi_cons, limit = 5000)",
                "error_ind": 18,
                "direct_match": false,
                "fuzzy_match": 10,
                "codebleu": {
                    "codebleu": 0.28311667042669225,
                    "ngram_match_score": 0.019320990745681776,
                    "weighted_ngram_match_score": 0.03798229226827674,
                    "syntax_match_score": 0.35294117647058826,
                    "dataflow_match_score": 0.7222222222222222
                },
                "codebertscore": {
                    "precision": 0.8223877549171448,
                    "recall": 0.8885473608970642,
                    "F1": 0.8541883826255798,
                    "F3": 0.881456196308136
                },
                "codebertscore_rescaled": {
                    "precision": 0.6447755098342896,
                    "recall": 0.7770947217941284,
                    "F1": 0.7083767652511597,
                    "F3": 0.762912392616272
                }
            },
            {
                "ind": 20,
                "gen_code": "ra_sdss = rec_sdss['ra']\ndec_sdss = rec_sdss['dec']\n\nra_desi = rec_desi['ra']\ndec_desi = rec_desi['dec']",
                "true_code": "ra_sdss = np.array([rec['ra'] for rec in rec_sdss.records])\ndec_sdss = np.array([rec['dec'] for rec in rec_sdss.records])\n\nra_desi = np.array([rec['ra'] for rec in rec_desi.records])\ndec_desi = np.array([rec['dec'] for rec in rec_desi.records])",
                "error_ind": 20,
                "direct_match": false,
                "fuzzy_match": 51,
                "codebleu": {
                    "codebleu": 0.11408523897408945,
                    "ngram_match_score": 0.01898996110469067,
                    "weighted_ngram_match_score": 0.023479043572154915,
                    "syntax_match_score": 0.1951219512195122,
                    "dataflow_match_score": 0.21875
                },
                "codebertscore": {
                    "precision": 0.9408469796180725,
                    "recall": 0.8231649398803711,
                    "F1": 0.8780805468559265,
                    "F3": 0.833591639995575
                },
                "codebertscore_rescaled": {
                    "precision": 0.881693959236145,
                    "recall": 0.6463298797607422,
                    "F1": 0.756161093711853,
                    "F3": 0.6671832799911499
                }
            },
            {
                "ind": 22,
                "gen_code": "plt.figure(figsize=(10, 8))\nplt.scatter(ra_sdss, dec_sdss, s=10, c='blue', marker='o', label='SDSS DR16')\nplt.scatter(ra_desi, dec_desi, s=10, c='red', marker='x', label='DESI EDR')\n\nplt.xlabel('Right Ascension (degrees)')\nplt.ylabel('Declination (degrees)')\nplt.title('Sky Positions of Galaxies with Spectra in SDSS DR16 and DESI EDR')\nplt.legend()\nplt.gca().invert_xaxis()  # Invert x-axis for correct representation\n\nplt.grid(True)\nplt.show()",
                "true_code": "## Overlap of sources\n\nplt.figure(figsize = (8,8))\n\nplt.suptitle('Sky Positions of Galaxies with SDSS and DESI Spectra', fontsize = 20)\n\nplt.scatter(ra_desi, dec_desi, color = 'grey', marker = 'o', s = 50, alpha = 0.8, lw = 2.0, label = 'DESI EDR')\nplt.scatter(ra_sdss, dec_sdss, color = 'r', marker = 'X', s = 50, label = 'SDSS DR16')\nplt.gca().invert_xaxis()\nplt.xlabel('R.A. [deg]')\nplt.ylabel('Dec. [deg]')\nplt.legend(loc = 'upper right')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 12,
                "codebleu": {
                    "codebleu": 0.4664713316756532,
                    "ngram_match_score": 0.053252452885755454,
                    "weighted_ngram_match_score": 0.06263287381685724,
                    "syntax_match_score": 0.75,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8927415609359741,
                    "recall": 0.8697764873504639,
                    "F1": 0.8811094164848328,
                    "F3": 0.8720197081565857
                },
                "codebertscore_rescaled": {
                    "precision": 0.7854831218719482,
                    "recall": 0.7395529747009277,
                    "F1": 0.7622188329696655,
                    "F3": 0.7440394163131714
                }
            },
            {
                "ind": 24,
                "gen_code": "## Make a catalog of sources from the SDSS DR16 and the DESI EDR datasets\ncoords_sdss = SkyCoord(ra=ra_sdss * u.deg, dec=dec_sdss * u.deg)\ncoords_desi = SkyCoord(ra=ra_desi * u.deg, dec=dec_desi * u.deg)\n\n## Define the tolerance for matching sources\ntolerance = 1.0 * u.arcsec\n\n## Identify the common sources using search_around_sky\nidx_sdss, idx_desi, _, _ = search_around_sky(coords_sdss, coords_desi, tolerance)\n",
                "true_code": "## Find common sources between SDSS and DESI\n\ncat_desi = SkyCoord(ra = ra_desi*u.deg, dec = dec_desi*u.deg)\ncat_sdss = SkyCoord(ra = ra_sdss*u.deg, dec = dec_sdss*u.deg)\n\nii_desi, ii_sdss, _, _ = search_around_sky(cat_desi, cat_sdss, 0.5*u.arcsec)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 28,
                "codebleu": {
                    "codebleu": 0.4315749673725482,
                    "ngram_match_score": 0.02438440897812662,
                    "weighted_ngram_match_score": 0.04715355575016126,
                    "syntax_match_score": 0.8214285714285714,
                    "dataflow_match_score": 0.8333333333333334
                },
                "codebertscore": {
                    "precision": 0.8489711880683899,
                    "recall": 0.9054058790206909,
                    "F1": 0.8762808442115784,
                    "F3": 0.8994269967079163
                },
                "codebertscore_rescaled": {
                    "precision": 0.6979423761367798,
                    "recall": 0.8108117580413818,
                    "F1": 0.7525616884231567,
                    "F3": 0.7988539934158325
                }
            },
            {
                "ind": 26,
                "gen_code": "## Extract corresponding records from SDSS and DESI\n\ncommon_sdss_records = [rec_sdss.records[i] for i in ii_sdss]\ncommon_desi_records = [rec_desi.records[i] for i in ii_desi]",
                "true_code": "desi_common = [rec_desi.records[ii] for ii in ii_desi]\nsdss_common = [rec_sdss.records[ii] for ii in ii_sdss]",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 35,
                "codebleu": {
                    "codebleu": 0.5215390550101195,
                    "ngram_match_score": 0.030897518619233476,
                    "weighted_ngram_match_score": 0.05525870142124495,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8732518553733826,
                    "recall": 0.9174067378044128,
                    "F1": 0.8947849273681641,
                    "F3": 0.91279137134552
                },
                "codebertscore_rescaled": {
                    "precision": 0.7465037107467651,
                    "recall": 0.8348134756088257,
                    "F1": 0.7895698547363281,
                    "F3": 0.82558274269104
                }
            },
            {
                "ind": 28,
                "gen_code": "# Create Astropy tables from the list of common records\n\ntable_desi_common = Table(rows=desi_common, names=out)\ntable_sdss_common = Table(rows=sdss_common, names=out)",
                "true_code": "t_desi_common = Table(desi_common)\nt_sdss_common = Table(sdss_common)",
                "error_ind": 28,
                "direct_match": false,
                "fuzzy_match": 59,
                "codebleu": {
                    "codebleu": 0.18201550839104166,
                    "ngram_match_score": 0.01284618972676772,
                    "weighted_ngram_match_score": 0.048549177170732344,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.6666666666666666
                },
                "codebertscore": {
                    "precision": 0.81688392162323,
                    "recall": 0.9356117248535156,
                    "F1": 0.8722260594367981,
                    "F3": 0.9222081303596497
                },
                "codebertscore_rescaled": {
                    "precision": 0.63376784324646,
                    "recall": 0.8712234497070312,
                    "F1": 0.7444521188735962,
                    "F3": 0.8444162607192993
                }
            },
            {
                "ind": 30,
                "gen_code": "t_common = hstack([t_sdss_common, t_desi_common], table_names=['SDSS', 'DESI'])",
                "true_code": "## Combining the two tables into a single table\n\nt_comb = hstack([t_desi_common, t_sdss_common], table_names=['desi', 'sdss'])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 61,
                "codebleu": {
                    "codebleu": 0.5055817995673824,
                    "ngram_match_score": 0.009109250643152446,
                    "weighted_ngram_match_score": 0.013217947626377298,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9089327454566956,
                    "recall": 0.846177339553833,
                    "F1": 0.8764331340789795,
                    "F3": 0.8520601987838745
                },
                "codebertscore_rescaled": {
                    "precision": 0.8178654909133911,
                    "recall": 0.692354679107666,
                    "F1": 0.752866268157959,
                    "F3": 0.704120397567749
                }
            },
            {
                "ind": 32,
                "gen_code": "print(f\"Number of common objects from DESI EDR: {len(t_desi_common)}\")\nprint(f\"Number of common objects from SDSS DR16: {len(t_sdss_common)}\")\nprint(f\"Number of unique combined objects: {len(t_comb)}\")",
                "true_code": "print ('Number of unique SDSS objects: ', len(np.unique(t_comb['specid_sdss'])))\nprint ('Number of unique DESI objects: ', len(np.unique(t_comb['specid_desi'])))",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 38,
                "codebleu": {
                    "codebleu": 0.06460334113385875,
                    "ngram_match_score": 0.024178614976744797,
                    "weighted_ngram_match_score": 0.0342347495586902,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.2
                },
                "codebertscore": {
                    "precision": 0.8628359436988831,
                    "recall": 0.8832299709320068,
                    "F1": 0.8729138970375061,
                    "F3": 0.8811473250389099
                },
                "codebertscore_rescaled": {
                    "precision": 0.7256718873977661,
                    "recall": 0.7664599418640137,
                    "F1": 0.7458277940750122,
                    "F3": 0.7622946500778198
                }
            },
            {
                "ind": 34,
                "gen_code": "## Discrepancies in object counts between the surveys\n## There might be cases where one SDSS object corresponds to multiple DESI entries. Identify and remove these duplicates\n\nunique_ids, counts = np.unique(t_comb['specid_sdss'], return_counts=True)\nduplicate_ids = unique_ids[counts > 1]\n\nfiltered_entries = [i for i, specid in enumerate(t_comb['specid_sdss']) if specid not in duplicate_ids]\n\nt_comb_filtered = t_comb[filtered_entries]\n\nprint('Number of unique SDSS objects after filtering: ', len(np.unique(t_comb_filtered['specid_sdss'])))\nprint('Number of unique DESI objects after filtering: ', len(np.unique(t_comb_filtered['specid_desi'])))",
                "true_code": "## This suggests that one SDSS object has been selected as two DESI objects.\n## We remove that particular object from our selection\n\nsdss_ids_unique, n_counts = np.unique(t_comb['specid_sdss'].data, return_counts = True)\nsdss_id_repeated = sdss_ids_unique[n_counts > 1]\n\n## Removing this particular object\nt_comb_unique = t_comb[~(t_comb['specid_sdss'].data == sdss_id_repeated)]",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 30,
                "codebleu": {
                    "codebleu": 0.28552851450274097,
                    "ngram_match_score": 0.02060078286210938,
                    "weighted_ngram_match_score": 0.03160099444710006,
                    "syntax_match_score": 0.4583333333333333,
                    "dataflow_match_score": 0.631578947368421
                },
                "codebertscore": {
                    "precision": 0.7890897393226624,
                    "recall": 0.8429352641105652,
                    "F1": 0.8151242733001709,
                    "F3": 0.8372222781181335
                },
                "codebertscore_rescaled": {
                    "precision": 0.5781794786453247,
                    "recall": 0.6858705282211304,
                    "F1": 0.6302485466003418,
                    "F3": 0.6744445562362671
                }
            },
            {
                "ind": 36,
                "gen_code": "## Isolating redshift data for comparison\n\nredshift_sdss = t_comb_unique['redshift_sdss']\nredshift_desi = t_comb_unique['redshift_desi']",
                "true_code": "z_desi = t_comb_unique['redshift_desi']\nz_sdss = t_comb_unique['redshift_sdss']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 35,
                "codebleu": {
                    "codebleu": 0.5432589561698884,
                    "ngram_match_score": 0.05094110796339642,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8847988843917847,
                    "recall": 0.9284487962722778,
                    "F1": 0.906098484992981,
                    "F3": 0.9238909482955933
                },
                "codebertscore_rescaled": {
                    "precision": 0.7695977687835693,
                    "recall": 0.8568975925445557,
                    "F1": 0.8121969699859619,
                    "F3": 0.8477818965911865
                }
            },
            {
                "ind": 38,
                "gen_code": "## Just checking that the length of both redshift columns is the same\nprint(f\"Number of unique matches (DESI): {len(z_desi)}\")\nprint(f\"Number of unique matches (SDSS): {len(z_sdss)}\")\n",
                "true_code": "len(z_desi), len(z_sdss)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 22,
                "codebleu": {
                    "codebleu": 0.41666666666666663,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.6666666666666666,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7396367192268372,
                    "recall": 0.8993848562240601,
                    "F1": 0.8117257952690125,
                    "F3": 0.8803704380989075
                },
                "codebertscore_rescaled": {
                    "precision": 0.4792734384536743,
                    "recall": 0.7987697124481201,
                    "F1": 0.6234515905380249,
                    "F3": 0.7607408761978149
                }
            },
            {
                "ind": 40,
                "gen_code": "## Compare redshifts from the two different surveys\n\nplt.figure(figsize = (8,8))\n\nplt.plot([0.1, 0.15], [0.1, 0.15], 'k--', lw=2) # unity line\nplt.scatter(z_sdss, z_desi, color='blue', alpha=0.5, s=50, label='Galaxies')\n\nplt.xlabel('SDSS Redshift', fontsize=15)\nplt.ylabel('DESI Redshift', fontsize=15)\nplt.title('Redshift Comparison: SDSS vs DESI', fontsize=18)\nplt.legend(loc='upper left')\n\nplt.xlim(0.1, 0.15)\nplt.ylim(0.1, 0.15)\nplt.grid(True)\nplt.show()",
                "true_code": "# Comparison of redshifts\nplt.figure(figsize = (6,6))\nplt.suptitle('Redshift Comparison')\n\nplt.scatter(z_sdss, z_desi, edgecolors = 'k', marker = 'o', s = 100, lw = 3.0, facecolors = 'none')\nplt.plot([0.1, 0.15], [0.1,0.15], ls = ':', color = 'r', lw = 2.0)\nplt.xlabel('$z_{spec}$ (SDSS)')\nplt.ylabel('$z_{spec}$ (DESI)')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 13,
                "codebleu": {
                    "codebleu": 0.41936671305005746,
                    "ngram_match_score": 0.01573366652450736,
                    "weighted_ngram_match_score": 0.01728874123127798,
                    "syntax_match_score": 0.6444444444444445,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8695024251937866,
                    "recall": 0.8865170478820801,
                    "F1": 0.877927303314209,
                    "F3": 0.8847856521606445
                },
                "codebertscore_rescaled": {
                    "precision": 0.7390048503875732,
                    "recall": 0.7730340957641602,
                    "F1": 0.755854606628418,
                    "F3": 0.7695713043212891
                }
            },
            {
                "ind": 43,
                "gen_code": "# Import the data from the SDSS DR12 'emissionlinesport' table which contains [OII] measurements\n\n## Constraints for the query: \n## RA, Dec are within the specified limits\n## Only interested in non-zero [OII] flux sources\n\nquery = \"\"\"\nSELECT\n  elp.specobjid, s.ra, s.dec, elp.oii_3727_flux as oii_flux\nFROM\n  specphoto AS s\nJOIN\n  emissionlinesport as elp ON s.specobjid = elp.specobjid\nWHERE\n  s.ra BETWEEN 208.4 AND 210.2\n  AND s.dec BETWEEN 4.8 AND 6.4\n  AND elp.oii_3727_flux > 0\n\"\"\"\n\nresults = qc.query(sql=query, fmt='table')\nresults",
                "true_code": "## Query to access galaxies with non-zero [OII] measurements\nquery = \"\"\"\nSELECT specobjid as specid_sdss, \nflux_oii_3726, flux_oii_3726_err,\nflux_oii_3728, flux_oii_3728_err\nFROM sdss_dr12.emissionlinesport\nWHERE (ra >= 208.4) AND (ra <= 210.2) AND (dec >= 4.8) AND (dec <= 6.4) \nAND (flux_oii_3726_err != 0) AND (flux_oii_3728_err != 0)\n\"\"\"",
                "error_ind": 43,
                "direct_match": false,
                "fuzzy_match": 18,
                "codebleu": {
                    "codebleu": 0.46884639924230154,
                    "ngram_match_score": 0.045895857959758306,
                    "weighted_ngram_match_score": 0.07948973900944792,
                    "syntax_match_score": 0.75,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7762725949287415,
                    "recall": 0.8643622994422913,
                    "F1": 0.817952573299408,
                    "F3": 0.8546637296676636
                },
                "codebertscore_rescaled": {
                    "precision": 0.5525451898574829,
                    "recall": 0.7287245988845825,
                    "F1": 0.6359051465988159,
                    "F3": 0.7093274593353271
                }
            },
            {
                "ind": 45,
                "gen_code": "print(query)",
                "true_code": "print (query)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 96,
                "codebleu": {
                    "codebleu": 0.5,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.9702564477920532,
                    "recall": 0.9702564477920532,
                    "F1": 0.9702564477920532,
                    "F3": 0.9702563881874084
                },
                "codebertscore_rescaled": {
                    "precision": 0.9405128955841064,
                    "recall": 0.9405128955841064,
                    "F1": 0.9405128955841064,
                    "F3": 0.9405127763748169
                }
            },
            {
                "ind": 47,
                "gen_code": "## Execute query to fetch [OII] line data from the SDSS DR12 database\nresult = qc.query(sql=query, fmt='table')\n",
                "true_code": "t_em = qc.query(sql = query, fmt = 'table')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 49,
                "codebleu": {
                    "codebleu": 0.5098197434900045,
                    "ngram_match_score": 0.011502783619900045,
                    "weighted_ngram_match_score": 0.02777619034011792,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7709349393844604,
                    "recall": 0.8958204984664917,
                    "F1": 0.8286990523338318,
                    "F3": 0.8815401792526245
                },
                "codebertscore_rescaled": {
                    "precision": 0.5418698787689209,
                    "recall": 0.7916409969329834,
                    "F1": 0.6573981046676636,
                    "F3": 0.763080358505249
                }
            },
            {
                "ind": 49,
                "gen_code": "## Join the tables with emission lines data for sources with significant [OII] measurements\nt_comb_em = join(t_comb_unique, t_em, keys='specid_sdss')\n",
                "true_code": "## Find sources from the common SDSS and DESI catalog that has [OII] flux\n## This part will change with SPARCL as well\n\nt_oii_comb = join(t_comb_unique, t_em, keys = ['specid_sdss'])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 53,
                "codebleu": {
                    "codebleu": 0.30009290052923016,
                    "ngram_match_score": 0.03609504567614862,
                    "weighted_ngram_match_score": 0.03927655644077209,
                    "syntax_match_score": 0.125,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8783796429634094,
                    "recall": 0.8069278001785278,
                    "F1": 0.841139018535614,
                    "F3": 0.8135455846786499
                },
                "codebertscore_rescaled": {
                    "precision": 0.7567592859268188,
                    "recall": 0.6138556003570557,
                    "F1": 0.682278037071228,
                    "F3": 0.6270911693572998
                }
            },
            {
                "ind": 51,
                "gen_code": "len(t_oii_comb)",
                "true_code": "len(t_oii_comb)",
                "error_ind": null,
                "direct_match": true,
                "fuzzy_match": 100,
                "codebleu": {
                    "codebleu": 0.5553941064735807,
                    "ngram_match_score": 0.1778279410038923,
                    "weighted_ngram_match_score": 0.04374848489043043,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 1.000000238418579,
                    "recall": 1.000000238418579,
                    "F1": 1.000000238418579,
                    "F3": 1.000000238418579
                },
                "codebertscore_rescaled": {
                    "precision": 1.0000004768371582,
                    "recall": 1.0000004768371582,
                    "F1": 1.0000004768371582,
                    "F3": 1.0000004768371582
                }
            },
            {
                "ind": 53,
                "gen_code": "print('Number of unique SDSS objects with [OII] measurements: ', len(np.unique(t_oii_comb['specid_sdss'])))\nprint('Number of unique DESI objects with [OII] measurements: ', len(np.unique(t_oii_comb['specid_desi'])))",
                "true_code": "len(np.unique(t_oii_comb['specid_sdss'])), len(np.unique(t_oii_comb['specid_desi']))",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 56,
                "codebleu": {
                    "codebleu": 0.46875,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.875,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8469472527503967,
                    "recall": 0.952720046043396,
                    "F1": 0.8967252969741821,
                    "F3": 0.9409686326980591
                },
                "codebertscore_rescaled": {
                    "precision": 0.6938945055007935,
                    "recall": 0.905440092086792,
                    "F1": 0.7934505939483643,
                    "F3": 0.8819372653961182
                }
            },
            {
                "ind": 56,
                "gen_code": "## Extracting identifiers for SDSS and DESI\nsdss_ids = np.array(t_oii_comb['specid_sdss'])\ndesi_ids = np.array(t_oii_comb['specid_desi'])",
                "true_code": "## Unique identifiers for SDSS and DESI\nids_sdss = [str(idx) for idx in t_oii_comb['sparcl_id_sdss'].data]\nids_desi = [str(idx) for idx in t_oii_comb['sparcl_id_desi'].data]",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 66,
                "codebleu": {
                    "codebleu": 0.2507008507613308,
                    "ngram_match_score": 0.17576720371825974,
                    "weighted_ngram_match_score": 0.18793845496616127,
                    "syntax_match_score": 0.21052631578947367,
                    "dataflow_match_score": 0.42857142857142855
                },
                "codebertscore": {
                    "precision": 0.9199016094207764,
                    "recall": 0.8608537912368774,
                    "F1": 0.8893987536430359,
                    "F3": 0.86641526222229
                },
                "codebertscore_rescaled": {
                    "precision": 0.8398032188415527,
                    "recall": 0.7217075824737549,
                    "F1": 0.7787975072860718,
                    "F3": 0.7328305244445801
                }
            },
            {
                "ind": 58,
                "gen_code": "## Retrieve the spectra for SDSS and DESI sources using SPARCL client\n\nspec_sdss = client.retrieve(attributes=['wavelength', 'flux', 'ivar', 'model', 'sparcl_id'],\n                            constraints={'sparcl_id': ids_sdss},\n                            limit = len(ids_sdss))\n\nspec_desi = client.retrieve(attributes=['wavelength', 'flux', 'ivar', 'model', 'sparcl_id'],\n                            constraints={'sparcl_id': ids_desi},\n                            limit = len(ids_desi))",
                "true_code": "## Use client.retrive for spectra\n## This retrieves all the 89 spectra at once\n\nsel = ['wavelength', 'flux', 'ivar', 'model', 'sparcl_id']\n\nspec_sdss = client.retrieve(uuid_list=ids_sdss, include = sel)\nspec_desi = client.retrieve(uuid_list=ids_desi, include = sel)",
                "error_ind": 58,
                "direct_match": false,
                "fuzzy_match": 16,
                "codebleu": {
                    "codebleu": 0.2603675026993852,
                    "ngram_match_score": 0.04379353325367252,
                    "weighted_ngram_match_score": 0.049850390587346464,
                    "syntax_match_score": 0.34782608695652173,
                    "dataflow_match_score": 0.6
                },
                "codebertscore": {
                    "precision": 0.8369099497795105,
                    "recall": 0.8222536444664001,
                    "F1": 0.8295170664787292,
                    "F3": 0.8236961960792542
                },
                "codebertscore_rescaled": {
                    "precision": 0.673819899559021,
                    "recall": 0.6445072889328003,
                    "F1": 0.6590341329574585,
                    "F3": 0.6473923921585083
                }
            },
            {
                "ind": 60,
                "gen_code": "# Reordering of spectra lists to ensure alignment with the original galaxy table\nspec_sdss_sorted = sorted(spec_sdss, key=lambda x: ids_sdss.index(str(x['sparcl_id'])))\nspec_desi_sorted = sorted(spec_desi, key=lambda x: ids_desi.index(str(x['sparcl_id'])))",
                "true_code": "## Reorder the records to match the original table\n\nres_sdss = spec_sdss.reorder(ids_sdss)\nres_desi = spec_desi.reorder(ids_desi)",
                "error_ind": 60,
                "direct_match": false,
                "fuzzy_match": 8,
                "codebleu": {
                    "codebleu": 0.21564480400709823,
                    "ngram_match_score": 0.021084454569051277,
                    "weighted_ngram_match_score": 0.03467657964115989,
                    "syntax_match_score": 0.18181818181818182,
                    "dataflow_match_score": 0.625
                },
                "codebertscore": {
                    "precision": 0.8015918135643005,
                    "recall": 0.875877320766449,
                    "F1": 0.8370897173881531,
                    "F3": 0.8678349256515503
                },
                "codebertscore_rescaled": {
                    "precision": 0.6031836271286011,
                    "recall": 0.751754641532898,
                    "F1": 0.6741794347763062,
                    "F3": 0.7356698513031006
                }
            },
            {
                "ind": 62,
                "gen_code": "## Rest-frame spectra function\n\ndef sp_restframe(spec, redshift, observed=False):\n    \"\"\"\n    Function to return the spectra of galaxies in their restframe. Default in the restframe.\n    \n    Parameters\n    ----------\n    spec: SPARCL record\n        Contains the spectra for a given source.\n    \n    redshift: float\n        Spectroscopic redshift for the source\n    \n    observed: bool\n        If True, returns the observed frame spectra.\n\n    Returns\n    -------\n    wave_unred : ndarray\n        de-redshifted/rest frame wavelengths\n    \n    flux_unred_unred : ndarray\n        de-redshifted/rest frame fluxes\n    \n    ivar_unred : ndarray\n        de-redshifted/rest frame inverse variance\n    \n    \"\"\"\n    \n    z = 1/(1.+redshift)\n    wave_obs = np.array(spec['wavelength'].data)\n    flux_obs = np.array(spec['flux'].data)\n    ivar_obs = np.array(spec['ivar'].data)\n\n    if observed:\n        return wave_obs, flux_obs, ivar_obs\n    \n    wave_unred = wave_obs * z\n    flux_unred = flux_obs / z\n    ivar_unred = ivar_obs * z**2\n    \n    return wave_unred, flux_unred, ivar_unred",
                "true_code": "def get_restframe_spectra(sparcl_rec, z, rest_frame = True):\n    \"\"\"\n    Function to extract the spectra from a given SPARCL record\n    \n    Parameters\n    ----------\n    sparcl_rec : dict\n        SPARCL record of a given object\n        \n    z : float\n        Redshift of the object\n        \n    rest_frame : bool\n        Whether or not to return the rest-frame spectra.\n        Default is True.\n        \n    Returns \n    -------\n    wavelength : array\n        Wavelength array of the spectra. \n        Returns the rest-frame values if rest_frame = True\n    \n    flux : array\n        Flux array of the spectra. \n        Returns the rest-frame values if rest_frame = True\n        \n    ivar : array\n        Inverse variance array of the spectra. \n        Returns the rest-frame values if rest_frame = True\n    \"\"\"\n    \n    wavelength = sparcl_rec.wavelength\n    flux = sparcl_rec.flux\n    ivar = sparcl_rec.ivar\n    \n    if (rest_frame == True):\n        wavelength = wavelength/(1+z)\n        flux = flux*(1+z)\n        ivar = ivar/((1+z)**2)\n    \n    return (wavelength, flux, ivar)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.15702601079159606,
                    "ngram_match_score": 0.023469224184846812,
                    "weighted_ngram_match_score": 0.02355373790045629,
                    "syntax_match_score": 0.08108108108108109,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.7978911995887756,
                    "recall": 0.8488830924034119,
                    "F1": 0.8225976824760437,
                    "F3": 0.8434925079345703
                },
                "codebertscore_rescaled": {
                    "precision": 0.5957823991775513,
                    "recall": 0.6977661848068237,
                    "F1": 0.6451953649520874,
                    "F3": 0.6869850158691406
                }
            },
            {
                "ind": 64,
                "gen_code": "len(t_oii_comb)",
                "true_code": "len(t_oii_comb)",
                "error_ind": null,
                "direct_match": true,
                "fuzzy_match": 100,
                "codebleu": {
                    "codebleu": 0.5553941064735807,
                    "ngram_match_score": 0.1778279410038923,
                    "weighted_ngram_match_score": 0.04374848489043043,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 1.000000238418579,
                    "recall": 1.000000238418579,
                    "F1": 1.000000238418579,
                    "F3": 1.000000238418579
                },
                "codebertscore_rescaled": {
                    "precision": 1.0000004768371582,
                    "recall": 1.0000004768371582,
                    "F1": 1.0000004768371582,
                    "F3": 1.0000004768371582
                }
            },
            {
                "ind": 66,
                "gen_code": "## Calculate the [OII] line flux and its error and the associated SNR\n\n## [OII]3726\nflux_oii_3726 = t_oii_comb['flux_oii_3726']\nflux_oii_3726_err = t_oii_comb['flux_oii_3726_err']\n\n## [OII]3728\nflux_oii_3728 = t_oii_comb['flux_oii_3728']\nflux_oii_3728_err = t_oii_comb['flux_oii_3728_err']\n\n## Total flux and error\nflux_oii_tot = flux_oii_3726 + flux_oii_3728\nflux_oii_tot_err = np.sqrt(flux_oii_3726_err**2 + flux_oii_3728_err**2)\n\n## SNR\nsnr_oii = flux_oii_tot / flux_oii_tot_err\n\n## Index with max SNR\nmax_snr_idx = np.argmax(snr_oii)",
                "true_code": "total_oii_flux = t_oii_comb['flux_oii_3726'].data + t_oii_comb['flux_oii_3728'].data\ntotal_oii_err = np.sqrt((t_oii_comb['flux_oii_3726_err'].data**2)+(t_oii_comb['flux_oii_3728_err'].data**2))\noii_snr = total_oii_flux/total_oii_err\n\n## Select source with the maximum [OII] flux SNR \nii = np.argmax(oii_snr)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.2503230723123424,
                    "ngram_match_score": 0.005633294412316096,
                    "weighted_ngram_match_score": 0.01565899483705372,
                    "syntax_match_score": 0.5,
                    "dataflow_match_score": 0.48
                },
                "codebertscore": {
                    "precision": 0.8712073564529419,
                    "recall": 0.8928483128547668,
                    "F1": 0.8818950057029724,
                    "F3": 0.8906359672546387
                },
                "codebertscore_rescaled": {
                    "precision": 0.7424147129058838,
                    "recall": 0.7856966257095337,
                    "F1": 0.7637900114059448,
                    "F3": 0.7812719345092773
                }
            },
            {
                "ind": 68,
                "gen_code": "## Extract the rest-frame spectra for SDSS and DESI datasets\n\nz = t_oii_comb['redshift_sdss'].data[ii]\n\n## For SDSS\nwave_sdss, flux_sdss, ivar_sdss = get_restframe_spectra(res_sdss.records[ii], z, rest_frame=True)\n\n## For DESI\nwave_desi, flux_desi, ivar_desi = get_restframe_spectra(res_desi.records[ii], z, rest_frame=True)",
                "true_code": "lam_desi, flux_desi, ivar_desi = get_restframe_spectra(res_desi.records[ii], t_oii_comb['redshift_desi'].data[ii], rest_frame = True)\nlam_sdss, flux_sdss, ivar_sdss = get_restframe_spectra(res_sdss.records[ii], t_oii_comb['redshift_sdss'].data[ii], rest_frame = True)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 42,
                "codebleu": {
                    "codebleu": 0.3904408051342779,
                    "ngram_match_score": 0.1448218930239774,
                    "weighted_ngram_match_score": 0.27694132751313416,
                    "syntax_match_score": 0.64,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.8733024597167969,
                    "recall": 0.9266666769981384,
                    "F1": 0.899193525314331,
                    "F3": 0.9210385680198669
                },
                "codebertscore_rescaled": {
                    "precision": 0.7466049194335938,
                    "recall": 0.8533333539962769,
                    "F1": 0.7983870506286621,
                    "F3": 0.8420771360397339
                }
            },
            {
                "ind": 70,
                "gen_code": "## Calculate errors from inverse variance\nflux_err_desi = np.sqrt(1/ivar_desi)\nflux_err_sdss = np.sqrt(1/ivar_sdss)",
                "true_code": "err_sdss = np.sqrt(1/ivar_sdss)\nerr_desi = np.sqrt(1/ivar_desi)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 35,
                "codebleu": {
                    "codebleu": 0.5432589561698884,
                    "ngram_match_score": 0.05094110796339642,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8855188488960266,
                    "recall": 0.9403367042541504,
                    "F1": 0.9121049046516418,
                    "F3": 0.9345513582229614
                },
                "codebertscore_rescaled": {
                    "precision": 0.7710376977920532,
                    "recall": 0.8806734085083008,
                    "F1": 0.8242098093032837,
                    "F3": 0.8691027164459229
                }
            },
            {
                "ind": 72,
                "gen_code": "plt.figure(figsize=(16, 8))\nplt.title(f'[OII]-rich Galaxy Spectrum Comparison\\nSpec ID SDSS: {t_oii_comb[\"specid_sdss\"][ii]} | Spec ID DESI: {t_oii_comb[\"specid_desi\"][ii]}', fontsize=18)\n\n# Plot DESI spectra\nplt.plot(lam_desi, flux_desi, 'k-', label='DESI')\nplt.fill_between(lam_desi, flux_desi - err_desi, flux_desi + err_desi, color='gray', alpha=0.3)\n\n# Plot SDSS spectra\nplt.plot(lam_sdss, flux_sdss, 'r-', label='SDSS')\nplt.fill_between(lam_sdss, flux_sdss - err_sdss, flux_sdss + err_sdss, color='red', alpha=0.3)\n\nplt.xlabel('Rest-Frame Wavelength [\u00c5]')\nplt.ylabel(r'Flux [$10^{-17}$ erg s$^{-1}$ cm$^{-2}$ \u00c5$^{-1}$]')\nplt.legend()\nplt.grid(True)\nplt.xlim(3600, 9800)  # Limiting to a common relevant range for comparison\nplt.show()",
                "true_code": "plt.figure(figsize = (20, 8))\n\nplt.plot(lam_desi, flux_desi, color = 'k', label = 'DESI-EDR')\nplt.plot(lam_sdss, flux_sdss, color = 'r', label = 'SDSS')\nplt.xlim([3600, 7000])\nplt.ylim([-5, 100])\nplt.xlabel('$\\lambda~[\\AA]$')\nplt.ylabel('$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~{\\AA}^{-1}]$')\nplt.legend(loc = 'upper left')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.4059694510859363,
                    "ngram_match_score": 0.00797747599484009,
                    "weighted_ngram_match_score": 0.019746482195058836,
                    "syntax_match_score": 0.5961538461538461,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7792953848838806,
                    "recall": 0.8406542539596558,
                    "F1": 0.8088127970695496,
                    "F3": 0.8340869545936584
                },
                "codebertscore_rescaled": {
                    "precision": 0.5585907697677612,
                    "recall": 0.6813085079193115,
                    "F1": 0.6176255941390991,
                    "F3": 0.6681739091873169
                }
            },
            {
                "ind": 74,
                "gen_code": "plt.figure(figsize = (10, 6))\n\nplt.plot(lam_desi, flux_desi, color = 'k', label = 'DESI-EDR')\nplt.fill_between(lam_desi, flux_desi - err_desi, flux_desi + err_desi, color='gray', alpha=0.3)\nplt.plot(lam_sdss, flux_sdss, color = 'r', label = 'SDSS-DR16')\nplt.fill_between(lam_sdss, flux_sdss - err_sdss, flux_sdss + err_sdss, color='lightcoral', alpha=0.3)\n\nplt.axvline(x=3726, color='r', linestyle='--', label='[OII] 3726')\nplt.axvline(x=3728, color='r', linestyle='--', label='[OII] 3728')\n\nplt.xlim([3700, 3750])\nplt.ylim([-5, 100])\n\nplt.xlabel('$\\lambda_{rest}~[\\AA]$')\nplt.ylabel('$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~\\AA^{-1}]$')\nplt.legend(loc = 'upper left')\nplt.title('[OII] Doublet Region')\nplt.show()",
                "true_code": "fig, axs = plt.subplots(1,2,figsize = (20,6), sharex = True, sharey = True)\n\naxs[0].plot(lam_sdss, flux_sdss, color = 'k', lw = 2.0)\naxs[0].fill_between(lam_sdss, flux_sdss-err_sdss, flux_sdss+err_sdss, color = 'grey', alpha = 0.5)\naxs[1].plot(lam_desi, flux_desi, color = 'k', lw = 2.0)\naxs[1].fill_between(lam_desi, flux_desi-err_desi, flux_desi+err_desi, color = 'grey', alpha = 0.5)\naxs[0].axvline(3727.092, color = 'r', ls = ':')\naxs[0].axvline(3729.875, color = 'r', ls = ':')\naxs[1].axvline(3727.092, color = 'r', ls = ':')\naxs[1].axvline(3729.875, color = 'r', ls = ':')\n\naxs[0].set(xlabel = '$\\lambda~[\\AA]$', ylabel = '$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~{\\AA}^{-1}]$', title = 'SDSS')\naxs[1].set(xlim = [3710,3745], ylim = [-2,100], title = 'DESI-EDR', xlabel = '$\\lambda~[\\AA]$', ylabel = '$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~{\\AA}^{-1}]$')\n\nplt.show()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 17,
                "codebleu": {
                    "codebleu": 0.21174508235730444,
                    "ngram_match_score": 0.03825442801038049,
                    "weighted_ngram_match_score": 0.04310846800479366,
                    "syntax_match_score": 0.5084745762711864,
                    "dataflow_match_score": 0.2571428571428571
                },
                "codebertscore": {
                    "precision": 0.8680710196495056,
                    "recall": 0.8517873883247375,
                    "F1": 0.859852135181427,
                    "F3": 0.8533881902694702
                },
                "codebertscore_rescaled": {
                    "precision": 0.7361420392990112,
                    "recall": 0.7035747766494751,
                    "F1": 0.719704270362854,
                    "F3": 0.7067763805389404
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.06060606060606061,
            "fuzzy_match": 35.15151515151515,
            "codebleu": 0.3682757486483398,
            "syntax_match_score": 0.5990571362334143,
            "codebertscore": 0.8593345284461975,
            "codebertscore_rescaled": 0.718669056892395,
            "code_success": 0.7878787878787878,
            "total_code_cell_count": 33
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/02_GettingStartedWithDataLab_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/01_GettingStartedWithDataLab/02_GettingStartedWithDataLab.ipynb",
            "prefix": "gettingstarted_2"
        },
        "model": {
            "name": "gpt-4o",
            "model": "gpt-4o",
            "library": "OA"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "metadata = {\n    \"notebook_id\": \"astro_analysis_01\",\n    \"author\": \"Jane Doe\",\n    \"version\": \"1.0\",\n    \"datasets\": [\"dataset_2023_star_catalog\", \"dataset_2023_exoplanet\"],\n    \"keywords\": [\"astronomy\", \"stars\", \"exoplanets\", \"analysis\"]\n}",
                "true_code": "__nbid__ = '0002'\n__author__ = 'Knut Olsen <knut.olsen@noirlab.edu>, Robert Nikutta <robert.nikutta@noirlab.edu>'\n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['smash_dr1', 'des_dr1']\n__keywords__ = ['tutorial', 'query', 'image cutout', 'globular cluster', 'SIA']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.289353727146429,
                    "ngram_match_score": 0.0060155481087435176,
                    "weighted_ngram_match_score": 0.006471824245088331,
                    "syntax_match_score": 0.4782608695652174,
                    "dataflow_match_score": 0.6666666666666666
                },
                "codebertscore": {
                    "precision": 0.7669563889503479,
                    "recall": 0.7099224328994751,
                    "F1": 0.737338125705719,
                    "F3": 0.7152413129806519
                },
                "codebertscore_rescaled": {
                    "precision": 0.5339127779006958,
                    "recall": 0.4198448657989502,
                    "F1": 0.474676251411438,
                    "F3": 0.4304826259613037
                }
            },
            {
                "ind": 10,
                "gen_code": "# Authentication setup\ntoken = ac.login(input(\"Enter your Data Lab username: \"), getpass(\"Enter your Data Lab password: \"))\nprint(\"Authentication token obtained.\")",
                "true_code": "#token = ac.login(input(\"Enter user name: (+ENTER) \"),getpass(\"Enter password: (+ENTER) \"))\nac.whoAmI()",
                "error_ind": 10,
                "direct_match": false,
                "fuzzy_match": 57,
                "codebleu": {
                    "codebleu": 0.3179060171629163,
                    "ngram_match_score": 0.024218026052883736,
                    "weighted_ngram_match_score": 0.04740604259878138,
                    "syntax_match_score": 0.2,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.8333816528320312,
                    "recall": 0.8299136757850647,
                    "F1": 0.8316440582275391,
                    "F3": 0.8302591443061829
                },
                "codebertscore_rescaled": {
                    "precision": 0.6667633056640625,
                    "recall": 0.6598273515701294,
                    "F1": 0.6632881164550781,
                    "F3": 0.6605182886123657
                }
            },
            {
                "ind": 12,
                "gen_code": "qc.schema()",
                "true_code": "print(qc.schema())",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 76,
                "codebleu": {
                    "codebleu": 0.35714285714285715,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.42857142857142855,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.9438415169715881,
                    "recall": 0.895152747631073,
                    "F1": 0.9188525676727295,
                    "F3": 0.8997944593429565
                },
                "codebertscore_rescaled": {
                    "precision": 0.8876830339431763,
                    "recall": 0.790305495262146,
                    "F1": 0.837705135345459,
                    "F3": 0.7995889186859131
                }
            },
            {
                "ind": 14,
                "gen_code": "print(qc.schema('smash_dr1'))",
                "true_code": "print(qc.schema('smash_dr1'))",
                "error_ind": null,
                "direct_match": true,
                "fuzzy_match": 100,
                "codebleu": {
                    "codebleu": 0.5553941064735807,
                    "ngram_match_score": 0.1778279410038923,
                    "weighted_ngram_match_score": 0.04374848489043043,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 1.000000238418579,
                    "recall": 1.000000238418579,
                    "F1": 1.000000238418579,
                    "F3": 1.000000238418579
                },
                "codebertscore_rescaled": {
                    "precision": 1.0000004768371582,
                    "recall": 1.0000004768371582,
                    "F1": 1.0000004768371582,
                    "F3": 1.0000004768371582
                }
            },
            {
                "ind": 16,
                "gen_code": "print(qc.schema('smash_dr1', 'object'))",
                "true_code": "print(qc.schema('smash_dr1.object'))",
                "error_ind": 16,
                "direct_match": false,
                "fuzzy_match": 93,
                "codebleu": {
                    "codebleu": 0.3125,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.25,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.9899522662162781,
                    "recall": 0.9899522662162781,
                    "F1": 0.9899522662162781,
                    "F3": 0.9899522066116333
                },
                "codebertscore_rescaled": {
                    "precision": 0.9799045324325562,
                    "recall": 0.9799045324325562,
                    "F1": 0.9799045324325562,
                    "F3": 0.9799044132232666
                }
            },
            {
                "ind": 18,
                "gen_code": "query = \"SELECT * FROM tbl_stat WHERE tbl_name = 'smash_dr1.object'\"\nresult = qc.query(sql=query, fmt='table')\nprint(result)",
                "true_code": "#query = \"SELECT COUNT(ra) FROM phat_v2.phot_mod\" # SLOW\nquery = \"SELECT * FROM tbl_stat WHERE schema='smash_dr1' AND tbl_name='object'\" # Retrieve useful stats, quickly",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 47,
                "codebleu": {
                    "codebleu": 0.5629927203931788,
                    "ngram_match_score": 0.24272142396287774,
                    "weighted_ngram_match_score": 0.25924945760983753,
                    "syntax_match_score": 0.75,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8674073815345764,
                    "recall": 0.8302770256996155,
                    "F1": 0.848436176776886,
                    "F3": 0.833846390247345
                },
                "codebertscore_rescaled": {
                    "precision": 0.7348147630691528,
                    "recall": 0.660554051399231,
                    "F1": 0.696872353553772,
                    "F3": 0.6676927804946899
                }
            },
            {
                "ind": 20,
                "gen_code": "result = qc.query(sql=query, fmt='pandas')\nprint(result)",
                "true_code": "info = qc.query(sql=query) # by default the result is a CSV formatted string",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 44,
                "codebleu": {
                    "codebleu": 0.27897316384004234,
                    "ngram_match_score": 0.012900038794401852,
                    "weighted_ngram_match_score": 0.017278330851481758,
                    "syntax_match_score": 0.2857142857142857,
                    "dataflow_match_score": 0.8
                },
                "codebertscore": {
                    "precision": 0.8249256610870361,
                    "recall": 0.7912601828575134,
                    "F1": 0.8077422380447388,
                    "F3": 0.7945026159286499
                },
                "codebertscore_rescaled": {
                    "precision": 0.6498513221740723,
                    "recall": 0.5825203657150269,
                    "F1": 0.6154844760894775,
                    "F3": 0.5890052318572998
                }
            },
            {
                "ind": 22,
                "gen_code": "print(info)",
                "true_code": "print(info)",
                "error_ind": null,
                "direct_match": true,
                "fuzzy_match": 100,
                "codebleu": {
                    "codebleu": 0.5553941064735807,
                    "ngram_match_score": 0.1778279410038923,
                    "weighted_ngram_match_score": 0.04374848489043043,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 1.0,
                    "recall": 1.0,
                    "F1": 1.0,
                    "F3": 1.0
                },
                "codebertscore_rescaled": {
                    "precision": 1.0,
                    "recall": 1.0,
                    "F1": 1.0,
                    "F3": 1.0
                }
            },
            {
                "ind": 24,
                "gen_code": "query = \"SELECT * FROM smash_dr1.object LIMIT 10\"\nresult = qc.query(sql=query)",
                "true_code": "query = \"SELECT * FROM smash_dr1.object LIMIT 10\"\nresult = qc.query(sql=query) # by default the result is a CSV formatted string",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 76,
                "codebleu": {
                    "codebleu": 0.7166996887753806,
                    "ngram_match_score": 0.40289032152913296,
                    "weighted_ngram_match_score": 0.4639084335723894,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9900693297386169,
                    "recall": 0.8755923509597778,
                    "F1": 0.9293186664581299,
                    "F3": 0.8858348727226257
                },
                "codebertscore_rescaled": {
                    "precision": 0.9801386594772339,
                    "recall": 0.7511847019195557,
                    "F1": 0.8586373329162598,
                    "F3": 0.7716697454452515
                }
            },
            {
                "ind": 26,
                "gen_code": "print(type(result))\nprint(result[:1000])",
                "true_code": "print(type(result))\nprint(result[:1000]) # print just the first 1000 characters of the returned string",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 56,
                "codebleu": {
                    "codebleu": 0.5085373427625461,
                    "ngram_match_score": 0.0012923506022069113,
                    "weighted_ngram_match_score": 0.03285702044797773,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9565921425819397,
                    "recall": 0.7972729206085205,
                    "F1": 0.8696963787078857,
                    "F3": 0.8107763528823853
                },
                "codebertscore_rescaled": {
                    "precision": 0.9131842851638794,
                    "recall": 0.594545841217041,
                    "F1": 0.7393927574157715,
                    "F3": 0.6215527057647705
                }
            },
            {
                "ind": 28,
                "gen_code": "import pandas as pd\n\ndf_result = convert(result, to='pandas')\nprint(df_result.head())",
                "true_code": "df = convert(result,'pandas')\ndf.head()",
                "error_ind": 28,
                "direct_match": false,
                "fuzzy_match": 63,
                "codebleu": {
                    "codebleu": 0.2749909663317466,
                    "ngram_match_score": 0.023980296761827107,
                    "weighted_ngram_match_score": 0.07598356856515925,
                    "syntax_match_score": 0.4,
                    "dataflow_match_score": 0.6
                },
                "codebertscore": {
                    "precision": 0.8627502918243408,
                    "recall": 0.9399382472038269,
                    "F1": 0.8996917009353638,
                    "F3": 0.9316034317016602
                },
                "codebertscore_rescaled": {
                    "precision": 0.7255005836486816,
                    "recall": 0.8798764944076538,
                    "F1": 0.7993834018707275,
                    "F3": 0.8632068634033203
                }
            },
            {
                "ind": 30,
                "gen_code": "df_direct = qc.query(sql=query, fmt='pandas')\ndf_direct.head()",
                "true_code": "query = \"SELECT * FROM smash_dr1.object LIMIT 10\"\ndf = qc.query(sql=query,fmt='pandas')\ndf.head()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 64,
                "codebleu": {
                    "codebleu": 0.3356956175435426,
                    "ngram_match_score": 0.013249284136531224,
                    "weighted_ngram_match_score": 0.017033186037639283,
                    "syntax_match_score": 0.8125,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.9154742360115051,
                    "recall": 0.8217536807060242,
                    "F1": 0.8660858869552612,
                    "F3": 0.8302533030509949
                },
                "codebertscore_rescaled": {
                    "precision": 0.8309484720230103,
                    "recall": 0.6435073614120483,
                    "F1": 0.7321717739105225,
                    "F3": 0.6605066061019897
                }
            },
            {
                "ind": 33,
                "gen_code": "# define coordinates for NGC 288\nra_n288, dec_n288 = 13.1888, -26.5825 # in degrees\n\n# define field of view (FOV) in degrees\nfov = 0.1 # 6 arcmin x 6 arcmin\n\n# perform SIA query to get images overlapping the coordinates with specified FOV\nimg_table = svc.search((ra_n288, dec_n288), fov)\n\n# Show the first few rows of the search results\nimg_table.to_table().show_in_notebook()",
                "true_code": "# NGC 288 (a globular cluster)\nra = 13.19     # in decimal degrees\ndec = -26.59   # in decimal degrees\n\nfov = 13/60  # image cutout field of view (in degrees; here 13 arminutes = 0.22 degrees)\n\nimgTable = svc.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()  # uses declination correction",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.18273433619994295,
                    "ngram_match_score": 0.036858436589931105,
                    "weighted_ngram_match_score": 0.04995652495702264,
                    "syntax_match_score": 0.2962962962962963,
                    "dataflow_match_score": 0.34782608695652173
                },
                "codebertscore": {
                    "precision": 0.8025453686714172,
                    "recall": 0.827019214630127,
                    "F1": 0.8145985007286072,
                    "F3": 0.8245047926902771
                },
                "codebertscore_rescaled": {
                    "precision": 0.6050907373428345,
                    "recall": 0.6540384292602539,
                    "F1": 0.6291970014572144,
                    "F3": 0.6490095853805542
                }
            },
            {
                "ind": 35,
                "gen_code": "imgTable.pprint(max_lines=5, max_width=1000)",
                "true_code": "print(type(imgTable))\nimgTable",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 24,
                "codebleu": {
                    "codebleu": 0.25,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.7381107807159424,
                    "recall": 0.8311913013458252,
                    "F1": 0.7818905711174011,
                    "F3": 0.820840060710907
                },
                "codebertscore_rescaled": {
                    "precision": 0.47622156143188477,
                    "recall": 0.6623826026916504,
                    "F1": 0.5637811422348022,
                    "F3": 0.641680121421814
                }
            },
            {
                "ind": 37,
                "gen_code": "filteredTable = imgTable[(imgTable['obs_bandpass'] == 'g') & (imgTable['prod_type'] == 'image')]\nfilteredTable",
                "true_code": "# boolean selection for just g-band images\nsel0 = imgTable['obs_bandpass'] == 'g'\n\n# logically add selections for 'Stack' and 'image' product type\nsel = sel0 & ((imgTable['proctype'] == 'Stack') & (imgTable['prodtype'] == 'image')) # basic selection\n\n# filter the above results table\nTable = imgTable[sel] # select\nTable",
                "error_ind": 37,
                "direct_match": false,
                "fuzzy_match": 42,
                "codebleu": {
                    "codebleu": 0.24902169669044277,
                    "ngram_match_score": 0.0006677106948826235,
                    "weighted_ngram_match_score": 0.005034460682273033,
                    "syntax_match_score": 0.6153846153846154,
                    "dataflow_match_score": 0.375
                },
                "codebertscore": {
                    "precision": 0.8724380731582642,
                    "recall": 0.7637807726860046,
                    "F1": 0.8145016431808472,
                    "F3": 0.7734131813049316
                },
                "codebertscore_rescaled": {
                    "precision": 0.7448761463165283,
                    "recall": 0.5275615453720093,
                    "F1": 0.6290032863616943,
                    "F3": 0.5468263626098633
                }
            },
            {
                "ind": 39,
                "gen_code": "# Extract the download URL for the first matching image\nimage_url = Table['access_url'][0]\nprint(image_url)",
                "true_code": "row = Table[0]\nurl = row['access_url'] # get the download URL\nprint(url)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 36,
                "codebleu": {
                    "codebleu": 0.2290917882685229,
                    "ngram_match_score": 0.08032276872815308,
                    "weighted_ngram_match_score": 0.09578464408619825,
                    "syntax_match_score": 0.45454545454545453,
                    "dataflow_match_score": 0.2857142857142857
                },
                "codebertscore": {
                    "precision": 0.884028434753418,
                    "recall": 0.9080047607421875,
                    "F1": 0.8958562016487122,
                    "F3": 0.9055488109588623
                },
                "codebertscore_rescaled": {
                    "precision": 0.7680568695068359,
                    "recall": 0.816009521484375,
                    "F1": 0.7917124032974243,
                    "F3": 0.8110976219177246
                }
            },
            {
                "ind": 41,
                "gen_code": "filename = utils.data.download_file(url, cache=True)\nimage_data = io.fits.getdata(filename)",
                "true_code": "gimage = io.fits.getdata(utils.data.download_file(url,cache=True,show_progress=False,timeout=120))",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 54,
                "codebleu": {
                    "codebleu": 0.28325791079503454,
                    "ngram_match_score": 0.033031643180138064,
                    "weighted_ngram_match_score": 0.10000000000000002,
                    "syntax_match_score": 0.35714285714285715,
                    "dataflow_match_score": 0.6428571428571429
                },
                "codebertscore": {
                    "precision": 0.9106526374816895,
                    "recall": 0.8737847805023193,
                    "F1": 0.8918378949165344,
                    "F3": 0.8773367404937744
                },
                "codebertscore_rescaled": {
                    "precision": 0.8213052749633789,
                    "recall": 0.7475695610046387,
                    "F1": 0.7836757898330688,
                    "F3": 0.7546734809875488
                }
            },
            {
                "ind": 43,
                "gen_code": "from astropy.visualization import astropy_mpl_style, AsinhStretch, ImageNormalize\nplt.style.use(astropy_mpl_style)\n\nnorm = ImageNormalize(stretch=AsinhStretch())\nplt.imshow(gimage, cmap='gray', origin='lower', norm=norm)\nplt.colorbar()\nplt.title('NGC 288 Globular Cluster (g-band)')\nplt.xlabel('X Pixel')\nplt.ylabel('Y Pixel')\nplt.show()",
                "true_code": "fig = plt.subplots(figsize=(10,10))\nplt.imshow(np.arcsinh(gimage),cmap='gray',norm=matplotlib.colors.Normalize(vmin=0))\nplt.axis('off');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.28764748552551256,
                    "ngram_match_score": 0.007575731225158965,
                    "weighted_ngram_match_score": 0.05372849659117709,
                    "syntax_match_score": 0.4642857142857143,
                    "dataflow_match_score": 0.625
                },
                "codebertscore": {
                    "precision": 0.7580092549324036,
                    "recall": 0.7978674173355103,
                    "F1": 0.7774277329444885,
                    "F3": 0.7936939597129822
                },
                "codebertscore_rescaled": {
                    "precision": 0.5160185098648071,
                    "recall": 0.5957348346710205,
                    "F1": 0.554855465888977,
                    "F3": 0.5873879194259644
                }
            },
            {
                "ind": 45,
                "gen_code": "def get_deepest_image_stack(ra, dec, fov, band):\n    \"\"\"\n    Query and retrieve the deepest image stack for a specific band and sky location.\n        \n    Parameters:\n    ra : float\n        Right Ascension in decimal degrees.\n    dec : float\n        Declination in decimal degrees.\n    fov : float\n        Field of view in degrees.\n    band : str\n        Photometric band (e.g., 'g','r','i').\n        \n    Returns:\n    data : numpy.ndarray\n        The image data array.\n    \"\"\"\n    # Define the SIAService access URL\n    DEF_ACCESS_URL = \"https://datalab.noirlab.edu/sia/des_dr1\"\n    svc = sia.SIAService(DEF_ACCESS_URL)\n\n    # Search for images with given parameters\n    imgTable = svc.search((ra, dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n    \n    # Filter for specific band and best available image stack in the desired band\n    sel_band = (imgTable['obs_bandpass'] == band)\n    sel_stack = (imgTable['proctype'] == 'Stack') & (imgTable['prodtype'] == 'image')\n    selected_images = imgTable[sel_band & sel_stack]\n    \n    if len(selected_images) == 0:\n        raise ValueError(f\"No suitable image stacks found for band {band}\")\n    \n    # Choose the first image that meets the criteria\n    row = selected_images[0]\n\n    # Download the image using the access URL\n    url = row['access_url']\n    data = io.fits.getdata(utils.data.download_file(url, cache=True, show_progress=False, timeout=120))\n\n    return data\n",
                "true_code": "# A function to download the deepest available stacked images\ndef download_deep_stack(ra,dec,fov=0.1,band='g'):\n    imgTable = svc.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n    print(\"The full image list contains\", len(imgTable), \"entries\")\n\n    # apply image seletion criteria\n    sel0 = imgTable['obs_bandpass'] == band\n    sel = sel0 & ((imgTable['proctype'] == 'Stack') & (imgTable['prodtype'] == 'image')) # basic selection\n    Table = imgTable[sel] # select\n\n    # if more than one image matches our desired criteria\n    if (len(Table)>0):\n        row = Table[np.argmax(Table['exptime'].data.data.astype('float'))] # pick image with longest exposure time\n        url = row['access_url'] # get the download URL\n        print ('Downloading deepest stacked image...')\n        image = io.fits.getdata(utils.data.download_file(url,cache=True,show_progress=False,timeout=120))\n        print(url)\n\n    # if no images match our criteria\n    else:\n        print ('No image available.')\n        image = None\n        \n    print()\n    return image",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 19,
                "codebleu": {
                    "codebleu": 0.31654956863284667,
                    "ngram_match_score": 0.05222464659699836,
                    "weighted_ngram_match_score": 0.07790249186325206,
                    "syntax_match_score": 0.6036036036036037,
                    "dataflow_match_score": 0.5324675324675324
                },
                "codebertscore": {
                    "precision": 0.7606648206710815,
                    "recall": 0.7931764125823975,
                    "F1": 0.7765805125236511,
                    "F3": 0.789800763130188
                },
                "codebertscore_rescaled": {
                    "precision": 0.5213296413421631,
                    "recall": 0.5863528251647949,
                    "F1": 0.5531610250473022,
                    "F3": 0.579601526260376
                }
            },
            {
                "ind": 47,
                "gen_code": "rimage = download_deep_stack(ra, dec, fov, band='r')\niimage = download_deep_stack(ra, dec, fov, band='i')",
                "true_code": "rimage = download_deep_stack(ra,dec,fov,band='r')\niimage = download_deep_stack(ra,dec,fov,band='i')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 97,
                "codebleu": {
                    "codebleu": 0.5432589561698884,
                    "ngram_match_score": 0.05094110796339642,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9830407500267029,
                    "recall": 0.9830407500267029,
                    "F1": 0.9830407500267029,
                    "F3": 0.9830407500267029
                },
                "codebertscore_rescaled": {
                    "precision": 0.9660815000534058,
                    "recall": 0.9660815000534058,
                    "F1": 0.9660815000534058,
                    "F3": 0.9660815000534058
                }
            },
            {
                "ind": 49,
                "gen_code": "rgb_image = make_lupton_rgb(iimage, rimage, gimage, stretch=0.5, Q=10)\nplt.figure(figsize=(15, 15))\nplt.imshow(rgb_image)\nplt.axis('off')\nplt.title('False-Color Composite of NGC 288')\nplt.show()",
                "true_code": "color_image = make_lupton_rgb(iimage, rimage, gimage, stretch=100, Q=0.1)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 50,
                "codebleu": {
                    "codebleu": 0.460004783540089,
                    "ngram_match_score": 0.1431712315455507,
                    "weighted_ngram_match_score": 0.41113361690051975,
                    "syntax_match_score": 0.2857142857142857,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7675352096557617,
                    "recall": 0.9299162030220032,
                    "F1": 0.8409589529037476,
                    "F3": 0.9106503129005432
                },
                "codebertscore_rescaled": {
                    "precision": 0.5350704193115234,
                    "recall": 0.8598324060440063,
                    "F1": 0.6819179058074951,
                    "F3": 0.8213006258010864
                }
            },
            {
                "ind": 51,
                "gen_code": "plt.figure(figsize=(10, 10))\nplt.imshow(color_image, origin='lower')\nplt.axis('off')\nplt.title(\"False-color composite image of NGC 288\")\nplt.show()",
                "true_code": "fig = plt.figure(figsize=(10,10))\nplt.imshow(color_image)\nplt.axis('off');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 61,
                "codebleu": {
                    "codebleu": 0.2555147058823529,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.6470588235294118,
                    "dataflow_match_score": 0.375
                },
                "codebertscore": {
                    "precision": 0.8716340661048889,
                    "recall": 0.9566894769668579,
                    "F1": 0.9121833443641663,
                    "F3": 0.9474442005157471
                },
                "codebertscore_rescaled": {
                    "precision": 0.7432681322097778,
                    "recall": 0.9133789539337158,
                    "F1": 0.8243666887283325,
                    "F3": 0.8948884010314941
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.09090909090909091,
            "fuzzy_match": 53.68181818181818,
            "codebleu": 0.36921188844320163,
            "syntax_match_score": 0.5604126470160532,
            "codebertscore": 0.8721652003851804,
            "codebertscore_rescaled": 0.7443304007703607,
            "code_success": 0.8181818181818182,
            "total_code_cell_count": 22
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/StarClustersGaiaDR3_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/GalacticStructure/StarClustersGaiaDR3.ipynb",
            "prefix": "gaia_3"
        },
        "model": {
            "name": "gpt-4o",
            "model": "gpt-4o",
            "library": "OA"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "__nbid__ = \"stellar01\"\n__author__ = \"Jane Doe, Astrophysics Team <j.doe@example.com>\"\n__version__ = \"20231001\"\n__datasets__ = [\"Gaia DR3\"]\n__keywords__ = [\"star clusters\", \"stars\", \"proper motions\", \"CMD\", \"quiver\", \"animations\"]",
                "true_code": "__nbid__ = '0017'\n__author__ = 'Leah Fulmer, Astro Data Lab Team <datalab@noirlab.edu>'\n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['gaia_dr3']\n__keywords__ = ['star clusters', 'stars', 'proper motions', 'parallax', 'plot:cmd', 'plot:quiver', 'plot:animation']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 28,
                "codebleu": {
                    "codebleu": 0.4416739974037165,
                    "ngram_match_score": 0.029149335476135012,
                    "weighted_ngram_match_score": 0.029213320805397576,
                    "syntax_match_score": 0.8333333333333334,
                    "dataflow_match_score": 0.875
                },
                "codebertscore": {
                    "precision": 0.8767102956771851,
                    "recall": 0.8208262324333191,
                    "F1": 0.8478484153747559,
                    "F3": 0.826092004776001
                },
                "codebertscore_rescaled": {
                    "precision": 0.7534205913543701,
                    "recall": 0.6416524648666382,
                    "F1": 0.6956968307495117,
                    "F3": 0.652184009552002
                }
            },
            {
                "ind": 10,
                "gen_code": "def login():\n    \"\"\"Function to log into Astro Data Lab\"\"\"\n    try:\n        token = ac.login(input(\"Enter your username: \"), getpass(\"Enter your password: \"))\n        if token:\n            print(\"Authentication successful.\")\n        else:\n            print(\"Authentication failed. Please try again.\")\n    except Exception as e:\n        print(f\"An error occurred during authentication: {e}\")\n\n# Uncomment the line below to login\n# login()\n\n# Uncomment the line below to verify your identity\n# print(ac.whoAmI())",
                "true_code": "#token = ac.login(input(\"Enter user name: (+ENTER) \"),getpass(\"Enter password: (+ENTER) \"))\nac.whoAmI()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.3137630290314629,
                    "ngram_match_score": 0.007646073527070139,
                    "weighted_ngram_match_score": 0.04740604259878138,
                    "syntax_match_score": 0.2,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.6746709942817688,
                    "recall": 0.8169649243354797,
                    "F1": 0.7390308976173401,
                    "F3": 0.8000902533531189
                },
                "codebertscore_rescaled": {
                    "precision": 0.3493419885635376,
                    "recall": 0.6339298486709595,
                    "F1": 0.4780617952346802,
                    "F3": 0.6001805067062378
                }
            },
            {
                "ind": 12,
                "gen_code": "# A basic test query to fetch some data from the Gaia DR3 catalog\nquery = \"\"\"\nSELECT TOP 10 source_id, ra, dec, parallax, pmra, pmdec\nFROM gaia_dr3.gaia_source\n\"\"\"\n\ntry:\n    result = qc.query(sql=query, fmt='table')\n    print(result)\nexcept Exception as e:\n    print(\"Error executing query: \", e)",
                "true_code": "# Construct query as a string\nquery = \"SELECT * FROM gaia_dr3.gaia_source LIMIT 1\"\n\n# Submit query\nresponse = qc.query(sql=query, fmt='csv')\n\n# Convert output string to to a pandas DataFrame\ndf_init = convert(response,'pandas')\n\n# To view the available columns, include the following command\ndf_init.columns",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 15,
                "codebleu": {
                    "codebleu": 0.3945141174351806,
                    "ngram_match_score": 0.017839797286123647,
                    "weighted_ngram_match_score": 0.018863288995952104,
                    "syntax_match_score": 0.6842105263157895,
                    "dataflow_match_score": 0.8571428571428571
                },
                "codebertscore": {
                    "precision": 0.7760320901870728,
                    "recall": 0.7794898152351379,
                    "F1": 0.7777571082115173,
                    "F3": 0.7791426181793213
                },
                "codebertscore_rescaled": {
                    "precision": 0.5520641803741455,
                    "recall": 0.5589796304702759,
                    "F1": 0.5555142164230347,
                    "F3": 0.5582852363586426
                }
            },
            {
                "ind": 14,
                "gen_code": "def query_star_cluster(cluster_name, radius):\n    \"\"\"\n    Queries Gaia DR3 database for stars within a radius around a given star cluster.\n    \n    Parameters:\n    cluster_name (str): The name of the star cluster (e.g., 'Pleiades')\n    radius (float): The radius around the cluster center in degrees to query\n    \n    Returns:\n    pandas.DataFrame: A DataFrame containing the queried stars and their data\n    \"\"\"\n    # Define the sky coordinates of common star clusters (example for Pleiades, more can be added)\n    cluster_coordinates = {\n        'Pleiades': {'ra': 56.75, 'dec': 24.1167},  # Example coordinates for Pleiades\n    }\n    \n    # Get the RA and Dec for the given cluster name\n    if cluster_name in cluster_coordinates:\n        ra = cluster_coordinates[cluster_name]['ra']\n        dec = cluster_coordinates[cluster_name]['dec']\n    else:\n        raise ValueError(f\"Cluster name '{cluster_name}' not recognized. Available clusters: {list(cluster_coordinates.keys())}\")\n    \n    # Create SkyCoord object\n    coord = SkyCoord(ra=ra*u.degree, dec=dec*u.degree)\n    \n    # Format query string for Cone Search\n    query = f\"\"\"\n        SELECT * \n        FROM gaia_dr3.gaia_source\n        WHERE CONTAINS(\n            POINT('ICRS', ra, dec),\n            CIRCLE('ICRS', {coord.ra.degree}, {coord.dec.degree}, {radius})\n        ) = 1\n    \"\"\"\n    \n    # Execute query\n    response = qc.query(sql=query, fmt='csv')\n    \n    # Convert response to DataFrame\n    df_cluster = convert(response, 'pandas')\n    \n    return df_cluster\n\n# Example usage for the Pleiades cluster with a radius of 1 degree\ndf_pleiades = query_star_cluster('Pleiades', 1.0)\ndf_pleiades.head()",
                "true_code": "# Write a query that returns all of the stars surrounding a particular object out to a particular radius \n\ndef input_query(object_name, radius_deg):\n    # SkyCoord.from_name outputs the coordinates of a particular object given its name as a string\n    c = SkyCoord.from_name(object_name)\n    \n    # Construct a Cone Search query\n    query = \"\"\"SELECT * FROM gaia_dr3.gaia_source \n            WHERE (q3c_radial_query(ra, dec, {0}, {1}, %s)\n            AND NOT parallax='Nan')\"\"\".format(c.ra.value,c.dec.value) % (radius_deg)\n    \n    # Submit the query\n    response = qc.query(sql=query, fmt='csv')\n    \n    # Convert the query to a pandas DataFrame\n    df = convert(response,'pandas')\n    \n    # Check the number of objects in your query\n    print(\"The query of %s contains %s objects.\" % (object_name, len(df)))\n    \n    # Return the output DataFrame\n    return df",
                "error_ind": 14,
                "direct_match": false,
                "fuzzy_match": 21,
                "codebleu": {
                    "codebleu": 0.3016994661659378,
                    "ngram_match_score": 0.07084538153167014,
                    "weighted_ngram_match_score": 0.12432457615533694,
                    "syntax_match_score": 0.5116279069767442,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.7300534248352051,
                    "recall": 0.7881823182106018,
                    "F1": 0.7580050826072693,
                    "F3": 0.781956136226654
                },
                "codebertscore_rescaled": {
                    "precision": 0.46010684967041016,
                    "recall": 0.5763646364212036,
                    "F1": 0.5160101652145386,
                    "F3": 0.5639122724533081
                }
            },
            {
                "ind": 16,
                "gen_code": "# Example execution of the query function for the Pleiades star cluster\nobject_name = \"Pleiades\"\nradius_deg = 3.0\ndf_pleiades = input_query(object_name, radius_deg)\n\n# Display the first few rows of the dataframe\ndf_pleiades.head()",
                "true_code": "# Pick your favorite object!\n\n# Define an object\nobject_queried = \"NGC 6281\"\n\n# Define a radius\nradius = 0.5\n\n# Submit the function that returns a queried DataFrame\ndf = input_query(object_queried, radius)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 11,
                "codebleu": {
                    "codebleu": 0.4795965977411709,
                    "ngram_match_score": 0.009198035390746567,
                    "weighted_ngram_match_score": 0.009188355573937162,
                    "syntax_match_score": 0.9,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7688945531845093,
                    "recall": 0.7824163436889648,
                    "F1": 0.7755964994430542,
                    "F3": 0.7810428142547607
                },
                "codebertscore_rescaled": {
                    "precision": 0.5377891063690186,
                    "recall": 0.5648326873779297,
                    "F1": 0.5511929988861084,
                    "F3": 0.5620856285095215
                }
            },
            {
                "ind": 18,
                "gen_code": "def extract_parameters(df):\n    # Extracting important stellar parameters from the DataFrame\n    ra = df['ra'].values\n    dec = df['dec'].values\n    pmra = df['pmra'].values  # Proper motion in right ascension\n    pmdec = df['pmdec'].values # Proper motion in declination\n    parallax = df['parallax'].values\n    phot_g_mean_mag = df['phot_g_mean_mag'].values  # Photometry in G band\n\n    # Display key parameters to confirm successful extraction\n    print(\"Extracted parameters:\")\n    print(\"RA:\", ra[:5])\n    print(\"Dec:\", dec[:5])\n    print(\"PMRA:\", pmra[:5])\n    print(\"PMDec:\", pmdec[:5])\n    print(\"Parallax:\", parallax[:5])\n    print(\"PhotGMag:\", phot_g_mean_mag[:5])\n    \n    return ra, dec, pmra, pmdec, parallax, phot_g_mean_mag\n\n# Use the extraction function on the queried data\nra, dec, pmra, pmdec, parallax, phot_g_mean_mag = extract_parameters(df)",
                "true_code": "# Define variables from DataFrame\n# Doing so within a function makes later re-definition very simple\ndef define_variables (df):\n    ra, dec = df[\"ra\"], df[\"dec\"]\n    ra_rad, dec_rad = np.radians(ra), np.radians(dec)\n    pmra, pmdec = df[\"pmra\"], df[\"pmdec\"]\n    parallax = df['parallax']\n    g, g_bp = df[\"phot_g_mean_mag\"], df[\"phot_g_mean_mag\"]-df[\"phot_bp_mean_mag\"]\n    return ra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp\n\n# Submit the function that defines variables from the DataFrame\nra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp = define_variables(df)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.2080355334838774,
                    "ngram_match_score": 0.03881514372447816,
                    "weighted_ngram_match_score": 0.04985819485544367,
                    "syntax_match_score": 0.40384615384615385,
                    "dataflow_match_score": 0.33962264150943394
                },
                "codebertscore": {
                    "precision": 0.8221242427825928,
                    "recall": 0.8533250093460083,
                    "F1": 0.8374341130256653,
                    "F3": 0.8500987887382507
                },
                "codebertscore_rescaled": {
                    "precision": 0.6442484855651855,
                    "recall": 0.7066500186920166,
                    "F1": 0.6748682260513306,
                    "F3": 0.7001975774765015
                }
            },
            {
                "ind": 20,
                "gen_code": "def plot_stellar_distribution(ra, dec, pmra, pmdec, g, g_bp):\n    # Set up the figure and ax array\n    fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n    \n    # Spatial plot (RA vs Dec)\n    ax[0].scatter(ra, dec, s=1, alpha=0.5, color='blue')\n    ax[0].set_title('Spatial Distribution of Stars')\n    ax[0].set_xlabel('Right Ascension (deg)')\n    ax[0].set_ylabel('Declination (deg)')\n    \n    # Quiver plot (proper motion vectors)\n    ax[1].quiver(ra, dec, pmra, pmdec, angles='xy', scale_units='xy', scale=0.01, color='red', alpha=0.5)\n    ax[1].set_title('Proper Motion Vector Field')\n    ax[1].set_xlabel('Right Ascension (deg)')\n    ax[1].set_ylabel('Declination (deg)')\n    \n    # Color-Magnitude Diagram (CMD)\n    ax[2].scatter(g_bp, g, s=1, alpha=0.5, color='green')\n    ax[2].invert_yaxis()\n    ax[2].set_title('Color-Magnitude Diagram')\n    ax[2].set_xlabel('BP - G Color')\n    ax[2].set_ylabel('G Magnitude')\n    \n    plt.tight_layout()\n    plt.show()\n\n# Generate the plots using the defined function\nplot_stellar_distribution(ra, dec, pmra, pmdec, g, g_bp)",
                "true_code": "# Write a function that outputs spatial and color-magnitude plots for your sampled object\ndef panel_plot(ra, dec, pmra, pmdec, color, mag):\n    fig = plt.figure(figsize=(26,8))\n    \n    # A simple spatial plot\n    ax1 = fig.add_subplot(131)\n    ax1.scatter(ra, dec, marker='.', alpha= 1/np.power(len(df), 0.1))\n    ax1.set_title(\"Spatial Plot\",fontsize=10)\n    ax1.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax1.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A quiver plot (spatial plot with arrows that describe each object's proper motion)\n    ax2 = fig.add_subplot(132)\n    ax2.quiver(ra, dec, pmra, pmdec)\n    ax2.set_title(\"Proper Motions\",fontsize=10)\n    ax2.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax2.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A color-magnitude diagram that exhibits object density\n    ax3 = fig.add_subplot(133)\n    im3 = ax3.hexbin(g_bp, g, bins='log', cmap=plt.cm.viridis, mincnt=1)\n    ax3.set_ylim(max(g), min(g))\n    ax3.set_title(\"Color-Magnitude Diagram\",fontsize=10)\n    ax3.set_xlabel(\"Gaia G-BP Color\",fontsize=10)\n    ax3.set_ylabel(\"Gaia G Magnitude\",fontsize=10)\n    cb = plt.colorbar(im3,label='log(N)')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.20687482238808036,
                    "ngram_match_score": 0.015687742883224054,
                    "weighted_ngram_match_score": 0.016504353090832567,
                    "syntax_match_score": 0.3902439024390244,
                    "dataflow_match_score": 0.4050632911392405
                },
                "codebertscore": {
                    "precision": 0.8452150225639343,
                    "recall": 0.8093532919883728,
                    "F1": 0.826895534992218,
                    "F3": 0.8128019571304321
                },
                "codebertscore_rescaled": {
                    "precision": 0.6904300451278687,
                    "recall": 0.6187065839767456,
                    "F1": 0.653791069984436,
                    "F3": 0.6256039142608643
                }
            },
            {
                "ind": 22,
                "gen_code": "def parallax_skydist(ra, dec, pmra, pmdec, parallax, mag,\n                     mag_min=12.0, mag_max=18.0, d_max=2.0):\n    # Calculate distance in parsecs\n    d_pc = 1000.0 / parallax\n    \n    # Mask to apply limits on magnitude and distance\n    mask = (mag > mag_min) & (mag < mag_max) & (d_pc < d_max)\n    \n    # Convert to SkyCoord object only for masked objects\n    skycoord = SkyCoord(ra=ra[mask]*u.deg, dec=dec[mask]*u.deg,\n                        pm_ra_cosdec=pmra[mask]*u.mas/u.yr,\n                        pm_dec=pmdec[mask]*u.mas/u.yr,\n                        distance=d_pc[mask]*u.pc)\n    \n    return mag[mask], mask, skycoord",
                "true_code": "# Convert variables to SkyCoord object and impose limits on output\n\ndef convert_to_skycoord (g, ra_rad, dec_rad, parallax, dist1, dist2):\n    # Define variables as as an numpy array and SkyCoord object\n    # Note: The SkyCoord object contains data for ra, dec, and parallax\n    mag = np.array(g)\n    scnow = SkyCoord(np.array(ra_rad) * u.rad, np.array(dec_rad) * u.rad, \n                 distance=(np.array(parallax)*u.mas).to(u.pc, u.parallax()))\n\n    # Create a \"mask\" with varying data thresholds (here depending on magnitude and distance)\n    msk = (mag < 16)  & (scnow.distance > dist1*u.pc) & (scnow.distance < dist2*u.pc)\n    \n    # Apply data thresholds to the given magnitude and SkyCoord objects\n    mag = mag[msk]\n    scnow = scnow[msk]\n    \n    # Print the new object count after applying data thresholds\n    print('After the thresholds are applied, this query contains %s objects.' % (len(scnow)))\n    \n    # Return the defined variables\n    return mag, msk, scnow\n    \nmag, msk, scnow = convert_to_skycoord(g, ra_rad, dec_rad, parallax, 1e2, 9e2)\n",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 7,
                "codebleu": {
                    "codebleu": 0.17432387892640844,
                    "ngram_match_score": 0.012262466142464122,
                    "weighted_ngram_match_score": 0.01964377969628783,
                    "syntax_match_score": 0.20270270270270271,
                    "dataflow_match_score": 0.4626865671641791
                },
                "codebertscore": {
                    "precision": 0.8020691871643066,
                    "recall": 0.7589401602745056,
                    "F1": 0.7799088358879089,
                    "F3": 0.7630431652069092
                },
                "codebertscore_rescaled": {
                    "precision": 0.6041383743286133,
                    "recall": 0.5178803205490112,
                    "F1": 0.5598176717758179,
                    "F3": 0.5260863304138184
                }
            },
            {
                "ind": 24,
                "gen_code": "# Function to modify colormap and define visualization parameters for parallax\n\ndef prepare_viz_params(mag, scnow):\n    # Define the initial point color palette\n    # RGB values define the starting color of the point\n    N = len(mag)\n    colors = np.ones((len(mag), 4)) * np.array([0.1, 0.2, 0.9, 1.0])\n    \n    # Modify color palette to distinguish selected points by magnitude\n    # Adjusts the alpha transparency channel based on relative magnitude\n    colors[:, 3] = (20-mag)/10\n\n    # Assign modified color and size palettes\n    size = 20 - mag/2\n    \n    return colors, size\n\ncolors, size = prepare_viz_params(mag, scnow)",
                "true_code": "# Make a special version of the viridis colormap that goes to a darker yellow at the end. \n# This makes it easier to see small points on a white background.\nnewvhsv = colors.rgb_to_hsv(cm.viridis.colors)\nnewvhsv[:,-1] = np.minimum(newvhsv[:,-1], .88)\ndarker_vidiris = colors.ListedColormap(colors.hsv_to_rgb(newvhsv))\n\n# Define a function to represent magnitude with marker size and distance with marker color\n# Here purple will symbolize closer objects, and yellow will symbolize those further away\ndef mag_to_size(mag):\n    unity_rescaled_mag = (np.max(mag) - mag)/np.ptp(mag)\n    return 40*unity_rescaled_mag**2+2\n\n# Save these visualization arguments as 'scatkwargs'\nscatkwargs = dict(s=mag_to_size(mag), alpha=.9, c=scnow.distance, cmap=darker_vidiris)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.18197547086671098,
                    "ngram_match_score": 0.009553413481443023,
                    "weighted_ngram_match_score": 0.010015136652067571,
                    "syntax_match_score": 0.30357142857142855,
                    "dataflow_match_score": 0.40476190476190477
                },
                "codebertscore": {
                    "precision": 0.7565100789070129,
                    "recall": 0.7064917683601379,
                    "F1": 0.7306458353996277,
                    "F3": 0.7111939191818237
                },
                "codebertscore_rescaled": {
                    "precision": 0.5130201578140259,
                    "recall": 0.4129835367202759,
                    "F1": 0.46129167079925537,
                    "F3": 0.42238783836364746
                }
            },
            {
                "ind": 26,
                "gen_code": "# Function to animate the parallax effect\ndef parallax_animation(skycoord, scatkwargs, frames=30, interval=200):\n    # Factor to convert AU to parsec\n    AU_pc = 206265\n    \n    # Earth\u2019s semimajor axis in astronomical units (AU)\n    semimajor_axis_au = 1.0 \n    \n    # Estimate amplitude of parallax\n    amplitude = semimajor_axis_au / AU_pc\n\n    # Define an array for representing Earth's orbit over timeframes\n    orbit_phase = np.linspace(0, 2 * np.pi, frames)\n\n    # Convert spherical coordinates to cartesian representation with spherical to cartesian transformation\n    spherical = skycoord.spherical\n    cartesian = spherical.to_cartesian()\n\n    # Function to convert parametric orbit into Cartesian offsets\n    def get_offset(t):\n        return np.array([amplitude * np.cos(t), amplitude * np.sin(t), 0])\n    \n    # Initialize plot and scatter\n    fig, ax = plt.subplots(figsize=(7, 7))\n    scat = ax.scatter(cartesian.x.value, cartesian.y.value, **scatkwargs)\n    ax.set_xlim([-1.5 * amplitude, 1.5 * amplitude])\n    ax.set_ylim([-1.5 * amplitude, 1.5 * amplitude])\n    \n    # Animation function to iterate over each frame\n    def update(frame):\n        # Calculate new positions for each object based on frame\n        offset = get_offset(orbit_phase[frame])\n        new_pos = cartesian + CartesianRepresentation(offset * u.pc)\n        \n        # Update scatter plot with new positions\n        scat.set_offsets(np.c_[new_pos.x.value, new_pos.y.value])\n\n    ani = animation.FuncAnimation(fig, update, frames=frames, interval=interval)\n    return HTML(ani.to_html5_video())\n\n# Execute the animation function\nparallax_animation(scnow, scatkwargs)",
                "true_code": "# Write a function to animate the parallax of your sample\n\n# The amplitude describes the distance that markers will move in portraying parallax.\namplitude = 0.6*u.lightyear\nrepr0 = scnow.barycentrictrueecliptic.cartesian\n\ndef animfunc(phase, eclcart_to_spherical, centerstr, ylims, ax):\n    \n    # Converting from Cartesian to spherical coordinates\n    drepr = CartesianRepresentation([np.cos(phase),np.sin(phase),0]*amplitude)\n    rep = repr0 + drepr\n    srep = eclcart_to_spherical(rep)\n    \n    # Creating and defining plot aesthetics\n    ax.cla()\n    ax.set_title(f'Center={centerstr}, Earth Semimajor Axis={amplitude} \\n')\n    # ax.scatter(srep.lon.rad, 90-srep.lat.deg, **scatkwargs)\n    ax.scatter(80.2+srep.lon.rad, 90-srep.lat.deg, **scatkwargs)\n    ax.set_ylim(*ylims)\n    ax.set_yticks(np.linspace(*ax.get_ylim(), 5)[1:])\n    ax.set_yticklabels(['{}'.format(int(90-yl)) for yl in ax.get_yticks()])\n    ax.grid(alpha=0.5)",
                "error_ind": 26,
                "direct_match": false,
                "fuzzy_match": 8,
                "codebleu": {
                    "codebleu": 0.2366865709886815,
                    "ngram_match_score": 0.02467968594531085,
                    "weighted_ngram_match_score": 0.056475200159952846,
                    "syntax_match_score": 0.3655913978494624,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.7433739900588989,
                    "recall": 0.7609155178070068,
                    "F1": 0.7520424723625183,
                    "F3": 0.7591241598129272
                },
                "codebertscore_rescaled": {
                    "precision": 0.48674798011779785,
                    "recall": 0.5218310356140137,
                    "F1": 0.5040849447250366,
                    "F3": 0.5182483196258545
                }
            },
            {
                "ind": 28,
                "gen_code": "# Implement centering function on an arbitrary celestial object to calculate relevant transformations \ndef make_center_func(sky_target):\n    center = SkyCoord.from_name(sky_target)\n    center_ecliptic = center.barycentrictrueecliptic\n\n    def transform_func(cartesian_repr):\n        srep = cartesian_repr.represent_as(SphericalRepresentation)\n        return SphericalRepresentation(lon=srep.lon-center_ecliptic.lon,\n                                        lat=srep.lat-center_ecliptic.lat,\n                                        distance=srep.distance)\n    return transform_func\n\n# Define the object you want the animation to be centered on\ncenter_obj = \"NGC 6281\"\ncenter_transform_func = make_center_func(center_obj)\nphase_range = np.linspace(0, 2*np.pi, 60)\n\n# Set up figure and axis for animating:\nfig, ax = plt.subplots(figsize=[10, 7])\nylims = np.array([np.min(90.-scnow.barycentrictrueecliptic.lat.deg) - 0.5, \n                  np.max(90.-scnow.barycentrictrueecliptic.lat.deg) + 0.5])\n\n# Create the animation that illustrates the parallax of the query results\nanim = animation.FuncAnimation(fig, animfunc, frames=phase_range, fargs=(center_transform_func, center_obj, ylims, ax),\n                               blit=False, interval=100)\n\n# Display the HTML animation\nHTML(anim.to_jshtml())",
                "true_code": "# Centering the visualization on a given object\ndef eclcart_to_spherical3(rep):\n    icrsrep = SkyCoord(scnow.barycentrictrueecliptic.realize_frame(rep)).icrs.cartesian   \n    rot1 = matrix_utilities.rotation_matrix(object_name.ra, 'z')\n    rot2 = matrix_utilities.rotation_matrix(90*u.deg-object_name.dec, 'y')\n    return icrsrep.transform(rot2 @ rot1).represent_as(SphericalRepresentation)",
                "error_ind": 28,
                "direct_match": false,
                "fuzzy_match": 10,
                "codebleu": {
                    "codebleu": 0.25147574029008424,
                    "ngram_match_score": 0.002947604394137389,
                    "weighted_ngram_match_score": 0.014351368162210828,
                    "syntax_match_score": 0.358974358974359,
                    "dataflow_match_score": 0.6296296296296297
                },
                "codebertscore": {
                    "precision": 0.6768378615379333,
                    "recall": 0.7830474376678467,
                    "F1": 0.7260791659355164,
                    "F3": 0.7709497213363647
                },
                "codebertscore_rescaled": {
                    "precision": 0.3536757230758667,
                    "recall": 0.5660948753356934,
                    "F1": 0.4521583318710327,
                    "F3": 0.5418994426727295
                }
            },
            {
                "ind": 30,
                "gen_code": "# Apply the panel_plot function to visualize the dataset from our queried star cluster\npanel_plot(ra, dec, pmra, pmdec, g_bp, g)",
                "true_code": "# Call stationary plot\npanel_plot(scnow.ra, scnow.dec, pmra[msk], pmdec[msk], g_bp[msk], g[msk])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 46,
                "codebleu": {
                    "codebleu": 0.2576838210615152,
                    "ngram_match_score": 0.009629943614188135,
                    "weighted_ngram_match_score": 0.021105340631872645,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.8394118547439575,
                    "recall": 0.8167413473129272,
                    "F1": 0.8279213905334473,
                    "F3": 0.8189531564712524
                },
                "codebertscore_rescaled": {
                    "precision": 0.678823709487915,
                    "recall": 0.6334826946258545,
                    "F1": 0.6558427810668945,
                    "F3": 0.6379063129425049
                }
            },
            {
                "ind": 32,
                "gen_code": "# Create the parallax animation\ndef create_parallax_animation(amplitude, object_name):\n    # Obtain the spherical conversion function centered around the chosen object\n    eclcart_to_spherical = eclcart_to_spherical3\n    \n    fig, ax = plt.subplots(figsize=(8, 8))\n    \n    # Compute y-axis limits based on latitude for plotting\n    ylims = (0, np.ceil(90-np.min(scnow.barycentrictrueecliptic.lat.deg)))\n    \n    # Configure animation functions and parameters\n    anim = animation.FuncAnimation(fig, animfunc, \n                                   fargs=(eclcart_to_spherical, object_name, ylims, ax), \n                                   frames=np.linspace(0, 2*np.pi, 90), blit=False, repeat=True)\n    \n    # Set display parameters and generate video\n    plt.show()\n    return HTML(anim.to_jshtml())\n\n# Output the animation for your chosen object\nanimation_html = create_parallax_animation(amplitude, object_queried)",
                "true_code": "# Call parallax animation\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(projection='polar')\nobject_name = SkyCoord.from_name(object_queried)\ncenterstr3 = object_queried\nylims3 = (0, radius)\n\nanim3 = animation.FuncAnimation(fig, animfunc, np.linspace(0, 2*np.pi, 30),\n                                fargs=(eclcart_to_spherical3, centerstr3, ylims3, ax), \n                                interval=50)\n\nplt.close(fig)\nHTML(anim3.to_html5_video())",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.2861624189772247,
                    "ngram_match_score": 0.020818102422702947,
                    "weighted_ngram_match_score": 0.04942681158143398,
                    "syntax_match_score": 0.4791666666666667,
                    "dataflow_match_score": 0.5952380952380952
                },
                "codebertscore": {
                    "precision": 0.7653650045394897,
                    "recall": 0.8380219340324402,
                    "F1": 0.8000472784042358,
                    "F3": 0.8301413059234619
                },
                "codebertscore_rescaled": {
                    "precision": 0.5307300090789795,
                    "recall": 0.6760438680648804,
                    "F1": 0.6000945568084717,
                    "F3": 0.6602826118469238
                }
            },
            {
                "ind": 34,
                "gen_code": "# Define an object and radius of your choice\nsecond_object_queried = \"Pleiades\"\n\n# Define a radius for the second object\nsecond_radius = 0.5\n\n# Submit the function to retrieve a DataFrame for the second object\ndf_second = input_query(second_object_queried, second_radius)\n\n# Extract relevant variables using the function defined earlier\nra_second, dec_second, ra_rad_second, dec_rad_second, pmra_second, pmdec_second, parallax_second, g_second, g_bp_second = define_variables(df_second)\n\n# Convert extracted variables to back the SkyCoord object and apply proper limits\nmag_second, msk_second, scnow_second = convert_to_skycoord(g_second, ra_rad_second, dec_rad_second, parallax_second, 1e2, 9e2)\n\n# Call stationary plot for the second object\npanel_plot(scnow_second.ra, scnow_second.dec, pmra_second[msk_second], pmdec_second[msk_second], g_bp_second[msk_second], g_second[msk_second])\n\n# Call parallax animation for the second object\nfig_second = plt.figure(figsize=(8, 8))\nax_second = plt.subplot(projection='polar')\nsecond_object_name = SkyCoord.from_name(second_object_queried)\ncenterstr_second = second_object_queried\nylims_second = (0, second_radius)\n\nanim_second = animation.FuncAnimation(fig_second, animfunc, np.linspace(0, 2*np.pi, 30),\n                                      fargs=(eclcart_to_spherical3, centerstr_second, ylims_second, ax_second), \n                                      interval=50)\n\nplt.close(fig_second)\nHTML(anim_second.to_html5_video())",
                "true_code": "# Pick your second-favorite object!\n\n# Define object and radius\nobject_queried = \"NGC 6397\"\nradius = 0.1\n\n# Submit query\ndf = input_query(object_queried, radius)",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.49511360260256515,
                    "ngram_match_score": 0.011311880307517352,
                    "weighted_ngram_match_score": 0.06914253010274321,
                    "syntax_match_score": 0.9,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.583336353302002,
                    "recall": 0.8245570659637451,
                    "F1": 0.6832819581031799,
                    "F3": 0.7918140888214111
                },
                "codebertscore_rescaled": {
                    "precision": 0.1666727066040039,
                    "recall": 0.6491141319274902,
                    "F1": 0.36656391620635986,
                    "F3": 0.5836281776428223
                }
            },
            {
                "ind": 36,
                "gen_code": "# Define variables from DataFrame for the second object\nra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp = define_variables(df)\n\n# Convert variables to SkyCoord object and set limits\nmag, msk, scnow = convert_to_skycoord(g, ra_rad, dec_rad, parallax, 1e2, 9e2)\n\n# Save visualization arguments for the second object\nscatkwargs = dict(s=mag_to_size(mag), alpha=.9, c=scnow.distance, cmap=darker_vidiris)",
                "true_code": "# Define variables\nra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp = define_variables(df)\n\n# Apply thresholds\nmag, msk, scnow = convert_to_skycoord(g, ra_rad, dec_rad, parallax, 1e3, 3e3)\n\n# Define visualization parameters\nscatkwargs = dict(s=mag_to_size(mag), alpha=.9, c=scnow.distance, cmap=darker_vidiris)\namplitude = 0.6*u.lightyear\nrepr0 = scnow.barycentrictrueecliptic.cartesian",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 62,
                "codebleu": {
                    "codebleu": 0.6424566078194434,
                    "ngram_match_score": 0.44543837703691713,
                    "weighted_ngram_match_score": 0.5528433387937016,
                    "syntax_match_score": 0.7666666666666667,
                    "dataflow_match_score": 0.8048780487804879
                },
                "codebertscore": {
                    "precision": 0.9060214757919312,
                    "recall": 0.8865635395050049,
                    "F1": 0.896186888217926,
                    "F3": 0.8884717226028442
                },
                "codebertscore_rescaled": {
                    "precision": 0.8120429515838623,
                    "recall": 0.7731270790100098,
                    "F1": 0.792373776435852,
                    "F3": 0.7769434452056885
                }
            },
            {
                "ind": 38,
                "gen_code": "# Call stationary plot for the second object\npanel_plot(scnow.ra, scnow.dec, pmra[msk], pmdec[msk], g_bp[msk], g[msk])",
                "true_code": "# Call stationary plot\npanel_plot(scnow.ra, scnow.dec, pmra[msk], pmdec[msk], g_bp[msk], g[msk])",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 90,
                "codebleu": {
                    "codebleu": 0.8293315042835503,
                    "ngram_match_score": 0.5316967153331754,
                    "weighted_ngram_match_score": 0.785629301801026,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9534619450569153,
                    "recall": 0.9900473952293396,
                    "F1": 0.97141033411026,
                    "F3": 0.9862629175186157
                },
                "codebertscore_rescaled": {
                    "precision": 0.9069238901138306,
                    "recall": 0.9800947904586792,
                    "F1": 0.94282066822052,
                    "F3": 0.9725258350372314
                }
            },
            {
                "ind": 40,
                "gen_code": "# Call parallax animation\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(projection='polar')\nobject_name = SkyCoord.from_name(object_queried)\ncenterstr3 = object_queried\nylims3 = (0, radius)\n\nanim3 = animation.FuncAnimation(fig, animfunc, np.linspace(0, 2*np.pi, 30),\n                                fargs=(eclcart_to_spherical3, centerstr3, ylims3, ax), \n                                interval=50)\n\nplt.close(fig)\nHTML(anim3.to_html5_video())",
                "true_code": "# Call parallax animation\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(projection='polar')\nobject_name = SkyCoord.from_name(object_queried)\ncenterstr3 = object_queried\nylims3 = (0, radius)\n\nanim3 = animation.FuncAnimation(fig, animfunc, np.linspace(0, 2*np.pi, 30),\n                                fargs=(eclcart_to_spherical3, centerstr3, ylims3, ax), \n                                interval=50)\n\nplt.close(fig)\nHTML(anim3.to_html5_video())",
                "error_ind": 32,
                "direct_match": true,
                "fuzzy_match": 100,
                "codebleu": {
                    "codebleu": 1.0,
                    "ngram_match_score": 1.0,
                    "weighted_ngram_match_score": 1.0,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 1.0000001192092896,
                    "recall": 1.0000001192092896,
                    "F1": 1.0000001192092896,
                    "F3": 1.0000001192092896
                },
                "codebertscore_rescaled": {
                    "precision": 1.000000238418579,
                    "recall": 1.000000238418579,
                    "F1": 1.000000238418579,
                    "F3": 1.000000238418579
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.058823529411764705,
            "fuzzy_match": 25.647058823529413,
            "codebleu": 0.39419806938033,
            "syntax_match_score": 0.5470550026083724,
            "codebertscore": 0.8076524664373959,
            "codebertscore_rescaled": 0.6153049328747917,
            "code_success": 0.5294117647058824,
            "total_code_cell_count": 17
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/DwarfGalaxiesInDelveDr2_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/DwarfGalaxies/DwarfGalaxiesInDelveDr2.ipynb",
            "prefix": "dwarfgalaxies_4"
        },
        "model": {
            "name": "gpt-4o",
            "model": "gpt-4o",
            "library": "OA"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "# Metadata Variables\nNOTEBOOK_ID = \"Astronomy_Study_Delve_DR2\"\nAUTHORS = [\"John Doe\", \"Jane Smith\"]\nVERSION = \"1.0\"\nDATASETS = [\"DELVE_DR2\"]\nKEYWORDS = [\"Astronomy\", \"Dwarf Galaxies\", \"DELVE\", \"Data Analysis\"]",
                "true_code": "__nbid__ = '0007'\n__author__ = 'Jonah Medoff <jmedoff@uchicago.edu>, Alice Jacques <alice.jacques@noirlab.edu>'\n__version__ = '20240620' # yyyymmdd\n__datasets__ = ['delve_dr2']\n__keywords__ = ['science example', 'dwarf galaxies'] ",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.3335582816867866,
                    "ngram_match_score": 0.011371681934875243,
                    "weighted_ngram_match_score": 0.011856660123276007,
                    "syntax_match_score": 0.9473684210526315,
                    "dataflow_match_score": 0.36363636363636365
                },
                "codebertscore": {
                    "precision": 0.7552220225334167,
                    "recall": 0.7176857590675354,
                    "F1": 0.7359756231307983,
                    "F3": 0.7212706804275513
                },
                "codebertscore_rescaled": {
                    "precision": 0.5104440450668335,
                    "recall": 0.4353715181350708,
                    "F1": 0.4719512462615967,
                    "F3": 0.44254136085510254
                }
            },
            {
                "ind": 10,
                "gen_code": "query = \"\"\"\nSELECT RA, DEC, gmag, rmag, imag\nFROM delve_dr2_main\nWHERE \n    q3c_radial_query(ra, dec, 189.58, -40.89, 1.0) -- Search radius of 1 degree\n    AND gmag BETWEEN 18 AND 25 -- g-band magnitude limits\n    AND (gmag - rmag) < 0.2 -- Blue color index\n    AND (rmag - imag) > 0.2 -- Main sequence turn-off\n\"\"\"",
                "true_code": "ra = 189.58\ndec = -40.89\n\n# Create the query string; SQL keyword capitalized for clarity\n\nquery =\\\n\"\"\"SELECT ra,dec,mag_auto_g,mag_auto_r,mag_auto_i\n   FROM delve_dr2.objects\n   WHERE q3c_radial_query(ra, dec, 189.58, -40.89, 0.5) AND\n         mag_auto_g BETWEEN 14 AND 25 AND\n         (mag_auto_g - mag_auto_r) BETWEEN -0.4 AND 0.4\"\"\".format(ra, dec)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 30,
                "codebleu": {
                    "codebleu": 0.11158260474754457,
                    "ngram_match_score": 0.08774903339271693,
                    "weighted_ngram_match_score": 0.10858138559746133,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.25
                },
                "codebertscore": {
                    "precision": 0.8022381663322449,
                    "recall": 0.8165525197982788,
                    "F1": 0.8093320727348328,
                    "F3": 0.8150981664657593
                },
                "codebertscore_rescaled": {
                    "precision": 0.6044763326644897,
                    "recall": 0.6331050395965576,
                    "F1": 0.6186641454696655,
                    "F3": 0.6301963329315186
                }
            },
            {
                "ind": 12,
                "gen_code": "import pandas as pd\n\n# Execute query\njob_id = qc.query(sql=query, fmt='csv')\ndata_url = qc.status(job_id, error='raise')['msg'][0]\ndata = pd.read_csv(data_url)\n\ndata.head()  # Display the first few entries of the dataframe to confirm successful data retrieval",
                "true_code": "%time\nR = qc.query(sql=query,fmt='pandas') # R is a pandas DataFrame",
                "error_ind": 12,
                "direct_match": false,
                "fuzzy_match": 15,
                "codebleu": {
                    "codebleu": 0.404346306825208,
                    "ngram_match_score": 0.007434360163166208,
                    "weighted_ngram_match_score": 0.025535282722081352,
                    "syntax_match_score": 0.7272727272727273,
                    "dataflow_match_score": 0.8571428571428571
                },
                "codebertscore": {
                    "precision": 0.7148599624633789,
                    "recall": 0.7921183705329895,
                    "F1": 0.7515088319778442,
                    "F3": 0.7836490869522095
                },
                "codebertscore_rescaled": {
                    "precision": 0.4297199249267578,
                    "recall": 0.584236741065979,
                    "F1": 0.5030176639556885,
                    "F3": 0.567298173904419
                }
            },
            {
                "ind": 14,
                "gen_code": "# Verify the number of objects retrieved and display the first few entries\nprint(f\"Total number of objects retrieved: {len(R)}\")\nR.head()",
                "true_code": "print(\"Number of objects:\", R.shape[0])\nprint(R.head())",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 40,
                "codebleu": {
                    "codebleu": 0.34276268697441825,
                    "ngram_match_score": 0.009629943614188135,
                    "weighted_ngram_match_score": 0.05372849659117709,
                    "syntax_match_score": 0.3076923076923077,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.7918655276298523,
                    "recall": 0.8646112680435181,
                    "F1": 0.8266410827636719,
                    "F3": 0.8567407131195068
                },
                "codebertscore_rescaled": {
                    "precision": 0.5837310552597046,
                    "recall": 0.7292225360870361,
                    "F1": 0.6532821655273438,
                    "F3": 0.7134814262390137
                }
            },
            {
                "ind": 16,
                "gen_code": "# Define a grid and then use hist2d for the spatial density plot\n\nplt.figure(figsize=(10, 8))\nplt.hist2d(R['ra'], R['dec'], bins=200, cmap='viridis')\nplt.colorbar(label='Number of stars')\nplt.xlabel('Right Ascension (RA)')\nplt.ylabel('Declination (Dec)')\nplt.title('Spatial Density of Blue Stars')\nplt.gca().invert_xaxis()  # To match astronomical coordinates with RA increasing to the left\nplt.show()",
                "true_code": "fig = plt.figure(figsize=(7,6))\nplt.hexbin(R['ra'], R['dec'],gridsize=200)\nplt.xlabel('RA')\nplt.ylabel('Dec')\nplt.colorbar(label='number of objects per spatial bin');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 22,
                "codebleu": {
                    "codebleu": 0.33538044063283445,
                    "ngram_match_score": 0.004863083928997274,
                    "weighted_ngram_match_score": 0.018476860420522198,
                    "syntax_match_score": 0.8181818181818182,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.7759774327278137,
                    "recall": 0.8867536783218384,
                    "F1": 0.8276753425598145,
                    "F3": 0.8742727637290955
                },
                "codebertscore_rescaled": {
                    "precision": 0.5519548654556274,
                    "recall": 0.7735073566436768,
                    "F1": 0.6553506851196289,
                    "F3": 0.7485455274581909
                }
            },
            {
                "ind": 18,
                "gen_code": "def detect_overdensities(data, small_sigma=0.05, large_sigma=0.1, clip_percentile=99.5):\n    \"\"\"\n    Detects overdensities in the spatial distribution using a Difference of Gaussians (DoG).\n\n    Parameters:\n    - data: 2D histogram of spatial data.\n    - small_sigma: Standard deviation for the small Gaussian kernel.\n    - large_sigma: Standard deviation for the large Gaussian kernel.\n    - clip_percentile: Percentile for clipping to minimize noise.\n\n    Returns:\n    - convolved_image: Clipped array of the convolved image.\n    \"\"\"\n    # Generate the 2D Gaussian kernels\n    kernel_small = convolution.Gaussian2DKernel(small_sigma)\n    kernel_large = convolution.Gaussian2DKernel(large_sigma)\n    \n    # Convolve the data with both kernels\n    convolved_small = convolution.convolve(data, kernel_small, boundary='extend')\n    convolved_large = convolution.convolve(data, kernel_large, boundary='extend')\n    \n    # Difference of the convolved images\n    convolved_image = convolved_small - convolved_large\n    \n    # Clip the image to reduce noise\n    clipped_image = stats.sigma_clip(convolved_image, percentile=clip_percentile)\n    \n    return clipped_image\n\n# Example of using the function\n# Assuming `R['ra']`, `R['dec']` are arrays correctly set earlier\nh, xedges, yedges = np.histogram2d(R['ra'], R['dec'], bins=(200, 200))\noverdensity_map = detect_overdensities(h)\n",
                "true_code": "def dwarf_filter (ra,dec,fwhm_small=2.0,fwhm_big=20):\n\n    \"\"\"Differential convolution with 2D Gaussian kernels.\n    \n       Based on Koposov et al. (2008).\n       Code by Ken Mighell and Mike Fitzpatrick.\n       Minor edits by RN.\n       \n       Parameters\n       ----------\n       ra, dec : float or array\n           RA & Dec in degrees.\n    \n       fwhm_small, fwhm_big : float\n           Full-width half maximum sizes of the small and big Gaussian kernels\n           to use in convolution, in arcminutes.\n    \"\"\"\n    \n    x, y = ra, dec\n\n    print(\"Computing differential convolution .... \",)\n\n    # Information about declination (y) [degrees]\n    ymean = (y.min() + y.max()) / 2.0\n    ydiff_arcmin = (y.max() - y.min()) * 60.0 # convert from degrees to arcmin\n\n    # Information about right ascension (x) [degrees in time]:\n    xdiff = x.max() - x.min() # angular separation [degrees (time)] \n    xmean = (x.min() + x.max()) / 2.0\n\n    # convert from degrees in time to separation in angular degrees:\n    xdiff_angular = (x.max() - x.min()) * np.cos(ymean*(np.pi/180.0))\n\n    # convert from degress to arcmin\n    xdiff_angular_arcmin = xdiff_angular * 60.0 \n\n    # Get the number of one-arcmin pixels in the X and Y directions:\n    nx = np.rint(xdiff_angular_arcmin).astype('int')\n    ny = np.rint(ydiff_arcmin).astype('int')\n\n    # Create a two-dimensional histogram of the raw counts:\n    Counts, xedges, yedges  = np.histogram2d (x, y, (nx,ny) )\n    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n    raw_hist = np.rot90(Counts).copy() # hack around Pythonic weirdness\n\n    # Make the small and big Gaussian kernels with a standard deviation\n    # of the given FWHM in arcmin^2 pixels.\n    kernel_small = convolution.Gaussian2DKernel(fwhm_small/2.35,factor=1)\n    kernel_big = convolution.Gaussian2DKernel(fwhm_big/2.35,factor=1)\n\n    # Compute the differential convolution kernels.\n    conv_big = convolution.convolve(raw_hist, kernel_big)\n    conv_small = convolution.convolve(raw_hist, kernel_small)\n    conv_delta = conv_small - conv_big\n    delta = conv_delta.copy()\n\n    # Compute statistics and the floor\n    mean = np.mean(delta, dtype='float64')\n    sigma = np.std(delta, dtype='float64')\n    sigmaRaw = np.std(raw_hist,dtype='float64')\n    median = np.median(delta) # not used\n    floor = mean\n\n    print('dwarf_filter: mean = {:g}  sigma = {:g} sigmaRaw = {:g}'.format(mean, sigma, sigmaRaw))\n\n    clipped = delta.copy()\n    clipped[delta < floor] = floor\n\n    # Return the computed fields.\n    return raw_hist, extent, delta, clipped, sigma",
                "error_ind": 18,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.11414442004382808,
                    "ngram_match_score": 0.005889296570002738,
                    "weighted_ngram_match_score": 0.00879859892663269,
                    "syntax_match_score": 0.25888324873096447,
                    "dataflow_match_score": 0.1830065359477124
                },
                "codebertscore": {
                    "precision": 0.7860559821128845,
                    "recall": 0.7202023863792419,
                    "F1": 0.751689612865448,
                    "F3": 0.7262870073318481
                },
                "codebertscore_rescaled": {
                    "precision": 0.572111964225769,
                    "recall": 0.4404047727584839,
                    "F1": 0.503379225730896,
                    "F3": 0.4525740146636963
                }
            },
            {
                "ind": 20,
                "gen_code": "raw, extent, delta, clipped, dsigma = dwarf_filter(R['ra'], R['dec'])",
                "true_code": "%time\nsmall_k, big_k = 2., 20.  # kernel sizes in arcminutes\nraw, extent, delta, clipped, dsigma = dwarf_filter(R['ra'],R['dec'],fwhm_small=small_k,fwhm_big=big_k)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 59,
                "codebleu": {
                    "codebleu": 0.22275743755504168,
                    "ngram_match_score": 0.19493068205878689,
                    "weighted_ngram_match_score": 0.2516546237169354,
                    "syntax_match_score": 0.2777777777777778,
                    "dataflow_match_score": 0.16666666666666666
                },
                "codebertscore": {
                    "precision": 0.9363831877708435,
                    "recall": 0.7468438148498535,
                    "F1": 0.8309419751167297,
                    "F3": 0.7622734904289246
                },
                "codebertscore_rescaled": {
                    "precision": 0.872766375541687,
                    "recall": 0.49368762969970703,
                    "F1": 0.6618839502334595,
                    "F3": 0.5245469808578491
                }
            },
            {
                "ind": 22,
                "gen_code": "fig = plt.figure(figsize=(7,6))\nplt.imshow(clipped, extent=extent, cmap='hot', origin='lower', aspect='auto')\nplt.xlabel('RA')\nplt.ylabel('Dec')\nplt.colorbar(label='Convolved density')\nplt.title('Convolved 2D Histogram of Spatial Density')\nplt.show()",
                "true_code": "fig, ax = plt.subplots(figsize=(7,6))\nim = plt.imshow(clipped)\nplt.xlabel('pixel')\nplt.ylabel('pixel')\nplt.colorbar(label='relative spatial density after convolution');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 6,
                "codebleu": {
                    "codebleu": 0.3323069907466899,
                    "ngram_match_score": 0.010182425646195498,
                    "weighted_ngram_match_score": 0.01428363257865929,
                    "syntax_match_score": 0.7333333333333333,
                    "dataflow_match_score": 0.5714285714285714
                },
                "codebertscore": {
                    "precision": 0.8481359481811523,
                    "recall": 0.9054860472679138,
                    "F1": 0.8758732080459595,
                    "F3": 0.8994044065475464
                },
                "codebertscore_rescaled": {
                    "precision": 0.6962718963623047,
                    "recall": 0.8109720945358276,
                    "F1": 0.751746416091919,
                    "F3": 0.7988088130950928
                }
            },
            {
                "ind": 25,
                "gen_code": "# Detect peaks\nthreshold = dsigma * 3  # 3-sigma peaks\nbox_size = int(2 * small_k)  # box size in pixels\n\n# Identify 3 sigma peaks\npeaks_tbl = find_peaks(clipped, threshold, box_size=box_size, centroid_func=None)\npeaks_tbl['ra'] = xedges[0] + (peaks_tbl['x_peak'] + 0.5) * (xedges[-1]-xedges[0])/nx\npeaks_tbl['dec'] = yedges[0] + (peaks_tbl['y_peak'] + 0.5) * (yedges[-1]-yedges[0])/ny\n\nprint(peaks_tbl)",
                "true_code": "# find peaks\nmean, median, std = stats.sigma_clipped_stats(clipped,sigma=3.0,maxiters=5)\nprint(mean, median, std)\ntbl = find_peaks(clipped,median+3,box_size=small_k*2)\n\n# add ra & dec positions of peaks found\na, b = extent[:2]\nxvec = np.arange(a,b,(b-a)/clipped.shape[1])\na, b = extent[2:]\nyvec = np.arange(a,b,(b-a)/clipped.shape[0])\n\ntbl['ra'] = xvec[tbl['x_peak']]\ntbl['dec'] = yvec[-tbl['y_peak']-1]\nprint(tbl)",
                "error_ind": 25,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.1186228566118197,
                    "ngram_match_score": 0.0062239522614920065,
                    "weighted_ngram_match_score": 0.007249733756281732,
                    "syntax_match_score": 0.19117647058823528,
                    "dataflow_match_score": 0.2698412698412698
                },
                "codebertscore": {
                    "precision": 0.8016269207000732,
                    "recall": 0.7914858460426331,
                    "F1": 0.796524167060852,
                    "F3": 0.7924883961677551
                },
                "codebertscore_rescaled": {
                    "precision": 0.6032538414001465,
                    "recall": 0.5829716920852661,
                    "F1": 0.5930483341217041,
                    "F3": 0.5849767923355103
                }
            },
            {
                "ind": 27,
                "gen_code": "fig, ax = plt.subplots(figsize=(7,6))\nim = plt.imshow(clipped, cmap='viridis', origin='lower', extent=extent, interpolation='nearest')\nplt.xlabel('RA [deg]')\nplt.ylabel('Dec [deg]')\nplt.colorbar(label='relative density')\n\n# overlay the found peaks\nplt.scatter(tbl['ra'], tbl['dec'], s=tbl['peak_value']*20, edgecolor='red', facecolor='none', label='3-sigma peaks')\nplt.legend()\nplt.show()",
                "true_code": "ecs = ['w'] # color of box frame\nax.scatter(tbl['x_peak'],tbl['y_peak'],marker='s',s=tbl['peak_value']*50,c='none',edgecolors=ecs,lw=3) # keeps writing to previous ax\nfig  # repeats (the updated) figure",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 11,
                "codebleu": {
                    "codebleu": 0.20290683285626845,
                    "ngram_match_score": 0.007939087147543497,
                    "weighted_ngram_match_score": 0.012021577610863726,
                    "syntax_match_score": 0.625,
                    "dataflow_match_score": 0.16666666666666666
                },
                "codebertscore": {
                    "precision": 0.7371744513511658,
                    "recall": 0.7693519592285156,
                    "F1": 0.7529195547103882,
                    "F3": 0.7660083770751953
                },
                "codebertscore_rescaled": {
                    "precision": 0.47434890270233154,
                    "recall": 0.5387039184570312,
                    "F1": 0.5058391094207764,
                    "F3": 0.5320167541503906
                }
            },
            {
                "ind": 29,
                "gen_code": "# Define a function to plot image cutouts\ndef plot_image_cutouts(peak_list, survey='delve'):\n    for i, peak in enumerate(peak_list):\n        ra, dec = peak['ra'], peak['dec']\n        \n        # Access the image cutout service (SIA)\n        service = sia.SIAService(f'https://datalab.noirlab.edu/sia/{survey}')\n        response = service.search(pos=(ra, dec), size=0.1)  # 0.1 degree cutout\n        \n        if response.size > 0:\n            image_url = response[0].getdataurl()\n            image_file = download_file(image_url, cache=True)\n            \n            # Open the image file\n            with fits.open(image_file) as hdulist:\n                wcs = WCS(hdulist[0].header)\n                data = hdulist[0].data\n                \n                # Plot the image\n                fig, ax = plt.subplots(1, 1, subplot_kw={'projection': wcs})\n                ax.imshow(data, origin='lower', cmap='gray', vmin=np.percentile(data, 5), vmax=np.percentile(data, 99))\n                ax.set_title(f'RA: {ra:.2f}, Dec: {dec:.2f}')\n                ax.set_xlabel('Right Ascension')\n                ax.set_ylabel('Declination')\n                plt.grid(color='white', ls='dotted')\n\nplot_image_cutouts(tbl)",
                "true_code": "# set up SIA and image table\nDEF_ACCESS_URL = \"https://datalab.noirlab.edu/sia/nsa\"\nsvc_nsa = sia.SIAService(DEF_ACCESS_URL)\nra = 189.58\ndec = -40.89\nfov = 0.1\n\nimgTable = svc_nsa.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n   \n# multi panel image plotter\ndef plot_images(images,geo=None,panelsize=5,titles=list('gri'),cmap=plt.cm.gray_r):\n    if geo is None:\n        geo = (len(images),1)  # ncols, nrows\n        \n    fig = plt.figure(figsize=(geo[0]*panelsize,geo[1]*panelsize))\n    for j,img in enumerate(images):\n        ax = fig.add_subplot(geo[1],geo[0],j+1)\n        ax.imshow(img,origin='lower',interpolation='none',cmap=cmap,norm=plt.mpl.colors.PowerNorm(0.1))\n        ax.set_title('{:s}'.format(titles[j]))\n        plt.axis('off')",
                "error_ind": 29,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.18195434669876176,
                    "ngram_match_score": 0.008598149504976525,
                    "weighted_ngram_match_score": 0.014954547205206399,
                    "syntax_match_score": 0.3364485981308411,
                    "dataflow_match_score": 0.367816091954023
                },
                "codebertscore": {
                    "precision": 0.7552788853645325,
                    "recall": 0.7468004822731018,
                    "F1": 0.7510157227516174,
                    "F3": 0.7476397156715393
                },
                "codebertscore_rescaled": {
                    "precision": 0.5105577707290649,
                    "recall": 0.4936009645462036,
                    "F1": 0.5020314455032349,
                    "F3": 0.4952794313430786
                }
            },
            {
                "ind": 31,
                "gen_code": "# Extract corners from tbl for first identified peak\npeak_ra = tbl['ra'][0]\npeak_dec = tbl['dec'][0]\n\n# Generate URLs with extracting image cutout for g, r, and i bands\ndef get_img_url(band):\n    positions = f\"{peak_ra}d {peak_dec}d\"\n    size = \"0.03d\"\n    return f\"https://www.legacysurvey.org/viewer/fits-cutout?ra={peak_ra}&dec={peak_dec}&layer=ls-dr9&pixscale=0.262&bands={band}&size=512\"\n\n# Download the images\nimg_g_url = get_img_url('g')\nimg_r_url = get_img_url('r')\nimg_i_url = get_img_url('i')\n\n# Display the images\nimgs = [fits.getdata(download_file(img_g_url, cache=True)), \n        fits.getdata(download_file(img_r_url, cache=True)), \n        fits.getdata(download_file(img_i_url, cache=True))]\n\nplot_images(imgs)",
                "true_code": "#There is an astrometric offset in the false-color image, so these constants are used to move the images around\n#Right now we have it set so that the g and i images are moved 8 pixels to the left\na=0\nb=8",
                "error_ind": 31,
                "direct_match": false,
                "fuzzy_match": 1,
                "codebleu": {
                    "codebleu": 0.13128856368353706,
                    "ngram_match_score": 0.009270196054984463,
                    "weighted_ngram_match_score": 0.015884058679163742,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.6072202324867249,
                    "recall": 0.6842257976531982,
                    "F1": 0.6434272527694702,
                    "F3": 0.675657331943512
                },
                "codebertscore_rescaled": {
                    "precision": 0.2144404649734497,
                    "recall": 0.3684515953063965,
                    "F1": 0.28685450553894043,
                    "F3": 0.3513146638870239
                }
            },
            {
                "ind": 33,
                "gen_code": "# Retrieve g-band image\nurl = imgTable[0]['sia_url']\nfile = download_file(url,cache=True)\nhdul = fits.open(file)\ng_img = hdul[1].data\nhdr = hdul[1].header\nexp_time_g = hdr['EXPTIME']\nzpt_g = hdr['PHOT_ZP']\nhdr['CRPIX1'] -= a\n\ng_img = g_img / exp_time_g\ng_img *= 10**((zpt_g-22.5)/2.5)\n\n# Display g-band image\nplt.figure(figsize=(5, 5))\nplt.imshow(g_img, cmap='gray', origin='lower', interpolation='none', \n           norm=plt.mpl.colors.PowerNorm(0.1))\nplt.title('g band')\nplt.axis('off')\nplt.show()",
                "true_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='311551') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'g'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni1 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage1 = i1[0:1362, b:1233]\n#Normalization\n#image1 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=85, expnum=188187, ccdnum=16\nzp=31.514652\nimage1 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]",
                "error_ind": 33,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.1440089403623301,
                    "ngram_match_score": 0.011182694164423438,
                    "weighted_ngram_match_score": 0.011427015724517047,
                    "syntax_match_score": 0.32954545454545453,
                    "dataflow_match_score": 0.22388059701492538
                },
                "codebertscore": {
                    "precision": 0.7326578497886658,
                    "recall": 0.7151813507080078,
                    "F1": 0.7238141298294067,
                    "F3": 0.7168914079666138
                },
                "codebertscore_rescaled": {
                    "precision": 0.46531569957733154,
                    "recall": 0.4303627014160156,
                    "F1": 0.4476282596588135,
                    "F3": 0.43378281593322754
                }
            },
            {
                "ind": 35,
                "gen_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='311551') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'r'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni2 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n# Dimensions of each image need to be equal\nimage2 = i2[0:1362, a:1233]\n#Normalization\nzp=31.538866\nimage2 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]",
                "true_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='313152') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'r')) \n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni2 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage2 = i2[0:1362, 0:1233-b]\n#Normalization\n#image2 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=85, expnum=188186, ccdnum=16\nzp=31.66765\nimage2 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]",
                "error_ind": 35,
                "direct_match": false,
                "fuzzy_match": 91,
                "codebleu": {
                    "codebleu": 0.8183223938975605,
                    "ngram_match_score": 0.6822864388618091,
                    "weighted_ngram_match_score": 0.6878306317713939,
                    "syntax_match_score": 0.9325842696629213,
                    "dataflow_match_score": 0.9705882352941176
                },
                "codebertscore": {
                    "precision": 0.9783207774162292,
                    "recall": 0.9473817348480225,
                    "F1": 0.9626026749610901,
                    "F3": 0.9503872990608215
                },
                "codebertscore_rescaled": {
                    "precision": 0.9566415548324585,
                    "recall": 0.8947634696960449,
                    "F1": 0.9252053499221802,
                    "F3": 0.9007745981216431
                }
            },
            {
                "ind": 37,
                "gen_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='309792') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'i'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni3 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage3 = i3[a:1362-a, 0:1233-b]\n#Normalization\n# For i-band, let's use an approximation for zeropoint\nzp = 31.4 # Example approximation if not available\nimage3 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]\n\n# Plot all three images\nplot_images([image1, image2, image3], titles=['g-band', 'r-band', 'i-band'])",
                "true_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='307960') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'i'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni3 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage3 = i3[0:1362, b:1233]\n#Normalization\n#image3 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=20, expnum=294524, ccdnum=60\n#Note: the expnum and ccdnum for the i image did not produce a zeropoint, \n#so we estimated a zeropoint of 31.0, which worked well to produce a proper false-color image.\nzp=31.0\nimage3 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]",
                "error_ind": 37,
                "direct_match": false,
                "fuzzy_match": 71,
                "codebleu": {
                    "codebleu": 0.7049201432144802,
                    "ngram_match_score": 0.4856587968581807,
                    "weighted_ngram_match_score": 0.49175583298752834,
                    "syntax_match_score": 0.9318181818181818,
                    "dataflow_match_score": 0.9104477611940298
                },
                "codebertscore": {
                    "precision": 0.9268206357955933,
                    "recall": 0.9102944135665894,
                    "F1": 0.9184831976890564,
                    "F3": 0.9119204878807068
                },
                "codebertscore_rescaled": {
                    "precision": 0.8536412715911865,
                    "recall": 0.8205888271331787,
                    "F1": 0.8369663953781128,
                    "F3": 0.8238409757614136
                }
            },
            {
                "ind": 39,
                "gen_code": "# lrgb = make_lupton_rgb(image1-np.median(image1),image2-np.median(image2),image3-np.median(image3), Q=3, stretch=0.5)\nlrgb = make_lupton_rgb(image1-np.median(image1), image2-np.median(image2), image3-np.median(image3), stretch=0.5)\n\nplot_images([image1, image2, image3], geo=(3, 1), titles=['g', 'r', 'i'], cmap=plt.cm.gray)\nplt.figure(figsize=(8, 8))\nplt.imshow(lrgb, interpolation='none', origin='lower')\nplt.xlabel('pixel')\nplt.ylabel('pixel')\nplt.title('False-color Image')\nplt.axis('off')\nplt.show()",
                "true_code": "bands = list('gri')\nimages=[image1, image2, image3]\nimages = [im-np.median(im) for im in images] # subtract median from all images for better scaling\nimages += [make_lupton_rgb(*images[::-1],stretch=1)] # add a 3-color composite image\nplot_images(images,geo=(4,1),titles=bands+['False-color 3-band image'])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.1526854222528352,
                    "ngram_match_score": 0.007751109309122896,
                    "weighted_ngram_match_score": 0.007030983742621923,
                    "syntax_match_score": 0.2777777777777778,
                    "dataflow_match_score": 0.3181818181818182
                },
                "codebertscore": {
                    "precision": 0.7852034568786621,
                    "recall": 0.7800202965736389,
                    "F1": 0.7826033234596252,
                    "F3": 0.7805355191230774
                },
                "codebertscore_rescaled": {
                    "precision": 0.5704069137573242,
                    "recall": 0.5600405931472778,
                    "F1": 0.5652066469192505,
                    "F3": 0.5610710382461548
                }
            },
            {
                "ind": 41,
                "gen_code": "def construct_photometry_query(ra_peak, dec_peak, radius=5):\n    \"\"\"\n    Construct an SQL query to retrieve photometric data for stars within a given radius of a density peak.\n    \n    Parameters:\n        ra_peak (float): Right Ascension of the density peak in degrees.\n        dec_peak (float): Declination of the density peak in degrees.\n        radius (float): Radius of the vicinity to query around the peak, in arcminutes. Default is 5 arcmin.\n\n    Returns:\n        query (str): SQL query string.\n    \"\"\"\n    # Create the query string; SQL keyword capitalized for clarity\n    query = f\"\"\"\n    SELECT ra, dec, mag_auto_g, mag_auto_r, mag_auto_i\n    FROM delve_dr2.objects\n    WHERE q3c_radial_query(ra, dec, {ra_peak}, {dec_peak}, {radius / 60}) AND\n          mag_auto_g IS NOT NULL AND\n          mag_auto_r IS NOT NULL AND\n          mag_auto_i IS NOT NULL\n    \"\"\"\n    return query",
                "true_code": "def makequery(ra0,dec0,radius0):\n    query_template = \"\"\"\nSELECT ra,dec,mag_auto_g,mag_auto_r,mag_auto_i FROM delve_dr2.objects\n  WHERE q3c_radial_query(ra, dec, {0}, {1}, {2})\n    AND mag_auto_g BETWEEN 14 AND 25\"\"\" \n    query = query_template.format(ra0,dec0,radius0)\n    \n    return query",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 18,
                "codebleu": {
                    "codebleu": 0.1252843398682197,
                    "ngram_match_score": 0.04453526730059063,
                    "weighted_ngram_match_score": 0.21301234858254467,
                    "syntax_match_score": 0.07692307692307693,
                    "dataflow_match_score": 0.16666666666666666
                },
                "codebertscore": {
                    "precision": 0.7157739996910095,
                    "recall": 0.7987428307533264,
                    "F1": 0.7549858093261719,
                    "F3": 0.7895902991294861
                },
                "codebertscore_rescaled": {
                    "precision": 0.43154799938201904,
                    "recall": 0.5974856615066528,
                    "F1": 0.5099716186523438,
                    "F3": 0.5791805982589722
                }
            },
            {
                "ind": 43,
                "gen_code": "radius = 5.0 / 60.0\n\n# Apply the query to the first peak's coordinates in `tbl`\nra_peak, dec_peak = tbl['ra'][0], tbl['dec'][0]\n\nquery_peak = makequery(ra_peak, dec_peak, radius)\npeak_data = qc.query(sql=query_peak, fmt='pandas')\n\nprint(peak_data.head())",
                "true_code": "query0 = makequery(tbl['ra'][0],tbl['dec'][0], 5./60.) # center ra & dec\nR0 = qc.query(sql=query0,fmt='pandas')\nprint(R0.head()) # a pandas method",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 18,
                "codebleu": {
                    "codebleu": 0.3188035884707654,
                    "ngram_match_score": 0.007939087147543497,
                    "weighted_ngram_match_score": 0.015138514598766055,
                    "syntax_match_score": 0.8076923076923077,
                    "dataflow_match_score": 0.4444444444444444
                },
                "codebertscore": {
                    "precision": 0.8281124234199524,
                    "recall": 0.8608131408691406,
                    "F1": 0.844146192073822,
                    "F3": 0.8574272394180298
                },
                "codebertscore_rescaled": {
                    "precision": 0.6562248468399048,
                    "recall": 0.7216262817382812,
                    "F1": 0.688292384147644,
                    "F3": 0.7148544788360596
                }
            },
            {
                "ind": 45,
                "gen_code": "R0['color'] = R0['mag_auto_g'] - R0['mag_auto_r']\nprint(R0[['mag_auto_g', 'mag_auto_r', 'color']].head())",
                "true_code": "R0['g_r'] = R0['mag_auto_g'] - R0['mag_auto_r']\nprint( R0.head())",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 73,
                "codebleu": {
                    "codebleu": 0.5954636003856152,
                    "ngram_match_score": 0.345720784641941,
                    "weighted_ngram_match_score": 0.41113361690051975,
                    "syntax_match_score": 0.625,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9513874053955078,
                    "recall": 0.9628390073776245,
                    "F1": 0.9570789337158203,
                    "F3": 0.9616814255714417
                },
                "codebertscore_rescaled": {
                    "precision": 0.9027748107910156,
                    "recall": 0.925678014755249,
                    "F1": 0.9141578674316406,
                    "F3": 0.9233628511428833
                }
            },
            {
                "ind": 47,
                "gen_code": "def plot_cmd(ax, x, y, title=\"CMD\", xlim=(-1,1), ylim=(25,14)):\n    ax.scatter(x, y, s=2, alpha=0.5)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    ax.set_xlabel('Color (g-r)')\n    ax.set_ylabel('Magnitude (g)')\n    ax.set_title(title)\n    ax.grid(True)\n",
                "true_code": "def plotpanel(axid,x,y,title='',xlim=(-1,2),ylim=(25.2,14)):\n    ax = fig.add_subplot(axid)\n    ax.scatter(x,y,marker='.',s=10, alpha=0.8)\n    ax.set_xlabel(x.name)\n    ax.set_ylabel(y.name)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    ax.set_title(title)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 31,
                "codebleu": {
                    "codebleu": 0.2512243863438425,
                    "ngram_match_score": 0.02560744480557418,
                    "weighted_ngram_match_score": 0.04740604259878136,
                    "syntax_match_score": 0.5652173913043478,
                    "dataflow_match_score": 0.36666666666666664
                },
                "codebertscore": {
                    "precision": 0.894868016242981,
                    "recall": 0.8946084380149841,
                    "F1": 0.8947382569313049,
                    "F3": 0.8946343660354614
                },
                "codebertscore_rescaled": {
                    "precision": 0.7897360324859619,
                    "recall": 0.7892168760299683,
                    "F1": 0.7894765138626099,
                    "F3": 0.7892687320709229
                }
            },
            {
                "ind": 49,
                "gen_code": "fig = plt.figure(figsize=(6,8))\nplotpanel(111, R0['g_r'], R0['mag_auto_g'],\n              title='Color-magnitude diagram around peak',\n              xlim=(-0.5, 1.5), ylim=(25.5, 14))\nplt.tight_layout()\nplt.show()",
                "true_code": "fig = plt.figure(figsize=(12,5.5))\nplotpanel(121,R0['g_r'],R0['mag_auto_g'],'white box, {:d} objects'.format(len(R0)))",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 41,
                "codebleu": {
                    "codebleu": 0.31761734489325333,
                    "ngram_match_score": 0.026012784404037925,
                    "weighted_ngram_match_score": 0.06985342056580097,
                    "syntax_match_score": 0.2857142857142857,
                    "dataflow_match_score": 0.8888888888888888
                },
                "codebertscore": {
                    "precision": 0.8254889249801636,
                    "recall": 0.883418083190918,
                    "F1": 0.8534716963768005,
                    "F3": 0.8772618770599365
                },
                "codebertscore_rescaled": {
                    "precision": 0.6509778499603271,
                    "recall": 0.7668361663818359,
                    "F1": 0.7069433927536011,
                    "F3": 0.754523754119873
                }
            },
            {
                "ind": 52,
                "gen_code": "# Save the DataFrame to a CSV file\nR0.to_csv('centaurus_i_detection_photometry.csv', index=False)",
                "true_code": "outfile = 'cen1.csv'\nR0.to_csv(outfile,index=False)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 43,
                "codebleu": {
                    "codebleu": 0.3333333333333333,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.3333333333333333,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.8011956810951233,
                    "recall": 0.8533681631088257,
                    "F1": 0.8264592885971069,
                    "F3": 0.8478472232818604
                },
                "codebertscore_rescaled": {
                    "precision": 0.6023913621902466,
                    "recall": 0.7067363262176514,
                    "F1": 0.6529185771942139,
                    "F3": 0.6956944465637207
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.0,
            "fuzzy_match": 27.59090909090909,
            "codebleu": 0.29969433009477153,
            "syntax_match_score": 0.47221549006965113,
            "codebertscore": 0.8123594522476196,
            "codebertscore_rescaled": 0.6247189044952393,
            "code_success": 0.6363636363636364,
            "total_code_cell_count": 22
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/01_EmLineGalaxies_SpectraStack_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/EmLineGalaxies/01_EmLineGalaxies_SpectraStack.ipynb",
            "prefix": "emlinegalaxies_0"
        },
        "model": {
            "name": "llama3.1",
            "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "library": "together"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "# Notebook metadata\nnotebook_id = \"ASTR-001\"\nauthors = [\n    {\"name\": \"John Doe\", \"email\": \"johndoe@example.com\"},\n    {\"name\": \"Jane Smith\", \"email\": \"janesmith@example.com\"}\n]\nversion = \"20221231\"\ndatasets = [\"SDSS Data Release 12\", \"SDSS Data Release 16\"]\nkeywords = [\"Astronomy\", \"Spectroscopy\", \"Spectra Stacking\", \"SPARCL Method\", \"SDSS\"]",
                "true_code": "__nbid__ = '0011'\n__author__ = 'Ragadeepika Pucha <rpucha@arizona.edu>, Stephanie Juneau <stephanie.juneau@noirlab.edu>'\n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['sdss_dr12', 'sdss_dr16']\n__keywords__ = ['sdss spectra', 'spectra stacking', 'sparcl']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 11,
                "codebleu": {
                    "codebleu": 0.3606769739613288,
                    "ngram_match_score": 0.006874614919231696,
                    "weighted_ngram_match_score": 0.010924856017658639,
                    "syntax_match_score": 0.8095238095238095,
                    "dataflow_match_score": 0.6153846153846154
                },
                "codebertscore": {
                    "precision": 0.7523952722549438,
                    "recall": 0.745324969291687,
                    "F1": 0.7488434314727783,
                    "F3": 0.7460259795188904
                },
                "codebertscore_rescaled": {
                    "precision": 0.5047905445098877,
                    "recall": 0.490649938583374,
                    "F1": 0.49768686294555664,
                    "F3": 0.49205195903778076
                }
            },
            {
                "ind": 10,
                "gen_code": "# Authentication\ndef login():\n    # Get username and password from the user\n    username = input(\"Enter your Data Lab username: \")\n    password = getpass(\"Enter your Data Lab password: \")\n\n    # Create an authentication client\n    auth = ac.AuthClient()\n\n    # Login to the Data Lab\n    auth.login(username, password)\n\n    # Save the authentication token for later use\n    token = auth.token\n\n    return token\n\n# To login, simply call the function\n# token = login()",
                "true_code": "#token = ac.login(input(\"Enter user name: (+ENTER) \"),getpass(\"Enter password: (+ENTER) \"))\n#ac.whoAmI()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 18,
                "codebleu": {
                    "codebleu": 0.2570820579543679,
                    "ngram_match_score": 0.003519816815769827,
                    "weighted_ngram_match_score": 0.024808415001701823,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.7307600378990173,
                    "recall": 0.7780095934867859,
                    "F1": 0.7536449432373047,
                    "F3": 0.7730115056037903
                },
                "codebertscore_rescaled": {
                    "precision": 0.46152007579803467,
                    "recall": 0.5560191869735718,
                    "F1": 0.5072898864746094,
                    "F3": 0.5460230112075806
                }
            },
            {
                "ind": 12,
                "gen_code": "# Customizing plot settings\nplt.rcParams['font.size'] = 14\nplt.rcParams['axes.linewidth'] = 1.5\nplt.rcParams['xtick.direction'] = 'in'\nplt.rcParams['ytick.direction'] = 'in'\nplt.rcParams['xtick.top'] = True\nplt.rcParams['ytick.right'] = True\nplt.rcParams['xtick.major.size'] = 8\nplt.rcParams['ytick.major.size'] = 8\nplt.rcParams['xtick.minor.size'] = 4\nplt.rcParams['ytick.minor.size'] = 4\nplt.rcParams['xtick.major.width'] = 1.5\nplt.rcParams['ytick.major.width'] = 1.5\nplt.rcParams['xtick.minor.width'] = 1.0\nplt.rcParams['ytick.minor.width'] = 1.0",
                "true_code": "## Setting up plots\n\n# Font size\nfont = {'size':22}\nmatplotlib.rc('font', **font)\n\n# Axes width\nwidth = {'linewidth':3.0}\nmatplotlib.rc('axes', **width)\n\n# x- and y- ticks\nticks = {'major.size':6.0, 'minor.size':4.0, 'major.width':3.0, 'minor.width':1.5, 'direction':'in',\\\n        'minor.visible':True}\nmatplotlib.rc('xtick', **ticks)\nmatplotlib.rc('ytick', **ticks)\n\n# Include top and right ticks \nplt.rcParams['xtick.top'] = True\nplt.rcParams['ytick.right'] = True",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 8,
                "codebleu": {
                    "codebleu": 0.20970676863983773,
                    "ngram_match_score": 0.104229676550087,
                    "weighted_ngram_match_score": 0.11248726770241228,
                    "syntax_match_score": 0.4426229508196721,
                    "dataflow_match_score": 0.1794871794871795
                },
                "codebertscore": {
                    "precision": 0.8850585222244263,
                    "recall": 0.8279570937156677,
                    "F1": 0.8555561304092407,
                    "F3": 0.8333334922790527
                },
                "codebertscore_rescaled": {
                    "precision": 0.7701170444488525,
                    "recall": 0.6559141874313354,
                    "F1": 0.7111122608184814,
                    "F3": 0.6666669845581055
                }
            },
            {
                "ind": 14,
                "gen_code": "# Initialize the SPARCL Client\nsparcl_client = SparclClient()",
                "true_code": "## SPARCL Client\nclient = SparclClient()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 77,
                "codebleu": {
                    "codebleu": 0.5512912253650712,
                    "ngram_match_score": 0.08307018474412793,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8904885053634644,
                    "recall": 0.9630097150802612,
                    "F1": 0.9253303408622742,
                    "F3": 0.9552303552627563
                },
                "codebertscore_rescaled": {
                    "precision": 0.7809770107269287,
                    "recall": 0.9260194301605225,
                    "F1": 0.8506606817245483,
                    "F3": 0.9104607105255127
                }
            },
            {
                "ind": 16,
                "gen_code": "# Emission lines catalog from Portsmouth group\n## Define columns and conditions for accessing the Portsmouth Group emission lines catalog\n\n# Columns to retrieve\ncolumns = ['specobjid', 'h_alpha_flux', 'h_alpha_flux_err', 'h_beta_flux', 'h_beta_flux_err', \n           'nii_6584_flux', 'nii_6584_flux_err', 'oiii_5007_flux', 'oiii_5007_flux_err']\n\n# Conditions for flux errors and signal-to-noise ratios\nconditions = ['h_alpha_flux_err > 0', 'h_beta_flux_err > 0', 'nii_6584_flux_err > 0', 'oiii_5007_flux_err > 0',\n              'h_alpha_flux / h_alpha_flux_err > 3', 'h_beta_flux / h_beta_flux_err > 3', \n              'nii_6584_flux / nii_6584_flux_err > 3', 'oiii_5007_flux / oiii_5007_flux_err > 3']\n\n# Create a structured query\nquery = {\n    \"catalog\": \"dr12.sdss.v5_10_7.portsmouth\",\n    \"columns\": columns,\n    \"conditions\": conditions\n}",
                "true_code": "# List of emission lines we are interested in - \nemission_lines = ('Hb_4861', 'OIII_5006', 'Ha_6562', 'NII_6583')\n\n# Creating a list of columns for all the emission lines for Flux, Flux_Err and Aon for each - \nselected_columns_sdss = ', \\n'.join(['E.Flux_{0}, E.Flux_{0}_Err, E.Aon_{0}'.format(e) for e in emission_lines])\n\n# Conditions - \n# Conditions on flux errors (flux errors > 0 and flux errors != Infinity)\nerr_cond_sdss = ' AND \\n'.join(['(E.Flux_{0}_Err > 0) AND (E.Flux_{0}_Err != \\'Infinity\\')'.format(e) for e in emission_lines])\n# Conditions on Signal to Noise ratio of all the emission lines\nsn_cond_sdss = ' AND \\n'.join(['(E.Flux_{0}/E.Flux_{0}_Err > 5)'.format(e) for e in emission_lines])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.1394397420078292,
                    "ngram_match_score": 0.009331532062640018,
                    "weighted_ngram_match_score": 0.009634332520400883,
                    "syntax_match_score": 0.125,
                    "dataflow_match_score": 0.41379310344827586
                },
                "codebertscore": {
                    "precision": 0.7570055723190308,
                    "recall": 0.7430081963539124,
                    "F1": 0.7499415278434753,
                    "F3": 0.7443846464157104
                },
                "codebertscore_rescaled": {
                    "precision": 0.5140111446380615,
                    "recall": 0.4860163927078247,
                    "F1": 0.4998830556869507,
                    "F3": 0.4887692928314209
                }
            },
            {
                "ind": 18,
                "gen_code": "# Query to get the unique objects with best spectra from emissionlinesport catalog\nquery = \"\"\"\n    SELECT \n        E.specobjid, \n        E.ra, \n        E.dec, \n        E.z, \n        {}\n    FROM \n        emissionlinesport AS E\n    INNER JOIN \n        specobj AS S\n    ON \n        E.specobjid = S.specobjid\n    WHERE \n        S.class = 'GALAXY' AND \n        S.zwarning = 0 AND \n        S.z >= 0.02 AND \n        S.z <= 0.2 AND \n        {}\n    \"\"\".format(selected_columns_sdss, err_cond_sdss + ' AND ' + sn_cond_sdss)\n\n# Execute the query\ndata = qc.query(sql=query)",
                "true_code": "# Write a query for the emission lines from the SDSS DR12 emissionlinesport catalog\n# Applying the S/N cut of >= 5 for all the four emission lines\n# Also applying the conditions that all the flux errors are >0 and != infinity.\n# Applying condition on redshift - only selecting galaxies with 0.02 <= z <= 0.2\n# We add bpt column - which marks the class of the galaxy based on its position on the BPT Diagram\n# We use sdss_joinid to JOIN with SDSS DR16\n# This is to get the SDSS DR16 specobjid of objects - which is used to access the spectra\n\nquery = \"\"\"\nSELECT \nE.ra as ra_sdss, E.dec as dec_sds, E.z, E.bpt,\nE.mjd, E.plate, E.fiberid,\n%s,\nS.specobjid\nFROM sdss_dr12.emissionlinesport as E\nJOIN sdss_dr16.specobj as S\nON (E.sdss_joinid = S.sdss_joinid) AND (E.mjd = S.mjd)\nWHERE (E.z > 0.02) AND (E.z < 0.2) AND\n%s AND\n%s\n\"\"\" %(selected_columns_sdss, err_cond_sdss, sn_cond_sdss)",
                "error_ind": 18,
                "direct_match": false,
                "fuzzy_match": 24,
                "codebleu": {
                    "codebleu": 0.25583925713987005,
                    "ngram_match_score": 0.022353216819839213,
                    "weighted_ngram_match_score": 0.0343371450729743,
                    "syntax_match_score": 0.16666666666666666,
                    "dataflow_match_score": 0.8
                },
                "codebertscore": {
                    "precision": 0.8448899984359741,
                    "recall": 0.7596975564956665,
                    "F1": 0.8000321984291077,
                    "F3": 0.7674357891082764
                },
                "codebertscore_rescaled": {
                    "precision": 0.6897799968719482,
                    "recall": 0.519395112991333,
                    "F1": 0.6000643968582153,
                    "F3": 0.5348715782165527
                }
            },
            {
                "ind": 20,
                "gen_code": "# Display the query to verify its structure\nprint(query)",
                "true_code": "print(query)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 35,
                "codebleu": {
                    "codebleu": 0.5357252520655248,
                    "ngram_match_score": 0.023980296761827107,
                    "weighted_ngram_match_score": 0.11892071150027214,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.7675471305847168,
                    "recall": 0.9097298383712769,
                    "F1": 0.8326120972633362,
                    "F3": 0.893184244632721
                },
                "codebertscore_rescaled": {
                    "precision": 0.5350942611694336,
                    "recall": 0.8194596767425537,
                    "F1": 0.6652241945266724,
                    "F3": 0.7863684892654419
                }
            },
            {
                "ind": 22,
                "gen_code": "# Execute the SQL query to retrieve the refined data set from the emission lines catalog\nresult = qc.query(sql=query)\nprint(result)",
                "true_code": "final_table = qc.query(sql=query, fmt = 'table')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 34,
                "codebleu": {
                    "codebleu": 0.211026391577842,
                    "ngram_match_score": 0.009629943614188135,
                    "weighted_ngram_match_score": 0.040824829046386304,
                    "syntax_match_score": 0.2222222222222222,
                    "dataflow_match_score": 0.5714285714285714
                },
                "codebertscore": {
                    "precision": 0.7537045478820801,
                    "recall": 0.8614572882652283,
                    "F1": 0.803986668586731,
                    "F3": 0.8493151068687439
                },
                "codebertscore_rescaled": {
                    "precision": 0.5074090957641602,
                    "recall": 0.7229145765304565,
                    "F1": 0.6079733371734619,
                    "F3": 0.6986302137374878
                }
            },
            {
                "ind": 26,
                "gen_code": "# Function to access SDSS spectra given a specobjid\ndef get_sdss_spectrum(specobjid, restframe=True):\n    \"\"\"\n    Retrieves SDSS spectrum given a specobjid.\n\n    Parameters:\n    specobjid (int): The unique identifier for the SDSS spectrum.\n    restframe (bool): Whether to return the spectrum in rest-frame (default) or observed-frame.\n\n    Returns:\n    wavelength (numpy array): The wavelength array of the spectrum.\n    flux (numpy array): The flux array of the spectrum.\n    model (numpy array): The model array of the spectrum.\n    ivar (numpy array): The inverse variance array of the spectrum.\n    \"\"\"\n    spectrum = client.get_spectrum(specobjid, restframe=restframe)\n    wavelength = spectrum.wavelength\n    flux = spectrum.flux\n    model = spectrum.model\n    ivar = spectrum.ivar\n    return wavelength, flux, model, ivar\n\n# Function to annotate plots with emission and absorption line identifications\ndef annotate_spectrum(ax, wavelength, flux, emission_lines=None, absorption_lines=None):\n    \"\"\"\n    Annotates a spectrum plot with emission and absorption line identifications.\n\n    Parameters:\n    ax (matplotlib Axes): The Axes object of the plot.\n    wavelength (numpy array): The wavelength array of the spectrum.\n    flux (numpy array): The flux array of the spectrum.\n    emission_lines (list of tuples): A list of tuples containing the wavelength and label of each emission line.\n    absorption_lines (list of tuples): A list of tuples containing the wavelength and label of each absorption line.\n    \"\"\"\n    if emission_lines is not None:\n        for line in emission_lines:\n            ax.axvline(line[0], color='red', linestyle='--')\n            ax.text(line[0], np.max(flux), line[1], rotation=90, ha='center', va='bottom')\n    if absorption_lines is not None:\n        for line in absorption_lines:\n            ax.axvline(line[0], color='blue', linestyle='--')\n            ax.text(line[0], np.max(flux), line[1], rotation=90, ha='center', va='bottom')\n\n# Function to plot SDSS spectra\ndef plot_sdss_spectrum(specobjid, z, wavelength=None, flux=None, model=None, ivar=None, xlim=None, emission_lines=None, absorption_lines=None):\n    \"\"\"\n    Plots an SDSS spectrum.\n\n    Parameters:\n    specobjid (",
                "true_code": "# Assigning variables for the columns required to plot the spectra -\nz = final_table['z'].data\n\n## We need to convert the numpy array of specobjid into a int list to work with SPARCL\nspecobjid = [int(s) for s in final_table['specobjid'].data]",
                "error_ind": 26,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.21611006350567782,
                    "ngram_match_score": 0.0035565730464553903,
                    "weighted_ngram_match_score": 0.024520044612619533,
                    "syntax_match_score": 0.2,
                    "dataflow_match_score": 0.6363636363636364
                },
                "codebertscore": {
                    "precision": 0.6286673545837402,
                    "recall": 0.7502334713935852,
                    "F1": 0.6840916872024536,
                    "F3": 0.7360013127326965
                },
                "codebertscore_rescaled": {
                    "precision": 0.25733470916748047,
                    "recall": 0.5004669427871704,
                    "F1": 0.3681833744049072,
                    "F3": 0.47200262546539307
                }
            },
            {
                "ind": 28,
                "gen_code": "# Print the number of unique entries in the data set\nprint(len(final_table))",
                "true_code": "# Print number of objects in table\nN_table = len(final_table)\nprint(N_table)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 62,
                "codebleu": {
                    "codebleu": 0.4044394935282365,
                    "ngram_match_score": 0.053863663688318665,
                    "weighted_ngram_match_score": 0.06389431042462725,
                    "syntax_match_score": 0.5,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.8923017382621765,
                    "recall": 0.9149083495140076,
                    "F1": 0.9034636616706848,
                    "F3": 0.9125962257385254
                },
                "codebertscore_rescaled": {
                    "precision": 0.784603476524353,
                    "recall": 0.8298166990280151,
                    "F1": 0.8069273233413696,
                    "F3": 0.8251924514770508
                }
            },
            {
                "ind": 30,
                "gen_code": "def get_sdss_spectrum(specobjid, z, restframe=True):\n    \"\"\"\n    Retrieves SDSS spectrum given a specobjid and redshift.\n    \n    Parameters:\n    specobjid (int): Unique identifier for the SDSS spectrum.\n    z (float): Redshift of the object.\n    restframe (bool): Whether to return the spectrum in restframe (default) or observed frame.\n    \n    Returns:\n    wavelength (array): Wavelength array of the spectrum.\n    flux (array): Flux array of the spectrum.\n    model (array): Model array of the spectrum (if available).\n    ivar (array): Inverse variance array of the spectrum (if available).\n    \"\"\"\n    spectrum = client.get_spectrum(specobjid, restframe=restframe)\n    wavelength = spectrum.wavelength\n    flux = spectrum.flux\n    model = spectrum.model\n    ivar = spectrum.ivar\n    return wavelength, flux, model, ivar\n\n\ndef annotate_spectrum(ax, lines, z=0, restframe=True):\n    \"\"\"\n    Annotates a spectrum plot with emission and absorption line identifications.\n    \n    Parameters:\n    ax (matplotlib Axes): Axes object of the plot.\n    lines (list): List of line wavelengths (in vacuum) to annotate.\n    z (float): Redshift of the object (default=0).\n    restframe (bool): Whether the spectrum is in restframe (default) or observed frame.\n    \"\"\"\n    for line in lines:\n        if restframe:\n            line_obs = line[1] * (1 + z)\n        else:\n            line_obs = line[1]\n        ax.axvline(line_obs, color='gray', linestyle='--')\n        ax.text(line_obs, ax.get_ylim()[1] * 0.9, line[0], rotation=90, ha='center')\n\n\ndef plot_sdss_spectrum(specobjid, z, xlim=None, lines=None, model=False, ivar=False):\n    \"\"\"\n    Plots an SDSS spectrum given a specobjid and redshift.\n    \n    Parameters:\n    specobjid (int): Unique identifier for the SDSS spectrum.\n    z (float): Redshift of the object.\n    xlim (tuple): Wavelength range to plot (default=None).\n    lines (list): List of line wavelengths (in vacuum) to annotate (default=None).\n    model (bool): Whether to plot the model spectrum (default=False).\n    ivar (bool): Whether to plot",
                "true_code": "# We will first plot with all the default values - \n# Requires specobjid and z\n\nindex = 10     # Change the value between 0 and N_table-1 to plot different spectra in rest-frame \n\n# Getting the wavelength, flux, model and ivar arrays for the given source\nwavelength, flux, model, ivar = get_sdss_spectra(specobjid[index], rest_frame = True)\nplot_sdss_spectra(wavelength, flux, model, ivar, z[index])",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.13479727079087866,
                    "ngram_match_score": 0.018518359755473147,
                    "weighted_ngram_match_score": 0.08317072340804149,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.4375
                },
                "codebertscore": {
                    "precision": 0.6877175569534302,
                    "recall": 0.7844921350479126,
                    "F1": 0.7329241037368774,
                    "F3": 0.7736060619354248
                },
                "codebertscore_rescaled": {
                    "precision": 0.37543511390686035,
                    "recall": 0.5689842700958252,
                    "F1": 0.4658482074737549,
                    "F3": 0.5472121238708496
                }
            },
            {
                "ind": 32,
                "gen_code": "def get_sdss_spectra(specobjid, rest_frame=False):\n    \"\"\"\n    Retrieves SDSS spectra using SPARCL.\n\n    Parameters:\n    specobjid (int): The unique identifier for the SDSS spectrum.\n    rest_frame (bool): Whether to return the spectrum in the rest frame. Defaults to False.\n\n    Returns:\n    wavelength (numpy array): The wavelength array of the spectrum.\n    flux (numpy array): The flux array of the spectrum.\n    model (numpy array): The model array of the spectrum.\n    ivar (numpy array): The inverse variance array of the spectrum.\n    \"\"\"\n    # Using SPARCL to access the SDSS spectra\n    spectrum = client.get_spectrum(specobjid, rest_frame=rest_frame)\n    wavelength = spectrum.wavelength\n    flux = spectrum.flux\n    model = spectrum.model\n    ivar = spectrum.ivar\n    return wavelength, flux, model, ivar\n\n\ndef annotate_plot(wavelength, lines, ax=None, **kwargs):\n    \"\"\"\n    Annotates a plot with emission and absorption line identifications.\n\n    Parameters:\n    wavelength (numpy array): The wavelength array of the spectrum.\n    lines (list of tuples): A list of tuples containing the line wavelength and label.\n    ax (matplotlib Axes): The axes to annotate. Defaults to None.\n    **kwargs: Additional keyword arguments for the annotate function.\n\n    Returns:\n    None\n    \"\"\"\n    if ax is None:\n        ax = plt.gca()\n    for line in lines:\n        ax.axvline(line[0], color='k', linestyle='--', alpha=0.5)\n        ax.annotate(line[1], (line[0], ax.get_ylim()[1]*0.9), ha='center', **kwargs)\n\n\ndef plot_sdss_spectra(wavelength, flux, model=None, ivar=None, z=None, xlim=None, \n                      emission_lines=None, absorption_lines=None, **kwargs):\n    \"\"\"\n    Plots an SDSS spectrum with optional model and line annotations.\n\n    Parameters:\n    wavelength (numpy array): The wavelength array of the spectrum.\n    flux (numpy array): The flux array of the spectrum.\n    model (numpy array): The model array of the spectrum. Defaults to None.\n    ivar (numpy array): The inverse variance array of the spectrum. Defaults to None.\n    z (float): The redshift of the object. Defaults to None.\n    xlim (tuple): The x-axis limits. Defaults to",
                "true_code": "# Changing the default values for the plotting function\n\nindex = 10           # Change the value between 0 and N_table-1 to plot different spectra in rest-frame \n\nplot_sdss_spectra(wavelength, flux, model, ivar, z[index], rest_frame = True, \\\n                      xlim = [4500, 7000], ylim = None, \\\n                      spectra_kwargs = {'color': 'grey', 'alpha': 0.5}, \\\n                      model_kwargs = {'color': 'k', 'linewidth': 2.0},\\\n                      emission_lines = True, absorption_lines = True, \\\n                      em_lines = None,  abs_lines = [])\n\n# The actual spectra from the SDSS is shown in grey and the model is shown in black.\n# You can change it to any color that you want by using the spectra_kwargs and model_kwargs keywords.",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.13716211581712237,
                    "ngram_match_score": 0.004129685732904142,
                    "weighted_ngram_match_score": 0.011185444202251978,
                    "syntax_match_score": 0.2,
                    "dataflow_match_score": 0.3333333333333333
                },
                "codebertscore": {
                    "precision": 0.733635425567627,
                    "recall": 0.78046715259552,
                    "F1": 0.7563270330429077,
                    "F3": 0.7755166292190552
                },
                "codebertscore_rescaled": {
                    "precision": 0.4672708511352539,
                    "recall": 0.56093430519104,
                    "F1": 0.5126540660858154,
                    "F3": 0.5510332584381104
                }
            },
            {
                "ind": 34,
                "gen_code": "# Define the function to get SDSS spectra using SPARCL\ndef get_sdss_spectra(specobjid, rest_frame=False):\n    \"\"\"\n    Function to get SDSS spectra using SPARCL.\n    \n    Parameters:\n    specobjid (int): The specobjid of the object.\n    rest_frame (bool): Whether to return the spectra in rest-frame or observed-frame. Default is False.\n    \n    Returns:\n    wavelength (array): The wavelength array of the spectrum.\n    flux (array): The flux array of the spectrum.\n    model (array): The model array of the spectrum.\n    ivar (array): The inverse variance array of the spectrum.\n    \"\"\"\n    # Use SPARCL to get the spectrum\n    spectrum = client.get_spectrum(specobjid)\n    \n    # Get the wavelength, flux, model, and ivar arrays\n    wavelength = spectrum.wavelength\n    flux = spectrum.flux\n    model = spectrum.model\n    ivar = spectrum.ivar\n    \n    # If rest_frame is True, convert the spectrum to rest-frame\n    if rest_frame:\n        # Get the redshift of the object\n        redshift = final_table['z'][final_table['specobjid'] == specobjid].data[0]\n        \n        # Convert the wavelength to rest-frame\n        wavelength /= (1 + redshift)\n    \n    return wavelength, flux, model, ivar\n\n# Define the function to plot SDSS spectra\ndef plot_sdss_spectra(wavelength, flux, model, ivar, z, rest_frame=False, xlim=None, ylim=None, \n                       spectra_kwargs={}, model_kwargs={}, emission_lines=False, absorption_lines=False, \n                       em_lines=None, abs_lines=None):\n    \"\"\"\n    Function to plot SDSS spectra.\n    \n    Parameters:\n    wavelength (array): The wavelength array of the spectrum.\n    flux (array): The flux array of the spectrum.\n    model (array): The model array of the spectrum.\n    ivar (array): The inverse variance array of the spectrum.\n    z (float): The redshift of the object.\n    rest_frame (bool): Whether the spectrum is in rest-frame or observed-frame. Default is False.\n    xlim (list): The x-axis limits of the plot. Default is None.\n    ylim (list): The y-axis limits of the plot. Default is None.\n    spectra_kwargs (dict): The keyword arguments for the spectrum plot. Default is {}.\n    model_kwargs (",
                "true_code": "# Computing the logarithm of line ratios for the BPT Diagram - \nNii_Ha = np.log10(final_table['flux_nii_6583']/final_table['flux_ha_6562'])\nOiii_Hb = np.log10(final_table['flux_oiii_5006']/final_table['flux_hb_4861'])",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.28856240349985374,
                    "ngram_match_score": 0.001930105812086378,
                    "weighted_ngram_match_score": 0.033271889139709514,
                    "syntax_match_score": 0.47619047619047616,
                    "dataflow_match_score": 0.6428571428571429
                },
                "codebertscore": {
                    "precision": 0.6082742214202881,
                    "recall": 0.668489933013916,
                    "F1": 0.6369621157646179,
                    "F3": 0.6619370579719543
                },
                "codebertscore_rescaled": {
                    "precision": 0.21654844284057617,
                    "recall": 0.33697986602783203,
                    "F1": 0.27392423152923584,
                    "F3": 0.3238741159439087
                }
            },
            {
                "ind": 36,
                "gen_code": "```python\n# Assigning the 'bpt' field from final_table to a variable\nbpt_class = final_table['bpt'].data\n\n# Creating boolean conditions to flag different galaxy types\nis_star_forming = (bpt_class == 1)\nis_seyfert = (bpt_class == 2)\nis_liner = (bpt_class == 3)\nis_composite = (bpt_class == 4)\n```\n\n<MARKDOWN>\n# Stacking spectra\nWe're now moving towards stacking spectra of galaxies from each BPT class. This process involves aligning and combining the spectra to increase the signal-to-noise ratio, allowing for a clearer study of their average properties. To start, define a function `stack_spectra()` that takes in the `specobjid` list and redshift `z` as inputs. This function should utilize SPARCL to access the spectra, align them to a common rest-frame, and then stack them. Consider incorporating error propagation to compute the stacked spectrum's uncertainty.\n<CELL END>\n\n<PYTHON CODE>\ndef stack_spectra(specobjid, z):\n    # Initialize arrays to store the stacked spectrum and its uncertainty\n    stacked_spectrum = None\n    stacked_ivar = None\n    \n    # Loop through each specobjid and its corresponding redshift\n    for i in range(len(specobjid)):\n        # Access the spectrum using SPARCL\n        wavelength, flux, model, ivar = get_sdss_spectra(specobjid[i], rest_frame=True)\n        \n        # If this is the first spectrum, initialize the stacked arrays\n        if stacked_spectrum is None:\n            stacked_spectrum = np.zeros_like(flux)\n            stacked_ivar = np.zeros_like(ivar)\n        \n        # Align the spectrum to the common rest-frame\n        aligned_spectrum = flux / (1 + z[i])\n        \n        # Stack the spectrum and propagate the uncertainty\n        stacked_spectrum += aligned_spectrum\n        stacked_ivar += ivar / (1 + z[i])**2\n    \n    # Compute the final stacked spectrum and its uncertainty\n    stacked_spectrum /= len(specobjid)\n    stacked_ivar = 1 / stacked_ivar\n    \n    return wavelength, stacked_spectrum, stacked_ivar\n<CELL END>\n\n<MARKDOWN>\n## Selecting galaxies from the BPT diagram\nTo stack spectra from each BPT class, we need to select the corresponding galaxies. Utilize the boolean conditions created earlier to filter the `specobjid",
                "true_code": "# Assigning a variable for the bpt column\nbpt = final_table['bpt']   # BPT Classification\n\n# Creating labels for the different classes based on BPT Column - \nis_sf = (bpt == 'Star Forming')\nis_sy = (bpt == 'Seyfert')\nis_comp = (bpt == 'Composite')\nis_liner = (bpt == 'LINER')",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.09982087900334366,
                    "ngram_match_score": 0.0034670892847095372,
                    "weighted_ngram_match_score": 0.022483093395331784,
                    "syntax_match_score": 0.24,
                    "dataflow_match_score": 0.13333333333333333
                },
                "codebertscore": {
                    "precision": 0.6187838912010193,
                    "recall": 0.8461601734161377,
                    "F1": 0.7148262858390808,
                    "F3": 0.8161694407463074
                },
                "codebertscore_rescaled": {
                    "precision": 0.23756778240203857,
                    "recall": 0.6923203468322754,
                    "F1": 0.4296525716781616,
                    "F3": 0.6323388814926147
                }
            },
            {
                "ind": 38,
                "gen_code": "# Define a function to access SDSS spectra given a specific specobjid\ndef get_sdss_spectra(specobjid, rest_frame=False):\n    # Use SPARCL to access SDSS spectra\n    spectra = client.get_spectra(specobjid, rest_frame=rest_frame)\n    # Return wavelength, flux, model, and inverse variance arrays\n    return spectra.wavelength, spectra.flux, spectra.model, spectra.ivar\n\n# Define a function to annotate plots with emission and absorption line identifications\ndef annotate_spectrum(ax, wavelength, emission_lines=True, absorption_lines=True, em_lines=None, abs_lines=None):\n    # Define default emission and absorption lines\n    default_em_lines = [4861, 5006, 6562, 6583]  # Hb, OIII, Ha, NII\n    default_abs_lines = [3727, 3933, 3968, 4102, 4304, 4341, 4364, 4471, 4686, 4713, 4861, 4922, 4959, 5007, 5015, 5041, 5056, 5170, 5198, 5236, 5271, 5299, 5317, 5334, 5371, 5412, 5426, 5433, 5518, 5528, 5542, 5555, 5563, 5577, 5585, 5592, 5606, 5635, 5640, 5668, 5676, 5686, 5696, 5705, 5710, 5713, 5721, 5728, 5737, 5741, 5755, 5762, 5778, 5792, 5797, 5806, 5812, 5819, 5824, 5835, 5843, 5850, 5853, 5864, 5876, 5889, 5894, 5902, 5915, 5929, 5931, 5941, 5953, 5960, 5964, 5976, 5984, 5993, 6006, 6016, 6021, 6032, 6041",
                "true_code": "# 2-d histogram density of all the galaxies\ndens_all,_,_ = np.histogram2d(Nii_Ha, Oiii_Hb, range=[[-2.0, 0.75],[-1.2, 1.2]], bins=100, density=True)\ndens_all = dens_all.T",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.14972955159203746,
                    "ngram_match_score": 0.0014491661938921757,
                    "weighted_ngram_match_score": 0.012673718536830811,
                    "syntax_match_score": 0.1111111111111111,
                    "dataflow_match_score": 0.47368421052631576
                },
                "codebertscore": {
                    "precision": 0.523061215877533,
                    "recall": 0.6627211570739746,
                    "F1": 0.5846666693687439,
                    "F3": 0.6454863548278809
                },
                "codebertscore_rescaled": {
                    "precision": 0.04612243175506592,
                    "recall": 0.3254423141479492,
                    "F1": 0.1693333387374878,
                    "F3": 0.2909727096557617
                }
            },
            {
                "ind": 40,
                "gen_code": "# Function to get the SDSS spectra\ndef get_sdss_spectra(specobjid, rest_frame = False):\n    # Using SPARCL to get the SDSS spectra\n    spectrum = client.get_spectrum(specobjid, rest_frame = rest_frame)\n    wavelength = spectrum.wavelength\n    flux = spectrum.flux\n    model = spectrum.model\n    ivar = spectrum.ivar\n    return wavelength, flux, model, ivar\n\n# Function to plot the SDSS spectra\ndef plot_sdss_spectra(wavelength, flux, model, ivar, z, rest_frame = False, \\\n                      xlim = None, ylim = None, \\\n                      spectra_kwargs = {}, model_kwargs = {}, \\\n                      emission_lines = False, absorption_lines = False, \\\n                      em_lines = None,  abs_lines = None):\n    # Plotting the SDSS spectra\n    plt.figure(figsize = (10,6))\n    plt.plot(wavelength, flux, **spectra_kwargs)\n    if model is not None:\n        plt.plot(wavelength, model, **model_kwargs)\n    plt.xlabel('Wavelength ($\\AA$)')\n    plt.ylabel('Flux')\n    plt.title('SDSS Spectrum')\n    \n    # Annotating the emission and absorption lines\n    if emission_lines:\n        em_lines = ['Hb_4861', 'OIII_5006', 'Ha_6562', 'NII_6583'] if em_lines is None else em_lines\n        em_wavelengths = [4861, 5006, 6562, 6583]\n        for em_line, em_wavelength in zip(em_lines, em_wavelengths):\n            plt.axvline(em_wavelength, color = 'k', linestyle = '--', alpha = 0.5)\n            plt.annotate(em_line, (em_wavelength, np.max(flux)), textcoords=\"offset points\", xytext=(0,10), ha='center')\n    \n    if absorption_lines:\n        abs_lines = ['CaII_K_3933', 'CaII_H_3968', 'NaI_D_5890', 'MgI_b_5175'] if abs_lines is None else abs_lines\n        abs_wavelengths = [3933, 3968, 5890, 5175]\n        for abs_line, abs_wavelength in zip(abs_lines, abs_wavelengths):\n            plt.axvline(abs_wavelength, color = 'k',",
                "true_code": "# BPT Diagram color-coded based on the class\nplt.figure(figsize = (8,8))\nplt.scatter(Nii_Ha[is_sy], Oiii_Hb[is_sy], color = 'r', s = 1.0)             # Seyferts in red (r)\nplt.scatter(Nii_Ha[is_sf], Oiii_Hb[is_sf], color = 'b', s = 1.0)             # SF in blue (b)\nplt.scatter(Nii_Ha[is_comp], Oiii_Hb[is_comp], color = 'g', s = 1.0)         # Composites in green (g)\nplt.scatter(Nii_Ha[is_liner], Oiii_Hb[is_liner], color = 'purple', s = 1.0)  # LINERs in purple\nplt.contour(dens_all, colors = 'white', extent = (-2.0, 0.75, -1.2, 1.2), levels = [0.0, 0.1, 0.2, 0.3, 0.5, 1.5, 3.0, 6.0])\nplt.xlim([-2, 0.75])\nplt.ylim([-1.2, 1.2])\nplt.text(-1.0, -0.5, 'SF', color = 'blue', fontsize = 18)\nplt.text(0.0, -1.0, 'Composite', color = 'green', fontsize = 18)\nplt.text(0.5, 0.2, 'LINER', color = 'purple', fontsize = 18, rotation = 90)\nplt.text(-0.9, 1.0, 'Seyfert', color = 'r', fontsize = 18)\nplt.xlabel('log ([NII]/H$\\\\alpha$)')\nplt.ylabel('log ([OIII]/H$\\\\beta$)')\nplt.show()",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.19910399174077228,
                    "ngram_match_score": 0.005223554771466016,
                    "weighted_ngram_match_score": 0.007859078858289723,
                    "syntax_match_score": 0.38333333333333336,
                    "dataflow_match_score": 0.4
                },
                "codebertscore": {
                    "precision": 0.6708633899688721,
                    "recall": 0.7174031734466553,
                    "F1": 0.6933531761169434,
                    "F3": 0.7124606370925903
                },
                "codebertscore_rescaled": {
                    "precision": 0.34172677993774414,
                    "recall": 0.43480634689331055,
                    "F1": 0.3867063522338867,
                    "F3": 0.42492127418518066
                }
            },
            {
                "ind": 45,
                "gen_code": "def get_sdss_spectra(specobjid, rest_frame=False):\n    \"\"\"\n    Retrieves the wavelength, flux, model, and inverse variance arrays for a given SDSS object.\n    \n    Parameters:\n    specobjid (int): The unique identifier for the SDSS object.\n    rest_frame (bool): If True, returns the spectra in the rest frame; otherwise, returns in the observed frame.\n    \n    Returns:\n    wavelength (numpy array): The wavelength array of the spectrum.\n    flux (numpy array): The flux array of the spectrum.\n    model (numpy array): The model array of the spectrum.\n    ivar (numpy array): The inverse variance array of the spectrum.\n    \"\"\"\n    # Retrieve the spectrum from SPARCL\n    spectrum = client.get_spectrum(specobjid, rest_frame=rest_frame)\n    \n    # Extract the wavelength, flux, model, and inverse variance arrays\n    wavelength = spectrum.wavelength\n    flux = spectrum.flux\n    model = spectrum.model\n    ivar = spectrum.ivar\n    \n    return wavelength, flux, model, ivar\n\n\ndef plot_sdss_spectra(wavelength, flux, model, ivar, z, rest_frame=False, \n                       xlim=None, ylim=None, spectra_kwargs=None, model_kwargs=None, \n                       emission_lines=False, absorption_lines=False, em_lines=None, abs_lines=None):\n    \"\"\"\n    Plots the SDSS spectrum with optional model and emission/absorption lines.\n    \n    Parameters:\n    wavelength (numpy array): The wavelength array of the spectrum.\n    flux (numpy array): The flux array of the spectrum.\n    model (numpy array): The model array of the spectrum.\n    ivar (numpy array): The inverse variance array of the spectrum.\n    z (float): The redshift of the object.\n    rest_frame (bool): If True, plots the spectrum in the rest frame; otherwise, plots in the observed frame.\n    xlim (list): The x-axis limits for the plot.\n    ylim (list): The y-axis limits for the plot.\n    spectra_kwargs (dict): Keyword arguments for the spectrum plot.\n    model_kwargs (dict): Keyword arguments for the model plot.\n    emission_lines (bool): If True, plots the emission lines.\n    absorption_lines (bool): If True, plots the absorption lines.\n    em_lines (list): A list of emission line wavelengths.\n    abs_lines (list): A list of absorption line wavelengths.\n    \"\"\"\n    # Create the plot\n   ",
                "true_code": "## Function 4 -\n\ndef stack_spectra(table):\n    \"\"\"\n    Function to Stack the spectra of all the sources in the given table.\n    Uses SPARCL to retrieve spectra\n    \n    Returns an inverse variance weighted mean of the input spectra.\n    \n    Parameters\n    ----------\n    table : table\n        Table of sources whose spectra need to be stacked\n    \n    Returns\n    -------\n    wavelength_stack : array\n        Wavelength array of the stacked spectra\n        \n    flux_stack : array\n        Flux array of the stacked spectra\n    \n    model_stack : array\n        Model array of the stacked spectra\n    \n    \"\"\"\n    \n    # Create an array with the targeted loglam values - reference array\n    loglam_ref = np.arange(3.5000, 3.9000, 0.0001).astype('float32')\n    \n    # Create empty lists for flux, ivar and model - \n    flux_array = []\n    model_array = []\n    ivar_array = []\n    \n    # Extract the necessary columns from the table\n    # redshift = table['z']\n    specobjid = [int(s) for s in table['specobjid'].data]\n    \n    # Number of spectra - \n    n = len(table)\n    \n    ## Retrieve the spectra\n    res = client.retrieve_by_specid(specid_list = specobjid, \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    ## All the spectra have the same spacing in log wavelength.\n    ## We shift the spectra in the observed wavelength range to fill the same log wavelength range\n    ## Join the different arrays of the individual spectra into a single array\n    \n    ## Compared the number of retrieved spectra to the number of requested spectra\n    ## NOTE: some datasets have missing spectra with inconsistent data models, which will be added at the \n    ##       next re-ingestion. Stats available here: https://astrosparcl.datalab.noirlab.edu/sparc/datasetnotes/\n    n_res = res.count\n    n_use = np.min([n_res, n])\n    if n_res!=n:\n        print(f\"WARNING: {n_res} spectra were retrieved from the requested {n}! Will proceed with {n_use} spectra.\")\n        \n    for ii in range(n_use):   \n                \n        ## Get rest-frame spectra of each object\n        res_rec = res.records[ii]\n        z = res_rec.redshift\n        lam = res_rec.wavelength/(1+z)\n        flux = res_rec.flux*(1+z)\n        model = res_rec.model*(1+z)\n        ivar = res_rec.ivar/((1+z)**2)\n        \n        loglam = np.around(np.log10(lam), 4).astype('float32')\n        # The log of reference wavelength and log of wavelength range of each spectra are converted to 'float32'\n        # This helps in avoiding the rounding errors\n        \n        # Creating empty arrays for flux, inverse variance and model \n        # with the same length as the reference loglam array\n        fl = np.zeros(len(loglam_ref))\n        iv = np.zeros(len(loglam_ref))\n        ml = np.zeros(len(loglam_ref))\n        \n        # Truth_array - A boolen array which will define what pixels the spectra have been shifted to\n        truth_array = np.zeros(len(loglam_ref), dtype = bool)\n        \n        # Find common elements between the reference and spectra wavelengths - \n        ll_common = np.intersect1d(loglam_ref, loglam)\n        \n        # Finding the indices of the first pixel in the common array in both reference and spectrum arrays\n        ref_start = np.where(loglam_ref == ll_common[0])[0][0]\n        spec_start = np.where(loglam == ll_common[0])[0][0]\n        \n        m = min(len(loglam_ref[ref_start:]), len(loglam[spec_start:]))\n        \n        # Match the first pixel of the common loglam values with the reference array \n        # Mark the number of pixels with the spectra starting from the first pixel to be True\n        truth_array[ref_start:ref_start+m] = True\n\n        # Fill the flux, inverse variance and model arrays\n        fl[truth_array] = flux[spec_start:spec_start+m]\n        iv[truth_array] = ivar[spec_start:spec_start+m]\n        ml[truth_array] = model[spec_start:spec_start+m]\n        \n        # Where the reference array is empty, fill the flux and model with nan values\n        # Set inverse variance to zero for these pixels\n        fl[~truth_array] = np.nan\n        iv[~truth_array] = 0.0\n        ml[~truth_array] = np.nan\n        \n        # Create a masked array with 'nan' values marked\n        # This avoids the pixels filled with 'nan' when stacking\n        fl = np.ma.masked_array(fl, np.isnan(fl))\n        iv = np.ma.masked_array(iv, np.isnan(iv))\n        ml = np.ma.masked_array(ml, np.isnan(ml))\n        \n        flux_array.append(fl)\n        model_array.append(ml)\n        ivar_array.append(iv)\n        \n    # Stack the spectra by weighted average \n    wavelength_stack = 10**(loglam_ref)\n    flux_stack = np.ma.average(flux_array, axis = 0, weights = ivar_array)\n    model_stack = np.ma.average(model_array, axis = 0, weights = ivar_array)\n    \n    flux_stack = flux_stack.filled(np.nan)\n    model_stack = model_stack.filled(np.nan)\n    \n    return (wavelength_stack, flux_stack, model_stack)",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.05932391919130402,
                    "ngram_match_score": 0.015495207129488394,
                    "weighted_ngram_match_score": 0.02315182098707902,
                    "syntax_match_score": 0.14864864864864866,
                    "dataflow_match_score": 0.05
                },
                "codebertscore": {
                    "precision": 0.8005298972129822,
                    "recall": 0.7290987372398376,
                    "F1": 0.7631464004516602,
                    "F3": 0.7356629967689514
                },
                "codebertscore_rescaled": {
                    "precision": 0.6010597944259644,
                    "recall": 0.4581974744796753,
                    "F1": 0.5262928009033203,
                    "F3": 0.47132599353790283
                }
            },
            {
                "ind": 47,
                "gen_code": "# Define the lower-left vertex coordinates for each of the four squares representing distinct galaxy types\nsquare_coords = {\n    'Seyfert': (-0.8, 0.4),\n    'Star-Forming': (-1.8, -0.8),\n    'LINER': (-0.2, 0.8),\n    'Composite': (-0.8, -0.2)\n}\n\n# Set a uniform width and height for these squares\nsquare_width = 0.6\nsquare_height = 0.6\n\n# Create boolean masks for each galaxy type based on the defined squares\nis_seyfert = (Nii_Ha > square_coords['Seyfert'][0]) & (Nii_Ha < square_coords['Seyfert'][0] + square_width) & \\\n             (Oiii_Hb > square_coords['Seyfert'][1]) & (Oiii_Hb < square_coords['Seyfert'][1] + square_height)\n\nis_star_forming = (Nii_Ha > square_coords['Star-Forming'][0]) & (Nii_Ha < square_coords['Star-Forming'][0] + square_width) & \\\n                  (Oiii_Hb > square_coords['Star-Forming'][1]) & (Oiii_Hb < square_coords['Star-Forming'][1] + square_height)\n\nis_liner = (Nii_Ha > square_coords['LINER'][0]) & (Nii_Ha < square_coords['LINER'][0] + square_width) & \\\n           (Oiii_Hb > square_coords['LINER'][1]) & (Oiii_Hb < square_coords['LINER'][1] + square_height)\n\nis_composite = (Nii_Ha > square_coords['Composite'][0]) & (Nii_Ha < square_coords['Composite'][0] + square_width) & \\\n               (Oiii_Hb > square_coords['Composite'][1]) & (Oiii_Hb < square_coords['Composite'][1] + square_height)\n\n# Select a random subset of galaxies from each type for stacking\nnp.random.seed(42)  # For reproducibility\nn_stack = 100\n\nseyfert_stack_idx = np.random.choice(np.where(is_seyfert)[0], n_stack, replace=False)\nstar_forming_stack_idx = np.random.choice(np.where(is_star_forming)[0],",
                "true_code": "## Defining vertices the lower-left corners of the four squares\nsy_x, sy_y = -0.15, 0.55\nsf_x, sf_y = -0.65, -0.05\nliner_x, liner_y = 0.0, 0.05\ncomp_x, comp_y = -0.25, 0.0\n\n# Defining the width and height size\nwidth = 0.1\nheight = 0.1",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.19947970848681604,
                    "ngram_match_score": 0.023968664677015562,
                    "weighted_ngram_match_score": 0.10395016927024861,
                    "syntax_match_score": 0.32,
                    "dataflow_match_score": 0.35
                },
                "codebertscore": {
                    "precision": 0.6166115999221802,
                    "recall": 0.8065082430839539,
                    "F1": 0.6988903284072876,
                    "F3": 0.7824124693870544
                },
                "codebertscore_rescaled": {
                    "precision": 0.23322319984436035,
                    "recall": 0.6130164861679077,
                    "F1": 0.3977806568145752,
                    "F3": 0.5648249387741089
                }
            },
            {
                "ind": 49,
                "gen_code": "## Function 1 - \ndef get_sdss_spectra(specobjid, rest_frame = False):\n    \"\"\"\n    Function to get SDSS spectra using SPARCL\n    \n    Parameters\n    ----------\n    specobjid : int\n        Unique identifier for the SDSS object\n        \n    rest_frame : bool\n        Whether to return the spectra in rest-frame or not\n        \n    Returns\n    -------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    flux : array\n        Flux array of the spectra\n        \n    model : array\n        Model array of the spectra\n        \n    ivar : array\n        Inverse variance array of the spectra\n    \"\"\"\n    \n    res = client.retrieve_by_specid(specid_list = [specobjid], \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    res_rec = res.records[0]\n    z = res_rec.redshift\n    lam = res_rec.wavelength\n    flux = res_rec.flux\n    model = res_rec.model\n    ivar = res_rec.ivar\n    \n    if rest_frame:\n        lam = lam/(1+z)\n        flux = flux*(1+z)\n        model = model*(1+z)\n        ivar = ivar/((1+z)**2)\n        \n    return (lam, flux, model, ivar)\n\n\n## Function 2 - \ndef plot_sdss_spectra(wavelength, flux, model, ivar, z, rest_frame = False, \\\n                      xlim = None, ylim = None, \\\n                      spectra_kwargs = {'color': 'k', 'alpha': 0.5}, \\\n                      model_kwargs = {'color': 'r', 'linewidth': 2.0},\\\n                      emission_lines = False, absorption_lines = False, \\\n                      em_lines = None,  abs_lines = None):\n    \"\"\"\n    Function to plot SDSS spectra\n    \n    Parameters\n    ----------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    flux : array\n        Flux array of the spectra\n        \n    model : array\n        Model array of the spectra\n        \n    ivar : array\n        Inverse variance array of the spectra\n        \n    z : float\n        Redshift of the object\n        \n    rest_frame : bool\n        Whether the spectra is in rest-frame or not\n        \n    xlim : tuple\n",
                "true_code": "s1= Rectangle(xy = (sy_x, sy_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\ns2 = Rectangle(xy = (sf_x, sf_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\ns3 = Rectangle(xy = (liner_x, liner_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\ns4 = Rectangle(xy = (comp_x, comp_y), width = width, height = height, color = 'white', lw = 3.0, fill = False)\n\nplt.figure(figsize = (8,8))\n\nplt.scatter(Nii_Ha[is_sy], Oiii_Hb[is_sy], color = 'r', s = 1.0)\nplt.scatter(Nii_Ha[is_sf], Oiii_Hb[is_sf], color = 'b', s = 1.0)\nplt.scatter(Nii_Ha[is_comp], Oiii_Hb[is_comp], color = 'g', s = 1.0)\nplt.scatter(Nii_Ha[is_liner], Oiii_Hb[is_liner], color = 'purple', s = 1.0)\nplt.gca().add_patch(s1)\nplt.gca().add_patch(s2)\nplt.gca().add_patch(s3)\nplt.gca().add_patch(s4)\nplt.text(-1.0, -0.5, 'SF', color = 'blue', fontsize = 18)\nplt.text(0.0, -1.0, 'Composite', color = 'green', fontsize = 18)\nplt.text(0.5, 0.2, 'LINER', color = 'purple', fontsize = 18, rotation = 90)\nplt.text(-0.9, 1.0, 'Seyfert', color = 'r', fontsize = 18)\nplt.xlim([-2, 0.75])\nplt.ylim([-1.2, 1.2])\nplt.xlabel('log ([NII]/H$\\\\alpha$)')\nplt.ylabel('log ([OIII]/H$\\\\beta$)')\n\nplt.show()",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.1279716725171821,
                    "ngram_match_score": 0.001667252551566934,
                    "weighted_ngram_match_score": 0.002359905744586272,
                    "syntax_match_score": 0.18478260869565216,
                    "dataflow_match_score": 0.3230769230769231
                },
                "codebertscore": {
                    "precision": 0.6435030102729797,
                    "recall": 0.6795818209648132,
                    "F1": 0.6610504984855652,
                    "F3": 0.6757928729057312
                },
                "codebertscore_rescaled": {
                    "precision": 0.2870060205459595,
                    "recall": 0.35916364192962646,
                    "F1": 0.32210099697113037,
                    "F3": 0.3515857458114624
                }
            },
            {
                "ind": 51,
                "gen_code": "# Identify the indices of the galaxies falling within the defined rectangular regions on the BPT plot\nsy_idx = np.where((Nii_Ha[is_sy] > sy_x) & (Nii_Ha[is_sy] < (sy_x + width)) & \n                  (Oiii_Hb[is_sy] > sy_y) & (Oiii_Hb[is_sy] < (sy_y + height)))[0]\n\nsf_idx = np.where((Nii_Ha[is_sf] > sf_x) & (Nii_Ha[is_sf] < (sf_x + width)) & \n                  (Oiii_Hb[is_sf] > sf_y) & (Oiii_Hb[is_sf] < (sf_y + height)))[0]\n\nliner_idx = np.where((Nii_Ha[is_liner] > liner_x) & (Nii_Ha[is_liner] < (liner_x + width)) & \n                     (Oiii_Hb[is_liner] > liner_y) & (Oiii_Hb[is_liner] < (liner_y + height)))[0]\n\ncomp_idx = np.where((Nii_Ha[is_comp] > comp_x) & (Nii_Ha[is_comp] < (comp_x + width)) & \n                    (Oiii_Hb[is_comp] > comp_y) & (Oiii_Hb[is_comp] < (comp_y + height)))[0]",
                "true_code": "# Regions of the white boxes - \n# Getting the indices of the sources within the four boxes\nsy_box = np.where((Nii_Ha >= sy_x) & (Nii_Ha <= sy_x+width) & (Oiii_Hb >= sy_y) & (Oiii_Hb <= sy_y+height))[0]\nsf_box = np.where((Nii_Ha >= sf_x) & (Nii_Ha <= sf_x+width) & (Oiii_Hb >= sf_y) & (Oiii_Hb <= sf_y+height))[0]\nliner_box = np.where((Nii_Ha >= liner_x) & (Nii_Ha <= liner_x+width) & (Oiii_Hb >= liner_y) & (Oiii_Hb <= liner_y+height))[0]\ncomp_box = np.where((Nii_Ha >= comp_x) & (Nii_Ha <= comp_x+width) & (Oiii_Hb >= comp_y) & (Oiii_Hb <= comp_y+height))[0]",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 58,
                "codebleu": {
                    "codebleu": 0.2329435239548795,
                    "ngram_match_score": 0.05291083849492647,
                    "weighted_ngram_match_score": 0.06230481576615002,
                    "syntax_match_score": 0.15584415584415584,
                    "dataflow_match_score": 0.6607142857142857
                },
                "codebertscore": {
                    "precision": 0.8699074983596802,
                    "recall": 0.9138808250427246,
                    "F1": 0.8913521766662598,
                    "F3": 0.9092845320701599
                },
                "codebertscore_rescaled": {
                    "precision": 0.7398149967193604,
                    "recall": 0.8277616500854492,
                    "F1": 0.7827043533325195,
                    "F3": 0.8185690641403198
                }
            },
            {
                "ind": 53,
                "gen_code": "# Function to access SDSS spectra given a specific specobjid\ndef get_sdss_spectra(specobjid, rest_frame = False):\n    \"\"\"\n    Function to retrieve SDSS spectra given a specific specobjid\n    \n    Parameters\n    ----------\n    specobjid : int\n        Unique identifier for the SDSS object\n        \n    rest_frame : bool\n        Whether to return the spectrum in the rest-frame or not\n        \n    Returns\n    -------\n    wavelength : array\n        Wavelength array of the spectrum\n        \n    flux : array\n        Flux array of the spectrum\n        \n    model : array\n        Model array of the spectrum\n        \n    ivar : array\n        Inverse variance array of the spectrum\n    \"\"\"\n    \n    res = client.retrieve_by_specid(specid_list = [specobjid], \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    res_rec = res.records[0]\n    z = res_rec.redshift\n    lam = res_rec.wavelength\n    flux = res_rec.flux\n    model = res_rec.model\n    ivar = res_rec.ivar\n    \n    if rest_frame:\n        lam = lam/(1+z)\n        flux = flux*(1+z)\n        model = model*(1+z)\n        ivar = ivar/((1+z)**2)\n    \n    return (lam, flux, model, ivar)\n\n\n# Function to annotate plots with emission and absorption line identifications\ndef annotate_lines(ax, em_lines = True, abs_lines = True, em_lines_list = None, abs_lines_list = None):\n    \"\"\"\n    Function to annotate plots with emission and absorption line identifications\n    \n    Parameters\n    ----------\n    ax : Axes\n        Axes to annotate\n        \n    em_lines : bool\n        Whether to annotate emission lines or not\n        \n    abs_lines : bool\n        Whether to annotate absorption lines or not\n        \n    em_lines_list : list\n        List of emission lines to annotate\n        \n    abs_lines_list : list\n        List of absorption lines to annotate\n    \"\"\"\n    \n    # Default emission lines\n    if em_lines_list is None:\n        em_lines_list = [4861, 4959, 5007, 6563, 6583]\n    \n    # Default absorption lines\n    if abs_lines_list is None:\n        abs_lines_list = [",
                "true_code": "len(final_table[sy_box]), len(final_table[sf_box]), len(final_table[comp_box]), len(final_table[liner_box])",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.09375,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.375
                },
                "codebertscore": {
                    "precision": 0.5052147507667542,
                    "recall": 0.6163620948791504,
                    "F1": 0.5552811622619629,
                    "F3": 0.6030939817428589
                },
                "codebertscore_rescaled": {
                    "precision": 0.0104295015335083,
                    "recall": 0.23272418975830078,
                    "F1": 0.11056232452392578,
                    "F3": 0.20618796348571777
                }
            },
            {
                "ind": 55,
                "gen_code": "# Function to get SDSS spectra\ndef get_sdss_spectra(specobjid, rest_frame = False):\n    \"\"\"\n    Function to get SDSS spectra using SPARCL\n    \n    Parameters\n    ----------\n    specobjid : int\n        The specobjid of the object whose spectra needs to be retrieved\n    rest_frame : bool\n        Whether to retrieve the spectra in rest-frame or not\n    \n    Returns\n    -------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    flux : array\n        Flux array of the spectra\n        \n    model : array\n        Model array of the spectra\n        \n    ivar : array\n        Inverse variance array of the spectra\n    \"\"\"\n    \n    # Retrieve the spectra\n    res = client.retrieve_by_specid(specid_list = [specobjid], \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    # Get rest-frame spectra of each object\n    res_rec = res.records[0]\n    z = res_rec.redshift\n    lam = res_rec.wavelength/(1+z)\n    flux = res_rec.flux*(1+z)\n    model = res_rec.model*(1+z)\n    ivar = res_rec.ivar/((1+z)**2)\n    \n    if rest_frame:\n        return lam, flux, model, ivar\n    else:\n        return res_rec.wavelength, res_rec.flux, res_rec.model, res_rec.ivar\n\n# Function to plot SDSS spectra\ndef plot_sdss_spectra(wavelength, flux, model, ivar, z, rest_frame = False, \\\n                      xlim = None, ylim = None, \\\n                      spectra_kwargs = {}, model_kwargs = {},\\\n                      emission_lines = False, absorption_lines = False, \\\n                      em_lines = None,  abs_lines = None):\n    \"\"\"\n    Function to plot SDSS spectra\n    \n    Parameters\n    ----------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    flux : array\n        Flux array of the spectra\n        \n    model : array\n        Model array of the spectra\n        \n    ivar : array\n        Inverse variance array of the spectra\n        \n    z : float\n        Redshift of the object\n        \n    rest_frame : bool\n        Whether the spectra is in rest-frame or not\n    \n    xlim : list\n       ",
                "true_code": "# Selecting 100 sources from each box and joining their rows into a table\nn = 100\n\n# Indices of 100 objects within each box\nsy_sel = np.sort(random.sample(list(sy_box), n))\nsf_sel = np.sort(random.sample(list(sf_box), n))\nliner_sel = np.sort(random.sample(list(liner_box), n))\ncomp_sel = np.sort(random.sample(list(comp_box), n))\n\n# Tables of the selections\ntab_sy = final_table[sy_sel]\ntab_sf = final_table[sf_sel]\ntab_liner = final_table[liner_sel]\ntab_comp = final_table[comp_sel]",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.09950035216199637,
                    "ngram_match_score": 0.002576220328785894,
                    "weighted_ngram_match_score": 0.010840208082045418,
                    "syntax_match_score": 0.14545454545454545,
                    "dataflow_match_score": 0.2391304347826087
                },
                "codebertscore": {
                    "precision": 0.6098727583885193,
                    "recall": 0.6528345942497253,
                    "F1": 0.6306228041648865,
                    "F3": 0.648267924785614
                },
                "codebertscore_rescaled": {
                    "precision": 0.21974551677703857,
                    "recall": 0.3056691884994507,
                    "F1": 0.26124560832977295,
                    "F3": 0.296535849571228
                }
            },
            {
                "ind": 57,
                "gen_code": "# Function to retrieve SDSS spectra given a specobjid\ndef get_sdss_spectra(specobjid, rest_frame = False):\n    \"\"\"\n    Function to retrieve SDSS spectra given a specobjid.\n    \n    Returns the wavelength, flux, model and inverse variance arrays of the spectrum.\n    \n    Parameters\n    ----------\n    specobjid : int\n        The unique identifier of the SDSS spectrum\n        \n    rest_frame : bool\n        If True, returns the spectrum in the rest-frame, else returns in the observed frame\n        \n    Returns\n    -------\n    wavelength : array\n        Wavelength array of the spectrum\n        \n    flux : array\n        Flux array of the spectrum\n        \n    model : array\n        Model array of the spectrum\n        \n    ivar : array\n        Inverse variance array of the spectrum\n    \"\"\"\n    \n    # Retrieve the spectrum\n    res = client.retrieve_by_specid(specid_list = [specobjid], \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    # Get the spectrum\n    res_rec = res.records[0]\n    z = res_rec.redshift\n    lam = res_rec.wavelength\n    flux = res_rec.flux\n    model = res_rec.model\n    ivar = res_rec.ivar\n    \n    # If rest_frame is True, convert to rest-frame\n    if rest_frame:\n        lam = lam/(1+z)\n        flux = flux*(1+z)\n        model = model*(1+z)\n        ivar = ivar/((1+z)**2)\n        \n    return (lam, flux, model, ivar)\n\n\n# Function to annotate emission and absorption lines\ndef annotate_lines(ax, emission_lines = True, absorption_lines = True, em_lines = None, abs_lines = None):\n    \"\"\"\n    Function to annotate emission and absorption lines.\n    \n    Parameters\n    ----------\n    ax : Axes\n        The axes object to annotate\n        \n    emission_lines : bool\n        If True, annotates emission lines\n        \n    absorption_lines : bool\n        If True, annotates absorption lines\n        \n    em_lines : list\n        List of emission line wavelengths to annotate\n        \n    abs_lines : list\n        List of absorption line wavelengths to annotate\n    \"\"\"\n    \n    # Emission lines\n    if emission_lines:\n        if em_lines is None:\n           ",
                "true_code": "# Stacked spectra for the 100 sources within each white box\nlam_sy, flux_sy, model_sy = stack_spectra(tab_sy)\nlam_sf, flux_sf, model_sf = stack_spectra(tab_sf)\nlam_liner, flux_liner, model_liner = stack_spectra(tab_liner)\nlam_comp, flux_comp, model_comp = stack_spectra(tab_comp)",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.077662759683053,
                    "ngram_match_score": 0.0011321077503950935,
                    "weighted_ngram_match_score": 0.009518930981816902,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.3
                },
                "codebertscore": {
                    "precision": 0.6013616323471069,
                    "recall": 0.7418409585952759,
                    "F1": 0.6642552614212036,
                    "F3": 0.7249070405960083
                },
                "codebertscore_rescaled": {
                    "precision": 0.20272326469421387,
                    "recall": 0.48368191719055176,
                    "F1": 0.3285105228424072,
                    "F3": 0.4498140811920166
                }
            },
            {
                "ind": 59,
                "gen_code": "## Function 1 - \ndef get_sdss_spectra(specobjid, rest_frame = True):\n    \"\"\"\n    Function to retrieve SDSS spectra for a given specobjid\n    Uses SPARCL to retrieve spectra\n    \n    Returns wavelength, flux, model and inverse variance arrays\n    \n    Parameters\n    ----------\n    specobjid : int\n        specobjid of the object\n        \n    Returns\n    -------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    flux : array\n        Flux array of the spectra\n    \n    model : array\n        Model array of the spectra\n    \n    ivar : array\n        Inverse variance array of the spectra\n    \"\"\"\n    \n    res = client.retrieve_by_specid(specid_list = [specobjid], \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    res_rec = res.records[0]\n    z = res_rec.redshift\n    lam = res_rec.wavelength/(1+z)\n    flux = res_rec.flux*(1+z)\n    model = res_rec.model*(1+z)\n    ivar = res_rec.ivar/((1+z)**2)\n    \n    if rest_frame == False:\n        lam = lam*(1+z)\n        flux = flux/(1+z)\n        model = model/(1+z)\n        ivar = ivar*((1+z)**2)\n        \n    return (lam, flux, model, ivar)\n\n## Function 2 - \ndef annotate_plot(wavelength, emission_lines = True, absorption_lines = True, em_lines = None, abs_lines = None):\n    \"\"\"\n    Function to annotate emission and absorption lines on the plot\n    \n    Parameters\n    ----------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    emission_lines : bool\n        If True, plots the emission lines\n        \n    absorption_lines : bool\n        If True, plots the absorption lines\n        \n    em_lines : list\n        List of emission lines to be plotted\n        \n    abs_lines : list\n        List of absorption lines to be plotted\n    \"\"\"\n    \n    # Vacuum wavelengths of emission lines\n    em_lines_default = [3726.03, 3728.82, 3869.06, 3889.05, 3933.68, 3967.47, 4026.19, ",
                "true_code": "fig, axs = plt.subplots(4,1, figsize = (12, 12), sharex = True, sharey = True)\nplt.subplots_adjust(wspace = 0., hspace = 0.)\n\naxs[0].plot(lam_sy, flux_sy, color = 'r', label = 'Seyferts')\naxs[0].legend(fontsize = 14, loc = 'upper left')\naxs[0].set_ylabel('$F_{\\lambda}$')\n\naxs[1].plot(lam_sf, flux_sf, color = 'b', label = 'Star-Forming')\naxs[1].legend(fontsize = 14, loc = 'upper left')\naxs[1].set_ylabel('$F_{\\lambda}$')\n\naxs[2].plot(lam_liner, flux_liner, color = 'purple', label = 'LINERs')\naxs[2].legend(fontsize = 14, loc = 'upper left')\naxs[2].set_ylabel('$F_{\\lambda}$')\n\naxs[3].plot(lam_comp, flux_comp, color = 'g', label = 'Composite')\naxs[3].legend(fontsize = 14, loc = 'upper left')\naxs[3].set_xlim([3510, 7010])\naxs[3].set_xlabel('$\\lambda$')\naxs[3].set_ylabel('$F_{\\lambda}$');",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.11632132206388723,
                    "ngram_match_score": 0.0030020202365544477,
                    "weighted_ngram_match_score": 0.007918188653915135,
                    "syntax_match_score": 0.15079365079365079,
                    "dataflow_match_score": 0.30357142857142855
                },
                "codebertscore": {
                    "precision": 0.6490424275398254,
                    "recall": 0.6442867517471313,
                    "F1": 0.646655797958374,
                    "F3": 0.6447591781616211
                },
                "codebertscore_rescaled": {
                    "precision": 0.2980848550796509,
                    "recall": 0.2885735034942627,
                    "F1": 0.29331159591674805,
                    "F3": 0.2895183563232422
                }
            },
            {
                "ind": 62,
                "gen_code": "# Function to get SDSS spectra\ndef get_sdss_spectra(specobjid, rest_frame = True):\n    \"\"\"\n    Function to get the SDSS spectra of a given object using SPARCL\n    \n    Parameters\n    ----------\n    specobjid : int\n        specobjid of the object\n        \n    rest_frame : bool\n        If True, returns the spectra in the rest frame\n        If False, returns the spectra in the observed frame\n        \n    Returns\n    -------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    flux : array\n        Flux array of the spectra\n        \n    model : array\n        Model array of the spectra\n        \n    ivar : array\n        Inverse variance array of the spectra\n    \"\"\"\n    \n    res = client.retrieve_by_specid(specid_list = [specobjid], \n                                    include = ['sparcl_id', 'specid', 'redshift', 'flux', 'wavelength', 'model', 'ivar'],\n                                    dataset_list = ['SDSS-DR16', 'BOSS-DR16'])\n    \n    res_rec = res.records[0]\n    z = res_rec.redshift\n    lam = res_rec.wavelength\n    flux = res_rec.flux\n    model = res_rec.model\n    ivar = res_rec.ivar\n    \n    if rest_frame:\n        lam = lam/(1+z)\n        flux = flux*(1+z)\n        model = model*(1+z)\n        ivar = ivar/((1+z)**2)\n    \n    return (lam, flux, model, ivar)\n\n\n# Function to plot SDSS spectra\ndef plot_sdss_spectra(wavelength, flux, model, ivar, z, rest_frame = True, \\\n                      xlim = None, ylim = None, \\\n                      spectra_kwargs = {'color': 'k', 'alpha': 0.5}, \\\n                      model_kwargs = {'color': 'r', 'linewidth': 2.0},\\\n                      emission_lines = True, absorption_lines = True, \\\n                      em_lines = None,  abs_lines = None):\n    \"\"\"\n    Function to plot the SDSS spectra\n    \n    Parameters\n    ----------\n    wavelength : array\n        Wavelength array of the spectra\n        \n    flux : array\n        Flux array of the spectra\n        \n    model : array\n        Model array of the spectra\n        \n    ivar : array\n        Inverse variance array of the spectra\n        \n    z : float\n        Redshift of the object\n        \n   ",
                "true_code": "fig, axs = plt.subplots(4,2, figsize = (16,12), sharey = True, sharex = 'col')\nplt.subplots_adjust(wspace = 0.05, hspace = 0.0)\n\naxs[0][0].plot(lam_sy, flux_sy, color = 'r', label = 'Seyferts')\naxs[0][0].legend(fontsize = 14, loc = 'upper left')\naxs[0][0].set_ylabel('$F_{\\lambda}$')\naxs[0][0].set_xlim([4810, 5090])\nadd_lines(ax = axs[0][0], z=0, abs_lines = [])\n\naxs[1][0].plot(lam_sf, flux_sf, color = 'b', label = 'Star-Forming')\naxs[1][0].legend(fontsize = 14, loc = 'upper left')\naxs[1][0].set_ylabel('$F_{\\lambda}$')\nadd_lines(ax = axs[1][0], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[2][0].plot(lam_liner, flux_liner, color = 'purple', label = 'LINERs')\naxs[2][0].legend(fontsize = 14, loc = 'upper left')\naxs[2][0].set_ylabel('$F_{\\lambda}$')\naxs[2][0].set_xlabel('$\\lambda$')\nadd_lines(ax = axs[2][0], z=0, rest_frame = True, abs_lines = [], em_label = False)\n                \naxs[3][0].plot(lam_comp, flux_comp, color = 'g', label = 'Composite')\naxs[3][0].legend(fontsize = 14, loc = 'upper left')\naxs[3][0].set_ylabel('$F_{\\lambda}$')\naxs[3][0].set_xlabel('$\\lambda$')\nadd_lines(ax = axs[3][0], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[0][1].plot(lam_sy, flux_sy, color = 'r', label = 'Seyferts')\naxs[0][1].set_xlim([6250, 6900])\nadd_lines(ax = axs[0][1], z=0, rest_frame = True, abs_lines = [])\n\naxs[1][1].plot(lam_sf, flux_sf, color = 'b', label = 'Star-Forming')\nadd_lines(ax = axs[1][1], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[2][1].plot(lam_liner, flux_liner, color = 'purple', label = 'LINERs')\nadd_lines(ax = axs[2][1], z=0, rest_frame = True, abs_lines = [], em_label = False)\n\naxs[3][1].plot(lam_comp, flux_comp, color = 'g', label = 'Composite')\naxs[3][1].set_xlabel('$\\lambda$')\nadd_lines(ax = axs[3][1], z=0, rest_frame = True, abs_lines = [], em_label = False)",
                "error_ind": 30,
                "direct_match": false,
                "fuzzy_match": 1,
                "codebleu": {
                    "codebleu": 0.10608579122914308,
                    "ngram_match_score": 0.008734817119305125,
                    "weighted_ngram_match_score": 0.009788696604772787,
                    "syntax_match_score": 0.10380622837370242,
                    "dataflow_match_score": 0.30201342281879195
                },
                "codebertscore": {
                    "precision": 0.680209219455719,
                    "recall": 0.6984668374061584,
                    "F1": 0.6892171502113342,
                    "F3": 0.6965970993041992
                },
                "codebertscore_rescaled": {
                    "precision": 0.360418438911438,
                    "recall": 0.3969336748123169,
                    "F1": 0.37843430042266846,
                    "F3": 0.39319419860839844
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.0,
            "fuzzy_match": 14.84,
            "codebleu": 0.2105420994991142,
            "syntax_match_score": 0.28344001630710586,
            "codebertscore": 0.7350813460350036,
            "codebertscore_rescaled": 0.4701626920700073,
            "code_success": 0.32,
            "total_code_cell_count": 25
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/02_DESI_EDR_SDSS_Comparison_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/DESI/02_DESI_EDR_SDSS_Comparison.ipynb",
            "prefix": "desi_1"
        },
        "model": {
            "name": "llama3.1",
            "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "library": "together"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "# Define notebook metadata\nnotebook_id = \"ASTRONOMY_NOTEBOOK_001\"\nauthor_name = \"John Doe\"\nauthor_email = \"john.doe@example.com\"\nversion_number = \"1.0.0\"\n\n# Define datasets used in the notebook\ndatasets = [\n    \"SDSS DR16\",\n    \"DESI Early Data Release\"\n]\n\n# Define keywords related to the notebook\nkeywords = [\n    \"astronomy\",\n    \"SDSS\",\n    \"DESI\",\n    \"spectroscopy\",\n    \"galaxy evolution\"\n]",
                "true_code": "__nbid__ = '0006'\n__author__ = 'Ragadeepika Pucha <rpucha@arizona.edu>, Stephanie Juneau <stephanie.juneau@noirlab.edu>' \n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['sdss_dr16', 'desi_edr']  \n__keywords__ = ['sparcl', 'spectra', 'database'] ",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 7,
                "codebleu": {
                    "codebleu": 0.3798280344221585,
                    "ngram_match_score": 0.005623975733856203,
                    "weighted_ngram_match_score": 0.011856660123276007,
                    "syntax_match_score": 0.8095238095238095,
                    "dataflow_match_score": 0.6923076923076923
                },
                "codebertscore": {
                    "precision": 0.7037404775619507,
                    "recall": 0.7034642100334167,
                    "F1": 0.7036023736000061,
                    "F3": 0.7034918665885925
                },
                "codebertscore_rescaled": {
                    "precision": 0.40748095512390137,
                    "recall": 0.4069284200668335,
                    "F1": 0.4072047472000122,
                    "F3": 0.40698373317718506
                }
            },
            {
                "ind": 9,
                "gen_code": "# Update matplotlib plot settings for better visual appeal\nplt.rcParams.update({\n    'font.size': 14,\n    'lines.linewidth': 1.5,\n    'axes.linewidth': 1.5,\n    'xtick.major.width': 1.5,\n    'ytick.major.width': 1.5,\n    'xtick.major.size': 8,\n    'ytick.major.size': 8,\n    'xtick.direction': 'in',\n    'ytick.direction': 'in',\n    'xtick.top': True,\n    'ytick.right': True,\n    'axes.labelsize': 16,\n    'axes.titlesize': 18,\n    'legend.fontsize': 14,\n    'figure.figsize': (10, 8)\n})",
                "true_code": "## Making the matplotlib plots look nicer\nsettings = {\n    'font.size':20,\n    'axes.linewidth':2.0,\n    'xtick.major.size':6.0,\n    'xtick.minor.size':4.0,\n    'xtick.major.width':2.0,\n    'xtick.minor.width':1.5,\n    'xtick.direction':'in', \n    'xtick.minor.visible':True,\n    'xtick.top':True,\n    'ytick.major.size':6.0,\n    'ytick.minor.size':4.0,\n    'ytick.major.width':2.0,\n    'ytick.minor.width':1.5,\n    'ytick.direction':'in', \n    'ytick.minor.visible':True,\n    'ytick.right':True\n}\n\nplt.rcParams.update(**settings)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 30,
                "codebleu": {
                    "codebleu": 0.4578481680687352,
                    "ngram_match_score": 0.005223577740745086,
                    "weighted_ngram_match_score": 0.007987276352377327,
                    "syntax_match_score": 0.8181818181818182,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.8538314700126648,
                    "recall": 0.8451602458953857,
                    "F1": 0.8494737148284912,
                    "F3": 0.8460195064544678
                },
                "codebertscore_rescaled": {
                    "precision": 0.7076629400253296,
                    "recall": 0.6903204917907715,
                    "F1": 0.6989474296569824,
                    "F3": 0.6920390129089355
                }
            },
            {
                "ind": 11,
                "gen_code": "## Initialize the SPARCL client\nsparcl_client = SparclClient()",
                "true_code": "## Load the SPARCL client for data discovery and spectral access\n\nclient = SparclClient()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 65,
                "codebleu": {
                    "codebleu": 0.5421394914129407,
                    "ngram_match_score": 0.08546138847070893,
                    "weighted_ngram_match_score": 0.08309657718105372,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9248273372650146,
                    "recall": 0.8689258694648743,
                    "F1": 0.8960055708885193,
                    "F3": 0.8742100596427917
                },
                "codebertscore_rescaled": {
                    "precision": 0.8496546745300293,
                    "recall": 0.7378517389297485,
                    "F1": 0.7920111417770386,
                    "F3": 0.7484201192855835
                }
            },
            {
                "ind": 13,
                "gen_code": "print(client)",
                "true_code": "client",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 63,
                "codebleu": {
                    "codebleu": 0.25,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.7719264030456543,
                    "recall": 0.8429650068283081,
                    "F1": 0.8058832287788391,
                    "F3": 0.8352781534194946
                },
                "codebertscore_rescaled": {
                    "precision": 0.5438528060913086,
                    "recall": 0.6859300136566162,
                    "F1": 0.6117664575576782,
                    "F3": 0.6705563068389893
                }
            },
            {
                "ind": 16,
                "gen_code": "## Define the output fields for the SPARCL database query\noutput_fields = [\n    'ra', 'dec', 'z', 'spectype', 'subclass', 'zerr', 'zwarning',\n    'plate', 'mjd', 'fiberid', 'flux', 'flux_ivar', 'maskbits',\n    'and_maskbits', 'or_maskbits', 'flux_g', 'flux_r', 'flux_i',\n    'flux_z', 'flux_w1', 'flux_w2', 'flux_w3', 'flux_w4'\n]\n\n## Define the constraints for the SPARCL database query\nconstraints = [\n    ('ra', '>=', 208.4), ('ra', '<=', 210.2),\n    ('dec', '>=', 4.8), ('dec', '<=', 6.4),\n    ('z', '>=', 0.1), ('z', '<=', 0.15),\n    ('spectype', '=', 'GALAXY')\n]\n\n## Define the dataset groups for the SPARCL database query\ndataset_groups = ['sdss_dr16', 'desi_edr']\n\n## Perform the SPARCL database query\nresults = client.query(\n    output_fields=output_fields,\n    constraints=constraints,\n    dataset_groups=dataset_groups\n)",
                "true_code": "## The outfields that are required as output from SPARCL\nout = ['sparcl_id', 'specid', 'ra', 'dec', 'redshift'] \n\n## Constraints\n## SPECTYPE = 'GALAXY'\n## 208.4 <= RA <= 210.2\n## 4.8 <= DEC <= 6.4\n## 0.1 <= Redshift <= 0.15\n## SPECPRIMARY = True -- consider only primary spectra\n## \"datasetgroup\" denotes the required survey (SDSS_BOSS for SDSS-DR16 (SDSS+BOSS data), and DESI for DESI EDR data (will be updated with future releases))\n\nsdss_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['SDSS_BOSS'], 'redshift': [0.1, 0.15]}\ndesi_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['DESI'], 'redshift': [0.1, 0.15]} ",
                "error_ind": 16,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.2368130508684798,
                    "ngram_match_score": 0.006255037585677653,
                    "weighted_ngram_match_score": 0.006547405122691289,
                    "syntax_match_score": 0.38181818181818183,
                    "dataflow_match_score": 0.5526315789473685
                },
                "codebertscore": {
                    "precision": 0.7487629652023315,
                    "recall": 0.7612206935882568,
                    "F1": 0.7549404501914978,
                    "F3": 0.7599563002586365
                },
                "codebertscore_rescaled": {
                    "precision": 0.4975259304046631,
                    "recall": 0.5224413871765137,
                    "F1": 0.5098809003829956,
                    "F3": 0.519912600517273
                }
            },
            {
                "ind": 18,
                "gen_code": "## Retrieve records from SDSS and DESI\nsdss_data = client.query(outfields=out, constraints=sdss_cons, limit=1000)\ndesi_data = client.query(outfields=out, constraints=desi_cons, limit=1000)",
                "true_code": "rec_sdss = client.find(outfields=out, constraints=sdss_cons, limit = 5000)\nrec_desi = client.find(outfields=out, constraints=desi_cons, limit = 5000)",
                "error_ind": 18,
                "direct_match": false,
                "fuzzy_match": 77,
                "codebleu": {
                    "codebleu": 0.50911687487825,
                    "ngram_match_score": 0.01626739260030573,
                    "weighted_ngram_match_score": 0.020200106912694155,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8765475749969482,
                    "recall": 0.9268790483474731,
                    "F1": 0.9010109305381775,
                    "F3": 0.921587347984314
                },
                "codebertscore_rescaled": {
                    "precision": 0.7530951499938965,
                    "recall": 0.8537580966949463,
                    "F1": 0.802021861076355,
                    "F3": 0.8431746959686279
                }
            },
            {
                "ind": 20,
                "gen_code": "## Extract the RA and Dec for the selected sources\nra_sdss = np.array(rec_sdss['ra'])\ndec_sdss = np.array(rec_sdss['dec'])\n\nra_desi = np.array(rec_desi['ra'])\ndec_desi = np.array(rec_desi['dec'])",
                "true_code": "ra_sdss = np.array([rec['ra'] for rec in rec_sdss.records])\ndec_sdss = np.array([rec['dec'] for rec in rec_sdss.records])\n\nra_desi = np.array([rec['ra'] for rec in rec_desi.records])\ndec_desi = np.array([rec['dec'] for rec in rec_desi.records])",
                "error_ind": 20,
                "direct_match": false,
                "fuzzy_match": 58,
                "codebleu": {
                    "codebleu": 0.2129529335726469,
                    "ngram_match_score": 0.02880880755932819,
                    "weighted_ngram_match_score": 0.026509024292235027,
                    "syntax_match_score": 0.3902439024390244,
                    "dataflow_match_score": 0.40625
                },
                "codebertscore": {
                    "precision": 0.9044969081878662,
                    "recall": 0.8779523372650146,
                    "F1": 0.8910269737243652,
                    "F3": 0.8805364370346069
                },
                "codebertscore_rescaled": {
                    "precision": 0.8089938163757324,
                    "recall": 0.7559046745300293,
                    "F1": 0.7820539474487305,
                    "F3": 0.7610728740692139
                }
            },
            {
                "ind": 22,
                "gen_code": "plt.figure(figsize=(10,8))\nplt.scatter(ra_sdss, dec_sdss, marker='o', color='blue', label='SDSS DR16')\nplt.scatter(ra_desi, dec_desi, marker='x', color='red', label='DESI EDR')\nplt.xlabel('Right Ascension (deg)')\nplt.ylabel('Declination (deg)')\nplt.legend()\nplt.gca().invert_xaxis()\nplt.show()",
                "true_code": "## Overlap of sources\n\nplt.figure(figsize = (8,8))\n\nplt.suptitle('Sky Positions of Galaxies with SDSS and DESI Spectra', fontsize = 20)\n\nplt.scatter(ra_desi, dec_desi, color = 'grey', marker = 'o', s = 50, alpha = 0.8, lw = 2.0, label = 'DESI EDR')\nplt.scatter(ra_sdss, dec_sdss, color = 'r', marker = 'X', s = 50, label = 'SDSS DR16')\nplt.gca().invert_xaxis()\nplt.xlabel('R.A. [deg]')\nplt.ylabel('Dec. [deg]')\nplt.legend(loc = 'upper right')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.4006120090812234,
                    "ngram_match_score": 0.004054557897791131,
                    "weighted_ngram_match_score": 0.009504589538213726,
                    "syntax_match_score": 0.7,
                    "dataflow_match_score": 0.8888888888888888
                },
                "codebertscore": {
                    "precision": 0.9151982069015503,
                    "recall": 0.8353464603424072,
                    "F1": 0.8734511137008667,
                    "F3": 0.8426991105079651
                },
                "codebertscore_rescaled": {
                    "precision": 0.8303964138031006,
                    "recall": 0.6706929206848145,
                    "F1": 0.7469022274017334,
                    "F3": 0.6853982210159302
                }
            },
            {
                "ind": 24,
                "gen_code": "## Define catalogs for SDSS and DESI sources\nsdss_catalog = SkyCoord(ra=ra_sdss*u.deg, dec=dec_sdss*u.deg)\ndesi_catalog = SkyCoord(ra=ra_desi*u.deg, dec=dec_desi*u.deg)\n\n## Search for common sources within a 1 arcsecond radius\nidx, d2d, d3d = sdss_catalog.match_to_catalog_sky(desi_catalog, nthneighbor=1)\n\n## Filter matches to only include those within 1 arcsecond\ncommon_idx = idx[d2d.arcsecond < 1]\n\n## Get the indices of common sources in the SDSS and DESI catalogs\ncommon_sdss_idx = np.arange(len(sdss_catalog))[common_idx]\ncommon_desi_idx = idx[common_idx]\n\n## Extract the RA and Dec of common sources\ncommon_ra_sdss = ra_sdss[common_sdss_idx]\ncommon_dec_sdss = dec_sdss[common_sdss_idx]\ncommon_ra_desi = ra_desi[common_desi_idx]\ncommon_dec_desi = dec_desi[common_desi_idx]\n\n## Plot the common sources\nplt.figure(figsize=(8,8))\nplt.suptitle('Common Sources between SDSS and DESI', fontsize=20)\nplt.scatter(ra_sdss, dec_sdss, color='r', marker='X', s=50, alpha=0.8, lw=2.0, label='SDSS DR16')\nplt.scatter(ra_desi, dec_desi, color='grey', marker='o', s=50, alpha=0.8, lw=2.0, label='DESI EDR')\nplt.scatter(common_ra_sdss, common_dec_sdss, color='b', marker='*', s=200, label='Common Sources')\nplt.gca().invert_xaxis()\nplt.xlabel('R.A. [deg]')\nplt.ylabel('Dec. [deg]')\nplt.legend(loc='upper right')",
                "true_code": "## Find common sources between SDSS and DESI\n\ncat_desi = SkyCoord(ra = ra_desi*u.deg, dec = dec_desi*u.deg)\ncat_sdss = SkyCoord(ra = ra_sdss*u.deg, dec = dec_sdss*u.deg)\n\nii_desi, ii_sdss, _, _ = search_around_sky(cat_desi, cat_sdss, 0.5*u.arcsec)",
                "error_ind": 24,
                "direct_match": false,
                "fuzzy_match": 12,
                "codebleu": {
                    "codebleu": 0.4148524183524634,
                    "ngram_match_score": 0.01401877073542637,
                    "weighted_ngram_match_score": 0.06205756934109383,
                    "syntax_match_score": 0.75,
                    "dataflow_match_score": 0.8333333333333334
                },
                "codebertscore": {
                    "precision": 0.6820065975189209,
                    "recall": 0.8922035694122314,
                    "F1": 0.7730717658996582,
                    "F3": 0.8655276298522949
                },
                "codebertscore_rescaled": {
                    "precision": 0.3640131950378418,
                    "recall": 0.7844071388244629,
                    "F1": 0.5461435317993164,
                    "F3": 0.7310552597045898
                }
            },
            {
                "ind": 26,
                "gen_code": "## Extract common records\n\ncommon_desi = [rec_desi.records[i] for i in ii_desi]\ncommon_sdss = [rec_sdss.records[i] for i in ii_sdss]",
                "true_code": "desi_common = [rec_desi.records[ii] for ii in ii_desi]\nsdss_common = [rec_sdss.records[ii] for ii in ii_sdss]",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 79,
                "codebleu": {
                    "codebleu": 0.5234194424309406,
                    "ngram_match_score": 0.038419068302517345,
                    "weighted_ngram_match_score": 0.05525870142124495,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9345818758010864,
                    "recall": 0.9447349309921265,
                    "F1": 0.9396309852600098,
                    "F3": 0.943709671497345
                },
                "codebertscore_rescaled": {
                    "precision": 0.8691637516021729,
                    "recall": 0.8894698619842529,
                    "F1": 0.8792619705200195,
                    "F3": 0.8874193429946899
                }
            },
            {
                "ind": 28,
                "gen_code": "## Convert lists to Astropy tables\nsdss_common_tab = Table([rec['sparcl_id'] for rec in sdss_common], \n                         [rec['specid'] for rec in sdss_common], \n                         [rec['ra'] for rec in sdss_common], \n                         [rec['dec'] for rec in sdss_common], \n                         [rec['redshift'] for rec in sdss_common], \n                         names=('sparcl_id', 'specid', 'ra', 'dec', 'redshift'))\n\ndesi_common_tab = Table([rec['sparcl_id'] for rec in desi_common], \n                         [rec['specid'] for rec in desi_common], \n                         [rec['ra'] for rec in desi_common], \n                         [rec['dec'] for rec in desi_common], \n                         [rec['redshift'] for rec in desi_common], \n                         names=('sparcl_id', 'specid', 'ra', 'dec', 'redshift'))",
                "true_code": "t_desi_common = Table(desi_common)\nt_sdss_common = Table(sdss_common)",
                "error_ind": 28,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.13790920096692955,
                    "ngram_match_score": 0.003087626696985844,
                    "weighted_ngram_match_score": 0.048549177170732344,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.5819186568260193,
                    "recall": 0.7663058638572693,
                    "F1": 0.6615036129951477,
                    "F3": 0.7427703738212585
                },
                "codebertscore_rescaled": {
                    "precision": 0.16383731365203857,
                    "recall": 0.5326117277145386,
                    "F1": 0.3230072259902954,
                    "F3": 0.4855407476425171
                }
            },
            {
                "ind": 30,
                "gen_code": "t_common = hstack([t_desi_common, t_sdss_common], table_names=['DESI', 'SDSS'])",
                "true_code": "## Combining the two tables into a single table\n\nt_comb = hstack([t_desi_common, t_sdss_common], table_names=['desi', 'sdss'])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 66,
                "codebleu": {
                    "codebleu": 0.5276256210579081,
                    "ngram_match_score": 0.04508379481408805,
                    "weighted_ngram_match_score": 0.06541868941754436,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.926900327205658,
                    "recall": 0.8555278182029724,
                    "F1": 0.88978511095047,
                    "F3": 0.8621665239334106
                },
                "codebertscore_rescaled": {
                    "precision": 0.8538006544113159,
                    "recall": 0.7110556364059448,
                    "F1": 0.7795702219009399,
                    "F3": 0.7243330478668213
                }
            },
            {
                "ind": 32,
                "gen_code": "print(len(np.unique(t_comb['desi_sparcl_id'])))\nprint(len(np.unique(t_comb['sdss_sparcl_id'])))",
                "true_code": "print ('Number of unique SDSS objects: ', len(np.unique(t_comb['specid_sdss'])))\nprint ('Number of unique DESI objects: ', len(np.unique(t_comb['specid_desi'])))",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 38,
                "codebleu": {
                    "codebleu": 0.42391304347826086,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.6956521739130435,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8952661752700806,
                    "recall": 0.8574013710021973,
                    "F1": 0.8759247660636902,
                    "F3": 0.8610430955886841
                },
                "codebertscore_rescaled": {
                    "precision": 0.7905323505401611,
                    "recall": 0.7148027420043945,
                    "F1": 0.7518495321273804,
                    "F3": 0.7220861911773682
                }
            },
            {
                "ind": 34,
                "gen_code": "# Remove duplicate entries from the combined table\nt_comb = t_comb.group_by('specid_sdss').groups[0]\n\n# Verify the updated object counts\nprint ('Number of unique SDSS objects: ', len(np.unique(t_comb['specid_sdss'])))\nprint ('Number of unique DESI objects: ', len(np.unique(t_comb['specid_desi'])))",
                "true_code": "## This suggests that one SDSS object has been selected as two DESI objects.\n## We remove that particular object from our selection\n\nsdss_ids_unique, n_counts = np.unique(t_comb['specid_sdss'].data, return_counts = True)\nsdss_id_repeated = sdss_ids_unique[n_counts > 1]\n\n## Removing this particular object\nt_comb_unique = t_comb[~(t_comb['specid_sdss'].data == sdss_id_repeated)]",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 18,
                "codebleu": {
                    "codebleu": 0.17367213298397965,
                    "ngram_match_score": 0.005871925248701311,
                    "weighted_ngram_match_score": 0.0067990628275682655,
                    "syntax_match_score": 0.20833333333333334,
                    "dataflow_match_score": 0.47368421052631576
                },
                "codebertscore": {
                    "precision": 0.8304134011268616,
                    "recall": 0.7990212440490723,
                    "F1": 0.8144149780273438,
                    "F3": 0.8020533919334412
                },
                "codebertscore_rescaled": {
                    "precision": 0.6608268022537231,
                    "recall": 0.5980424880981445,
                    "F1": 0.6288299560546875,
                    "F3": 0.6041067838668823
                }
            },
            {
                "ind": 36,
                "gen_code": "## Extracting the redshifts of unique common sources\n\nz_desi = t_comb_unique['redshift_desi'].data\nz_sdss = t_comb_unique['redshift_sdss'].data",
                "true_code": "z_desi = t_comb_unique['redshift_desi']\nz_sdss = t_comb_unique['redshift_sdss']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 71,
                "codebleu": {
                    "codebleu": 0.2773142965741053,
                    "ngram_match_score": 0.04271802513581977,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 0.4444444444444444,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.8673899173736572,
                    "recall": 0.9512393474578857,
                    "F1": 0.9073816537857056,
                    "F3": 0.9421318173408508
                },
                "codebertscore_rescaled": {
                    "precision": 0.7347798347473145,
                    "recall": 0.9024786949157715,
                    "F1": 0.8147633075714111,
                    "F3": 0.8842636346817017
                }
            },
            {
                "ind": 38,
                "gen_code": "print ('Length of DESI redshift array: ', len(z_desi))\nprint ('Length of SDSS redshift array: ', len(z_sdss))",
                "true_code": "len(z_desi), len(z_sdss)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 36,
                "codebleu": {
                    "codebleu": 0.41666666666666663,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.6666666666666666,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8005356192588806,
                    "recall": 0.9204511046409607,
                    "F1": 0.8563156127929688,
                    "F3": 0.906866729259491
                },
                "codebertscore_rescaled": {
                    "precision": 0.6010712385177612,
                    "recall": 0.8409022092819214,
                    "F1": 0.7126312255859375,
                    "F3": 0.8137334585189819
                }
            },
            {
                "ind": 40,
                "gen_code": "```python\n## Plotting the redshifts\n\nplt.figure(figsize = (8,8))\n\nplt.suptitle('Redshift Comparison between SDSS DR16 and DESI EDR', fontsize = 20)\n\nplt.scatter(z_desi, z_sdss, color = 'k', marker = 'o', s = 50, alpha = 0.8, lw = 2.0)\nplt.plot([0.1, 0.15], [0.1, 0.15], 'r--', lw = 2.0)\nplt.xlabel('DESI Redshift')\nplt.ylabel('SDSS Redshift')\nplt.legend(loc = 'upper right')\nplt.xlim([0.1, 0.15])\nplt.ylim([0.1, 0.15])\nplt.gca().set_aspect('equal', adjustable='box')\n```\n\n<MARKDOWN>\n## Selecting galaxies with [OII] measurements\nIdentify galaxies with [OII] emission line measurements in both SDSS and DESI datasets. This step is crucial for comparing the flux and spectral resolution of the two surveys. Utilize the `search_around_sky` function from Astropy to find matching sources between the two catalogs within a specified angular separation tolerance.\n<CELL END>\n\n<PYTHON CODE>\n## Find galaxies with [OII] emission line measurements in both SDSS and DESI\n\ncat_sdss = SkyCoord(ra = ra_sdss*u.deg, dec = dec_sdss*u.deg)\ncat_desi = SkyCoord(ra = ra_desi*u.deg, dec = dec_desi*u.deg)\n\nii_sdss, ii_desi, _, _ = search_around_sky(cat_sdss, cat_desi, 0.5*u.arcsec)\n\noii_sdss = [rec_sdss.records[ii] for ii in ii_sdss]\noii_desi = [rec_desi.records[ii] for ii in ii_desi]\n\nt_oii_sdss = Table(oii_sdss)\nt_oii_desi = Table(oii_desi)\n\nt_oii_comb = hstack([t_oii_desi, t_oii_sdss], table_names=['desi', 'sdss'])\n<CELL END>\n\n<MARKDOWN>\nOutput the number of unique objects from the SDSS and DESI data in the combined table. This step helps verify the merging process and indicates whether each object in the dataset corresponds correctly.\n<CELL END>\n\n<PYTHON CODE>\nprint ('Number of",
                "true_code": "# Comparison of redshifts\nplt.figure(figsize = (6,6))\nplt.suptitle('Redshift Comparison')\n\nplt.scatter(z_sdss, z_desi, edgecolors = 'k', marker = 'o', s = 100, lw = 3.0, facecolors = 'none')\nplt.plot([0.1, 0.15], [0.1,0.15], ls = ':', color = 'r', lw = 2.0)\nplt.xlabel('$z_{spec}$ (SDSS)')\nplt.ylabel('$z_{spec}$ (DESI)')",
                "error_ind": 40,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.5316745618642889,
                    "ngram_match_score": 0.04345138499476029,
                    "weighted_ngram_match_score": 0.2388024180179508,
                    "syntax_match_score": 0.8444444444444444,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.6913229823112488,
                    "recall": 0.9177597165107727,
                    "F1": 0.7886087894439697,
                    "F3": 0.8886527419090271
                },
                "codebertscore_rescaled": {
                    "precision": 0.38264596462249756,
                    "recall": 0.8355194330215454,
                    "F1": 0.5772175788879395,
                    "F3": 0.7773054838180542
                }
            },
            {
                "ind": 43,
                "gen_code": "# Extract galaxies with non-zero [OII] measurements from the \"emissionlinesport\" catalog within the SDSS DR12 database\nquery = \"\"\"\n    SELECT s.specobjid, s.ra, s.dec, s.z, s.zerr, s.class, s.subclass, \n           e.ew_3727, e.ew_3729, e.flux_3727, e.flux_3729, e.flux_ivar_3727, e.flux_ivar_3729\n    FROM specObj as s\n    JOIN emissionLinesPort as e ON s.specobjid = e.specobjid\n    WHERE s.class = 'GALAXY' AND s.z > 0.1 AND s.z < 0.15 AND s.ra > 208.4 AND s.ra < 210.2 AND s.dec > 4.8 AND s.dec < 6.4\n    AND e.ew_3727 > 0 AND e.ew_3729 > 0\n    AND e.flux_3727 > 0 AND e.flux_3729 > 0\n\"\"\"\n\n# Execute the query using the Data Lab query client\nresult = qc.query(sql=query)\n\n# Convert the result to an Astropy table\ntable = Table(result)\n\n# Print the table\nprint(table)",
                "true_code": "## Query to access galaxies with non-zero [OII] measurements\nquery = \"\"\"\nSELECT specobjid as specid_sdss, \nflux_oii_3726, flux_oii_3726_err,\nflux_oii_3728, flux_oii_3728_err\nFROM sdss_dr12.emissionlinesport\nWHERE (ra >= 208.4) AND (ra <= 210.2) AND (dec >= 4.8) AND (dec <= 6.4) \nAND (flux_oii_3726_err != 0) AND (flux_oii_3728_err != 0)\n\"\"\"",
                "error_ind": 43,
                "direct_match": false,
                "fuzzy_match": 29,
                "codebleu": {
                    "codebleu": 0.49027979993582105,
                    "ngram_match_score": 0.05688103891971951,
                    "weighted_ngram_match_score": 0.15423816082356476,
                    "syntax_match_score": 0.75,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7488500475883484,
                    "recall": 0.8429504632949829,
                    "F1": 0.7931188344955444,
                    "F3": 0.8324894905090332
                },
                "codebertscore_rescaled": {
                    "precision": 0.4977000951766968,
                    "recall": 0.6859009265899658,
                    "F1": 0.5862376689910889,
                    "F3": 0.6649789810180664
                }
            },
            {
                "ind": 45,
                "gen_code": "print(query)",
                "true_code": "print (query)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 96,
                "codebleu": {
                    "codebleu": 0.5,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.9702564477920532,
                    "recall": 0.9702564477920532,
                    "F1": 0.9702564477920532,
                    "F3": 0.9702563881874084
                },
                "codebertscore_rescaled": {
                    "precision": 0.9405128955841064,
                    "recall": 0.9405128955841064,
                    "F1": 0.9405128955841064,
                    "F3": 0.9405127763748169
                }
            },
            {
                "ind": 47,
                "gen_code": "## Execute the query to access galaxies with non-zero [OII] measurements\nt_oii_sdss = qc.query_sql(query, fmt='astropy')",
                "true_code": "t_em = qc.query(sql = query, fmt = 'table')",
                "error_ind": 47,
                "direct_match": false,
                "fuzzy_match": 38,
                "codebleu": {
                    "codebleu": 0.2721532963963857,
                    "ngram_match_score": 0.013217947626377298,
                    "weighted_ngram_match_score": 0.02777619034011792,
                    "syntax_match_score": 0.3333333333333333,
                    "dataflow_match_score": 0.7142857142857143
                },
                "codebertscore": {
                    "precision": 0.7425102591514587,
                    "recall": 0.87276291847229,
                    "F1": 0.8023848533630371,
                    "F3": 0.8577167391777039
                },
                "codebertscore_rescaled": {
                    "precision": 0.4850205183029175,
                    "recall": 0.7455258369445801,
                    "F1": 0.6047697067260742,
                    "F3": 0.7154334783554077
                }
            },
            {
                "ind": 49,
                "gen_code": "## Join the common sources table with the emission lines table\nt_em = t_em.rename_column('specid_sdss', 'specid')\nt_common_em = join(t_comb_unique, t_em, keys='specid', table_names=['common', 'emission'], join_type='inner')",
                "true_code": "## Find sources from the common SDSS and DESI catalog that has [OII] flux\n## This part will change with SPARCL as well\n\nt_oii_comb = join(t_comb_unique, t_em, keys = ['specid_sdss'])",
                "error_ind": 49,
                "direct_match": false,
                "fuzzy_match": 8,
                "codebleu": {
                    "codebleu": 0.2616788024939594,
                    "ngram_match_score": 0.04403666361864152,
                    "weighted_ngram_match_score": 0.044345213023862864,
                    "syntax_match_score": 0.125,
                    "dataflow_match_score": 0.8333333333333334
                },
                "codebertscore": {
                    "precision": 0.8337258696556091,
                    "recall": 0.7699013352394104,
                    "F1": 0.800543487071991,
                    "F3": 0.7758405804634094
                },
                "codebertscore_rescaled": {
                    "precision": 0.6674517393112183,
                    "recall": 0.5398026704788208,
                    "F1": 0.6010869741439819,
                    "F3": 0.5516811609268188
                }
            },
            {
                "ind": 51,
                "gen_code": "Here is the code that matches the specifications:\n\nimport numpy as np\nnp.seterr(divide = 'ignore')    ## Ignores division by zero warning\n\nfrom astropy.table import Table, join, hstack\nfrom astropy.coordinates import SkyCoord, search_around_sky\nimport astropy.units as u\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Data Lab\nfrom dl import queryClient as qc\n\n## SPARCL\nfrom sparcl.client import SparclClient\n\n## The outfields that are required as output from SPARCL\nout = ['sparcl_id', 'specid', 'ra', 'dec', 'redshift'] \n\n## Constraints\n## SPECTYPE = 'GALAXY'\n## 208.4 <= RA <= 210.2\n## 4.8 <= DEC <= 6.4\n## 0.1 <= Redshift <= 0.15\n## SPECPRIMARY = True -- consider only primary spectra\n## \"datasetgroup\" denotes the required survey (SDSS_BOSS for SDSS-DR16 (SDSS+BOSS data), and DESI for DESI EDR data (will be updated with future releases))\n\nsdss_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['SDSS_BOSS'], 'redshift': [0.1, 0.15]}\ndesi_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['DESI'], 'redshift': [0.1, 0.15]} \n\n## Load the SPARCL client for data discovery and spectral access\n\nclient = SparclClient()\n\n## Making the matplotlib plots look nicer\nsettings = {\n    'font.size':20,\n    'axes.linewidth':2.0,\n    'xtick.major.size':6.0,\n    'xtick.minor.size':4.0,\n    'xtick.major.width':2.0,\n    'xtick.minor.width':1.5,\n    'xtick.direction':'in', \n    'xtick.minor.visible':True,\n    'xtick.top':True,\n    'ytick.major",
                "true_code": "len(t_oii_comb)",
                "error_ind": 51,
                "direct_match": false,
                "fuzzy_match": 1,
                "codebleu": {
                    "codebleu": 0.25,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.4424162209033966,
                    "recall": 0.5830500721931458,
                    "F1": 0.5030897855758667,
                    "F3": 0.5650873184204102
                },
                "codebertscore_rescaled": {
                    "precision": -0.11516755819320679,
                    "recall": 0.1661001443862915,
                    "F1": 0.0061795711517333984,
                    "F3": 0.1301746368408203
                }
            },
            {
                "ind": 53,
                "gen_code": "<PYTHON CODE>\nprint ('Number of unique SDSS objects: ', len(np.unique(t_oii_comb['specid_sdss'])))\nprint ('Number of unique DESI objects: ', len(np.unique(t_oii_comb['specid_desi'])))\n<CELL END>",
                "true_code": "len(np.unique(t_oii_comb['specid_sdss'])), len(np.unique(t_oii_comb['specid_desi']))",
                "error_ind": 53,
                "direct_match": false,
                "fuzzy_match": 60,
                "codebleu": {
                    "codebleu": 0.46875,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.875,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8234665989875793,
                    "recall": 0.9509603381156921,
                    "F1": 0.8826332092285156,
                    "F3": 0.9364615082740784
                },
                "codebertscore_rescaled": {
                    "precision": 0.6469331979751587,
                    "recall": 0.9019206762313843,
                    "F1": 0.7652664184570312,
                    "F3": 0.8729230165481567
                }
            },
            {
                "ind": 56,
                "gen_code": "# Extracting unique identifiers for SDSS and DESI spectra\nspecid_sdss = np.unique(t_oii_comb['specid_sdss'])\nspecid_desi = np.unique(t_oii_comb['specid_desi'])",
                "true_code": "## Unique identifiers for SDSS and DESI\nids_sdss = [str(idx) for idx in t_oii_comb['sparcl_id_sdss'].data]\nids_desi = [str(idx) for idx in t_oii_comb['sparcl_id_desi'].data]",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 66,
                "codebleu": {
                    "codebleu": 0.2508520053214944,
                    "ngram_match_score": 0.17937980782158092,
                    "weighted_ngram_match_score": 0.1849304691034943,
                    "syntax_match_score": 0.21052631578947367,
                    "dataflow_match_score": 0.42857142857142855
                },
                "codebertscore": {
                    "precision": 0.9019473195075989,
                    "recall": 0.862653911113739,
                    "F1": 0.8818631172180176,
                    "F3": 0.8664284944534302
                },
                "codebertscore_rescaled": {
                    "precision": 0.8038946390151978,
                    "recall": 0.725307822227478,
                    "F1": 0.7637262344360352,
                    "F3": 0.7328569889068604
                }
            },
            {
                "ind": 58,
                "gen_code": "## Retrieve the spectra data for SDSS and DESI\nspectra_sdss = client.retrieve(ids_sdss, attributes=['wavelength', 'flux', 'ivar', 'model', 'sparcl_id'])\nspectra_desi = client.retrieve(ids_desi, attributes=['wavelength', 'flux', 'ivar', 'model', 'sparcl_id'])",
                "true_code": "## Use client.retrive for spectra\n## This retrieves all the 89 spectra at once\n\nsel = ['wavelength', 'flux', 'ivar', 'model', 'sparcl_id']\n\nspec_sdss = client.retrieve(uuid_list=ids_sdss, include = sel)\nspec_desi = client.retrieve(uuid_list=ids_desi, include = sel)",
                "error_ind": 58,
                "direct_match": false,
                "fuzzy_match": 35,
                "codebleu": {
                    "codebleu": 0.21821443669913343,
                    "ngram_match_score": 0.03583178555245556,
                    "weighted_ngram_match_score": 0.0391998742875564,
                    "syntax_match_score": 0.34782608695652173,
                    "dataflow_match_score": 0.45
                },
                "codebertscore": {
                    "precision": 0.8886197209358215,
                    "recall": 0.8435428142547607,
                    "F1": 0.8654947876930237,
                    "F3": 0.847843587398529
                },
                "codebertscore_rescaled": {
                    "precision": 0.7772394418716431,
                    "recall": 0.6870856285095215,
                    "F1": 0.7309895753860474,
                    "F3": 0.6956871747970581
                }
            },
            {
                "ind": 60,
                "gen_code": "## Reorder the spectra to match the original table\nspec_sdss = [spec_sdss.records[i] for i in np.argsort([spec_sdss.records[i]['sparcl_id'] for i in range(len(spec_sdss.records))])]\nspec_desi = [spec_desi.records[i] for i in np.argsort([spec_desi.records[i]['sparcl_id'] for i in range(len(spec_desi.records))])]",
                "true_code": "## Reorder the records to match the original table\n\nres_sdss = spec_sdss.reorder(ids_sdss)\nres_desi = spec_desi.reorder(ids_desi)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 22,
                "codebleu": {
                    "codebleu": 0.33058271235248937,
                    "ngram_match_score": 0.15878174295086994,
                    "weighted_ngram_match_score": 0.3567309246409057,
                    "syntax_match_score": 0.18181818181818182,
                    "dataflow_match_score": 0.625
                },
                "codebertscore": {
                    "precision": 0.789217472076416,
                    "recall": 0.8925005793571472,
                    "F1": 0.8376874327659607,
                    "F3": 0.8809714913368225
                },
                "codebertscore_rescaled": {
                    "precision": 0.578434944152832,
                    "recall": 0.7850011587142944,
                    "F1": 0.6753748655319214,
                    "F3": 0.761942982673645
                }
            },
            {
                "ind": 62,
                "gen_code": "def get_spectra(rec, z, rest_frame=True):\n    \"\"\"\n    This function takes a SPARCL record and the redshift of a galaxy \n    to return the rest-frame spectra. It allows for optional toggling \n    between observed and rest-frame spectra output.\n\n    Parameters:\n    rec (SPARCL record): The SPARCL record of the galaxy.\n    z (float): The redshift of the galaxy.\n    rest_frame (bool): Whether to return the rest-frame spectra. Default is True.\n\n    Returns:\n    wavelength (numpy array): The wavelength of the spectra.\n    flux (numpy array): The flux of the spectra.\n    ivar (numpy array): The inverse variance of the spectra.\n    \"\"\"\n\n    wavelength = np.array(rec['wavelength'])\n    flux = np.array(rec['flux'])\n    ivar = np.array(rec['ivar'])\n\n    if rest_frame:\n        wavelength /= (1 + z)\n\n    return wavelength, flux, ivar",
                "true_code": "def get_restframe_spectra(sparcl_rec, z, rest_frame = True):\n    \"\"\"\n    Function to extract the spectra from a given SPARCL record\n    \n    Parameters\n    ----------\n    sparcl_rec : dict\n        SPARCL record of a given object\n        \n    z : float\n        Redshift of the object\n        \n    rest_frame : bool\n        Whether or not to return the rest-frame spectra.\n        Default is True.\n        \n    Returns \n    -------\n    wavelength : array\n        Wavelength array of the spectra. \n        Returns the rest-frame values if rest_frame = True\n    \n    flux : array\n        Flux array of the spectra. \n        Returns the rest-frame values if rest_frame = True\n        \n    ivar : array\n        Inverse variance array of the spectra. \n        Returns the rest-frame values if rest_frame = True\n    \"\"\"\n    \n    wavelength = sparcl_rec.wavelength\n    flux = sparcl_rec.flux\n    ivar = sparcl_rec.ivar\n    \n    if (rest_frame == True):\n        wavelength = wavelength/(1+z)\n        flux = flux*(1+z)\n        ivar = ivar/((1+z)**2)\n    \n    return (wavelength, flux, ivar)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 20,
                "codebleu": {
                    "codebleu": 0.2801281282046367,
                    "ngram_match_score": 0.12848141320657577,
                    "weighted_ngram_match_score": 0.12806713564800692,
                    "syntax_match_score": 0.2972972972972973,
                    "dataflow_match_score": 0.5666666666666667
                },
                "codebertscore": {
                    "precision": 0.8756181597709656,
                    "recall": 0.876228392124176,
                    "F1": 0.8759231567382812,
                    "F3": 0.876167356967926
                },
                "codebertscore_rescaled": {
                    "precision": 0.7512363195419312,
                    "recall": 0.752456784248352,
                    "F1": 0.7518463134765625,
                    "F3": 0.752334713935852
                }
            },
            {
                "ind": 64,
                "gen_code": "## Determine the number of galaxies that have been consolidated from our data selection process\nn_galaxies = len(t_oii_comb)\nprint(f\"Number of galaxies with [OII] measurements: {n_galaxies}\")",
                "true_code": "len(t_oii_comb)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 15,
                "codebleu": {
                    "codebleu": 0.4066241106813578,
                    "ngram_match_score": 0.007575731225158965,
                    "weighted_ngram_match_score": 0.11892071150027214,
                    "syntax_match_score": 0.5,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.6998424530029297,
                    "recall": 0.8789589405059814,
                    "F1": 0.7792402505874634,
                    "F3": 0.8570244312286377
                },
                "codebertscore_rescaled": {
                    "precision": 0.3996849060058594,
                    "recall": 0.7579178810119629,
                    "F1": 0.5584805011749268,
                    "F3": 0.7140488624572754
                }
            },
            {
                "ind": 66,
                "gen_code": "## Calculate the total [OII] line flux and its associated error\nflux_oii_3726 = t_oii_comb['flux_oii_3726'].data + t_oii_comb['flux_oii_3728'].data\nflux_oii_3726_err = np.sqrt(t_oii_comb['flux_oii_3726_err'].data**2 + t_oii_comb['flux_oii_3728_err'].data**2)\n\n## Calculate the signal-to-noise ratio (SNR) for the [OII] emission\nsnr_oii = flux_oii_3726/flux_oii_3726_err\n\n## Find the galaxy with the maximum [OII] SNR\nmax_snr_idx = np.argmax(snr_oii)\nmax_snr_id_sdss = t_oii_comb['specid_sdss'].data[max_snr_idx]\nmax_snr_id_desi = t_oii_comb['specid_desi'].data[max_snr_idx]\n\nprint('Maximum [OII] SNR SDSS ID:', max_snr_id_sdss)\nprint('Maximum [OII] SNR DESI ID:', max_snr_id_desi)",
                "true_code": "total_oii_flux = t_oii_comb['flux_oii_3726'].data + t_oii_comb['flux_oii_3728'].data\ntotal_oii_err = np.sqrt((t_oii_comb['flux_oii_3726_err'].data**2)+(t_oii_comb['flux_oii_3728_err'].data**2))\noii_snr = total_oii_flux/total_oii_err\n\n## Select source with the maximum [OII] flux SNR \nii = np.argmax(oii_snr)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 39,
                "codebleu": {
                    "codebleu": 0.5221925956211304,
                    "ngram_match_score": 0.08147639524255246,
                    "weighted_ngram_match_score": 0.24258810488902785,
                    "syntax_match_score": 0.7647058823529411,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.830680787563324,
                    "recall": 0.9344376921653748,
                    "F1": 0.8795097470283508,
                    "F3": 0.9229100346565247
                },
                "codebertscore_rescaled": {
                    "precision": 0.661361575126648,
                    "recall": 0.8688753843307495,
                    "F1": 0.7590194940567017,
                    "F3": 0.8458200693130493
                }
            },
            {
                "ind": 68,
                "gen_code": "## Extract the rest-frame spectral data for SDSS and DESI\nsdss_rec = res_sdss.records[ii]\ndesi_rec = res_desi.records[ii]\n\nsdss_wave, sdss_flux, sdss_ivar = get_restframe_spectra(sdss_rec, t_oii_comb['redshift_sdss'].data[ii])\ndesi_wave, desi_flux, desi_ivar = get_restframe_spectra(desi_rec, t_oii_comb['redshift_desi'].data[ii])",
                "true_code": "lam_desi, flux_desi, ivar_desi = get_restframe_spectra(res_desi.records[ii], t_oii_comb['redshift_desi'].data[ii], rest_frame = True)\nlam_sdss, flux_sdss, ivar_sdss = get_restframe_spectra(res_sdss.records[ii], t_oii_comb['redshift_sdss'].data[ii], rest_frame = True)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 24,
                "codebleu": {
                    "codebleu": 0.2615784419074872,
                    "ngram_match_score": 0.009498525867740094,
                    "weighted_ngram_match_score": 0.015276780223747026,
                    "syntax_match_score": 0.56,
                    "dataflow_match_score": 0.46153846153846156
                },
                "codebertscore": {
                    "precision": 0.8703974485397339,
                    "recall": 0.9075791835784912,
                    "F1": 0.8885995149612427,
                    "F3": 0.9037186503410339
                },
                "codebertscore_rescaled": {
                    "precision": 0.7407948970794678,
                    "recall": 0.8151583671569824,
                    "F1": 0.7771990299224854,
                    "F3": 0.8074373006820679
                }
            },
            {
                "ind": 70,
                "gen_code": "err_desi = 1/np.sqrt(ivar_sdss)\nerr_sdss = 1/np.sqrt(ivar_desi)",
                "true_code": "err_sdss = np.sqrt(1/ivar_sdss)\nerr_desi = np.sqrt(1/ivar_desi)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 86,
                "codebleu": {
                    "codebleu": 0.2995088968196169,
                    "ngram_match_score": 0.12209471671615688,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 0.15384615384615385,
                    "dataflow_match_score": 0.8
                },
                "codebertscore": {
                    "precision": 0.9489508271217346,
                    "recall": 0.9500443935394287,
                    "F1": 0.9494973421096802,
                    "F3": 0.9499348998069763
                },
                "codebertscore_rescaled": {
                    "precision": 0.8979016542434692,
                    "recall": 0.9000887870788574,
                    "F1": 0.8989946842193604,
                    "F3": 0.8998697996139526
                }
            },
            {
                "ind": 72,
                "gen_code": "import numpy as np\nnp.seterr(divide = 'ignore')    ## Ignores division by zero warning\n\nfrom astropy.table import Table, join, hstack\nfrom astropy.coordinates import SkyCoord, search_around_sky\nimport astropy.units as u\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Data Lab\nfrom dl import queryClient as qc\n\n## SPARCL\nfrom sparcl.client import SparclClient\n\n## The outfields that are required as output from SPARCL\nout = ['sparcl_id', 'specid', 'ra', 'dec', 'redshift'] \n\n## Constraints\n## SPECTYPE = 'GALAXY'\n## 208.4 <= RA <= 210.2\n## 4.8 <= DEC <= 6.4\n## 0.1 <= Redshift <= 0.15\n## SPECPRIMARY = True -- consider only primary spectra\n## \"datasetgroup\" denotes the required survey (SDSS_BOSS for SDSS-DR16 (SDSS+BOSS data), and DESI for DESI EDR data (will be updated with future releases))\n\nsdss_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['SDSS_BOSS'], 'redshift': [0.1, 0.15]}\ndesi_cons = {'spectype':['GALAXY'], 'ra':[208.4, 210.2], 'dec':[4.8, 6.4], 'specprimary': [True], 'datasetgroup': ['DESI'], 'redshift': [0.1, 0.15]} \n\n## Load the SPARCL client for data discovery and spectral access\nclient = SparclClient()\n\n## Find common sources between SDSS and DESI\ncat_desi = SkyCoord(ra = ra_desi*u.deg, dec = dec_desi*u.deg)\ncat_sdss = SkyCoord(ra = ra_sdss*u.deg, dec = dec_sdss*u.deg)\n\nii_desi, ii_sdss, _, _ = search_around_sky(cat_desi, cat_sdss, 0.5*u.arcsec)\n\n## Query to access galaxies with non-zero [OII] measurements\nquery = \"\"\"\nSELECT specobjid as specid_sdss, \n",
                "true_code": "plt.figure(figsize = (20, 8))\n\nplt.plot(lam_desi, flux_desi, color = 'k', label = 'DESI-EDR')\nplt.plot(lam_sdss, flux_sdss, color = 'r', label = 'SDSS')\nplt.xlim([3600, 7000])\nplt.ylim([-5, 100])\nplt.xlabel('$\\lambda~[\\AA]$')\nplt.ylabel('$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~{\\AA}^{-1}]$')\nplt.legend(loc = 'upper left')",
                "error_ind": 72,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.25620785993019934,
                    "ngram_match_score": 0.0013221838202300833,
                    "weighted_ngram_match_score": 0.009772992164303728,
                    "syntax_match_score": 0.4423076923076923,
                    "dataflow_match_score": 0.5714285714285714
                },
                "codebertscore": {
                    "precision": 0.5957964062690735,
                    "recall": 0.6853684782981873,
                    "F1": 0.6374512314796448,
                    "F3": 0.6752172112464905
                },
                "codebertscore_rescaled": {
                    "precision": 0.19159281253814697,
                    "recall": 0.3707369565963745,
                    "F1": 0.27490246295928955,
                    "F3": 0.35043442249298096
                }
            },
            {
                "ind": 74,
                "gen_code": "## Zooming in on the [OII] doublet region\n\nplt.figure(figsize = (8, 8))\n\nplt.plot(lam_desi, flux_desi, color = 'k', label = 'DESI-EDR')\nplt.fill_between(lam_desi, flux_desi - err_desi, flux_desi + err_desi, color = 'grey', alpha = 0.5)\n\nplt.plot(lam_sdss, flux_sdss, color = 'r', label = 'SDSS')\nplt.fill_between(lam_sdss, flux_sdss - err_sdss, flux_sdss + err_sdss, color = 'r', alpha = 0.5)\n\nplt.axvline(3726, color = 'r', linestyle = ':')\nplt.axvline(3728, color = 'r', linestyle = ':')\n\nplt.xlim([3710, 3740])\nplt.ylim([-5, 50])\nplt.xlabel('$\\lambda~[\\AA]$')\nplt.ylabel('$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~{\\AA}^{-1}]$')\nplt.legend(loc = 'upper left')",
                "true_code": "fig, axs = plt.subplots(1,2,figsize = (20,6), sharex = True, sharey = True)\n\naxs[0].plot(lam_sdss, flux_sdss, color = 'k', lw = 2.0)\naxs[0].fill_between(lam_sdss, flux_sdss-err_sdss, flux_sdss+err_sdss, color = 'grey', alpha = 0.5)\naxs[1].plot(lam_desi, flux_desi, color = 'k', lw = 2.0)\naxs[1].fill_between(lam_desi, flux_desi-err_desi, flux_desi+err_desi, color = 'grey', alpha = 0.5)\naxs[0].axvline(3727.092, color = 'r', ls = ':')\naxs[0].axvline(3729.875, color = 'r', ls = ':')\naxs[1].axvline(3727.092, color = 'r', ls = ':')\naxs[1].axvline(3729.875, color = 'r', ls = ':')\n\naxs[0].set(xlabel = '$\\lambda~[\\AA]$', ylabel = '$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~{\\AA}^{-1}]$', title = 'SDSS')\naxs[1].set(xlim = [3710,3745], ylim = [-2,100], title = 'DESI-EDR', xlabel = '$\\lambda~[\\AA]$', ylabel = '$F_{\\lambda}~[10^{-17}~ergs~s^{-1}~cm^{-2}~{\\AA}^{-1}]$')\n\nplt.show()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 19,
                "codebleu": {
                    "codebleu": 0.2480806972172054,
                    "ngram_match_score": 0.13848173859004043,
                    "weighted_ngram_match_score": 0.14221877424972565,
                    "syntax_match_score": 0.4830508474576271,
                    "dataflow_match_score": 0.22857142857142856
                },
                "codebertscore": {
                    "precision": 0.885888397693634,
                    "recall": 0.8617819547653198,
                    "F1": 0.873668909072876,
                    "F3": 0.864133358001709
                },
                "codebertscore_rescaled": {
                    "precision": 0.7717767953872681,
                    "recall": 0.7235639095306396,
                    "F1": 0.747337818145752,
                    "F3": 0.728266716003418
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.0,
            "fuzzy_match": 37.0,
            "codebleu": 0.35555120394729983,
            "syntax_match_score": 0.5373945626037571,
            "codebertscore": 0.8303937496560992,
            "codebertscore_rescaled": 0.6607874993121985,
            "code_success": 0.5757575757575758,
            "total_code_cell_count": 33
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/02_GettingStartedWithDataLab_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/01_GettingStartedWithDataLab/02_GettingStartedWithDataLab.ipynb",
            "prefix": "gettingstarted_2"
        },
        "model": {
            "name": "llama3.1",
            "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "library": "together"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "# Notebook Metadata\nnotebook_id = \"ASTRONOMY_ANALYSIS_001\"\nauthor = \"Your Name\"\nversion = \"1.0.0\"\ndate_created = \"2023-12-01\"\nlast_updated = \"2023-12-01\"\n\n# Targeted Datasets\ndatasets = [\n    \"Gaia DR3\",\n    \"SDSS DR17\",\n    \"2MASS PSC\"\n]\n\n# Keywords\nkeywords = [\n    \"Astrometry\",\n    \"Photometry\",\n    \"Spectroscopy\",\n    \"Galactic Structure\",\n    \"Stellar Evolution\"\n]",
                "true_code": "__nbid__ = '0002'\n__author__ = 'Knut Olsen <knut.olsen@noirlab.edu>, Robert Nikutta <robert.nikutta@noirlab.edu>'\n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['smash_dr1', 'des_dr1']\n__keywords__ = ['tutorial', 'query', 'image cutout', 'globular cluster', 'SIA']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.39398735514194116,
                    "ngram_match_score": 0.006400178381760218,
                    "weighted_ngram_match_score": 0.010128952330932188,
                    "syntax_match_score": 0.8260869565217391,
                    "dataflow_match_score": 0.7333333333333333
                },
                "codebertscore": {
                    "precision": 0.7020691633224487,
                    "recall": 0.6945719122886658,
                    "F1": 0.6983004212379456,
                    "F3": 0.6953144073486328
                },
                "codebertscore_rescaled": {
                    "precision": 0.40413832664489746,
                    "recall": 0.38914382457733154,
                    "F1": 0.3966008424758911,
                    "F3": 0.3906288146972656
                }
            },
            {
                "ind": 10,
                "gen_code": "# Authenticate with the Data Lab\n# If you want to store results, you'll need to authenticate\n# To do so, uncomment the following lines and execute them\n\ntoken = ac.login()\nac.set_token(token)\n\n# Alternatively, if you prefer not to store your password in plain text,\n# you can use the following method to prompt the user for their password\n# and then authenticate:\n\n# password = getpass('Enter your Data Lab password: ')\n# token = ac.login(authenticate=False, password=password)\n# ac.set_token(token)",
                "true_code": "#token = ac.login(input(\"Enter user name: (+ENTER) \"),getpass(\"Enter password: (+ENTER) \"))\nac.whoAmI()",
                "error_ind": 10,
                "direct_match": false,
                "fuzzy_match": 6,
                "codebleu": {
                    "codebleu": 0.4069571330749629,
                    "ngram_match_score": 0.0030201172981498357,
                    "weighted_ngram_match_score": 0.024808415001701823,
                    "syntax_match_score": 0.6,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.6736422777175903,
                    "recall": 0.7393648028373718,
                    "F1": 0.7049750685691833,
                    "F3": 0.7322210669517517
                },
                "codebertscore_rescaled": {
                    "precision": 0.34728455543518066,
                    "recall": 0.47872960567474365,
                    "F1": 0.4099501371383667,
                    "F3": 0.4644421339035034
                }
            },
            {
                "ind": 12,
                "gen_code": "# Fetch a list of available datasets and their descriptions\navailable_datasets = qc.schema()\nprint(available_datasets)",
                "true_code": "print(qc.schema())",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 24,
                "codebleu": {
                    "codebleu": 0.35714285714285715,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.42857142857142855,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.737438976764679,
                    "recall": 0.9187209606170654,
                    "F1": 0.8181585073471069,
                    "F3": 0.8966782093048096
                },
                "codebertscore_rescaled": {
                    "precision": 0.4748779535293579,
                    "recall": 0.8374419212341309,
                    "F1": 0.6363170146942139,
                    "F3": 0.7933564186096191
                }
            },
            {
                "ind": 14,
                "gen_code": "# Get list of tables for SMASH DR1\nsmash_dr1_tables = qc.schema('smash_dr1')\nprint(smash_dr1_tables)",
                "true_code": "print(qc.schema('smash_dr1'))",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 39,
                "codebleu": {
                    "codebleu": 0.375,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.5,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.8406274318695068,
                    "recall": 0.9196362495422363,
                    "F1": 0.8783587217330933,
                    "F3": 0.9110733270645142
                },
                "codebertscore_rescaled": {
                    "precision": 0.6812548637390137,
                    "recall": 0.8392724990844727,
                    "F1": 0.7567174434661865,
                    "F3": 0.8221466541290283
                }
            },
            {
                "ind": 16,
                "gen_code": "# Get list of columns for the object table in SMASH DR1\nprint(qc.schema('smash_dr1', 'object'))",
                "true_code": "print(qc.schema('smash_dr1.object'))",
                "error_ind": 16,
                "direct_match": false,
                "fuzzy_match": 53,
                "codebleu": {
                    "codebleu": 0.3125,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.25,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.823754072189331,
                    "recall": 0.9380427002906799,
                    "F1": 0.8771914839744568,
                    "F3": 0.9252063035964966
                },
                "codebertscore_rescaled": {
                    "precision": 0.6475081443786621,
                    "recall": 0.8760854005813599,
                    "F1": 0.7543829679489136,
                    "F3": 0.8504126071929932
                }
            },
            {
                "ind": 18,
                "gen_code": "# Query to get statistics for the SMASH DR1 object table\nquery = \"SELECT * FROM tbl_stat WHERE table_name='smash_dr1.object'\"\nresult = qc.query(query)\nprint(result)",
                "true_code": "#query = \"SELECT COUNT(ra) FROM phat_v2.phot_mod\" # SLOW\nquery = \"SELECT * FROM tbl_stat WHERE schema='smash_dr1' AND tbl_name='object'\" # Retrieve useful stats, quickly",
                "error_ind": 18,
                "direct_match": false,
                "fuzzy_match": 50,
                "codebleu": {
                    "codebleu": 0.5709983787151212,
                    "ngram_match_score": 0.26699675743024226,
                    "weighted_ngram_match_score": 0.2669967574302422,
                    "syntax_match_score": 0.75,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.844631552696228,
                    "recall": 0.8445068597793579,
                    "F1": 0.844569206237793,
                    "F3": 0.8445193767547607
                },
                "codebertscore_rescaled": {
                    "precision": 0.689263105392456,
                    "recall": 0.6890137195587158,
                    "F1": 0.6891384124755859,
                    "F3": 0.6890387535095215
                }
            },
            {
                "ind": 20,
                "gen_code": "# Execute the query to retrieve statistics for the SMASH DR1 object table\njob = qc.query(query)\nprint(job)",
                "true_code": "info = qc.query(sql=query) # by default the result is a CSV formatted string",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 26,
                "codebleu": {
                    "codebleu": 0.194279318452961,
                    "ngram_match_score": 0.015138514598766055,
                    "weighted_ngram_match_score": 0.019121616355935123,
                    "syntax_match_score": 0.14285714285714285,
                    "dataflow_match_score": 0.6
                },
                "codebertscore": {
                    "precision": 0.7710709571838379,
                    "recall": 0.7958935499191284,
                    "F1": 0.7832856178283691,
                    "F3": 0.7933396100997925
                },
                "codebertscore_rescaled": {
                    "precision": 0.5421419143676758,
                    "recall": 0.5917870998382568,
                    "F1": 0.5665712356567383,
                    "F3": 0.586679220199585
                }
            },
            {
                "ind": 22,
                "gen_code": "print(info)",
                "true_code": "print(info)",
                "error_ind": null,
                "direct_match": true,
                "fuzzy_match": 100,
                "codebleu": {
                    "codebleu": 0.5553941064735807,
                    "ngram_match_score": 0.1778279410038923,
                    "weighted_ngram_match_score": 0.04374848489043043,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 1.0,
                    "recall": 1.0,
                    "F1": 1.0,
                    "F3": 1.0
                },
                "codebertscore_rescaled": {
                    "precision": 1.0,
                    "recall": 1.0,
                    "F1": 1.0,
                    "F3": 1.0
                }
            },
            {
                "ind": 24,
                "gen_code": "query = \"SELECT * FROM smash_dr1.object LIMIT 10\"\ndata = qc.query(sql=query)\nprint(data)",
                "true_code": "query = \"SELECT * FROM smash_dr1.object LIMIT 10\"\nresult = qc.query(sql=query) # by default the result is a CSV formatted string",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 70,
                "codebleu": {
                    "codebleu": 0.6402199095802964,
                    "ngram_match_score": 0.31668525203370046,
                    "weighted_ngram_match_score": 0.34419438628748505,
                    "syntax_match_score": 0.9,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9561440348625183,
                    "recall": 0.8673116564750671,
                    "F1": 0.9095640778541565,
                    "F3": 0.8754451274871826
                },
                "codebertscore_rescaled": {
                    "precision": 0.9122880697250366,
                    "recall": 0.7346233129501343,
                    "F1": 0.819128155708313,
                    "F3": 0.7508902549743652
                }
            },
            {
                "ind": 26,
                "gen_code": "print(type(result))\nprint(result[:1000])",
                "true_code": "print(type(result))\nprint(result[:1000]) # print just the first 1000 characters of the returned string",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 56,
                "codebleu": {
                    "codebleu": 0.5085373427625461,
                    "ngram_match_score": 0.0012923506022069113,
                    "weighted_ngram_match_score": 0.03285702044797773,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9565921425819397,
                    "recall": 0.7972729206085205,
                    "F1": 0.8696963787078857,
                    "F3": 0.8107763528823853
                },
                "codebertscore_rescaled": {
                    "precision": 0.9131842851638794,
                    "recall": 0.594545841217041,
                    "F1": 0.7393927574157715,
                    "F3": 0.6215527057647705
                }
            },
            {
                "ind": 28,
                "gen_code": "import pandas as pd\nfrom dl.helpers.utils import convert\n\n# Convert the CSV formatted result into a Pandas DataFrame\ndf = convert(result)\n\n# Display the first few rows of the DataFrame\nprint(df.head())",
                "true_code": "df = convert(result,'pandas')\ndf.head()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 25,
                "codebleu": {
                    "codebleu": 0.21836066506463991,
                    "ngram_match_score": 0.012756976469629349,
                    "weighted_ngram_match_score": 0.16068568378893033,
                    "syntax_match_score": 0.3,
                    "dataflow_match_score": 0.4
                },
                "codebertscore": {
                    "precision": 0.7213595509529114,
                    "recall": 0.8443266153335571,
                    "F1": 0.7780142426490784,
                    "F3": 0.8301749229431152
                },
                "codebertscore_rescaled": {
                    "precision": 0.44271910190582275,
                    "recall": 0.6886532306671143,
                    "F1": 0.5560284852981567,
                    "F3": 0.6603498458862305
                }
            },
            {
                "ind": 30,
                "gen_code": "# Construct and execute a query with the preferred output format option\nquery = \"SELECT * FROM smash_dr1.object LIMIT 10\"\nresult = qc.query(sql=query, fmt='pandas') \nresult.head()",
                "true_code": "query = \"SELECT * FROM smash_dr1.object LIMIT 10\"\ndf = qc.query(sql=query,fmt='pandas')\ndf.head()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 67,
                "codebleu": {
                    "codebleu": 0.7281119125965482,
                    "ngram_match_score": 0.280892413206789,
                    "weighted_ngram_match_score": 0.6315552371794037,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8683931827545166,
                    "recall": 0.9478253722190857,
                    "F1": 0.9063722491264343,
                    "F3": 0.9392341375350952
                },
                "codebertscore_rescaled": {
                    "precision": 0.7367863655090332,
                    "recall": 0.8956507444381714,
                    "F1": 0.8127444982528687,
                    "F3": 0.8784682750701904
                }
            },
            {
                "ind": 33,
                "gen_code": "# Define parameters for the image cutout\nra = 00.522583  # Right Ascension (RA) of NGC 288\ndec = -26.594167  # Declination (Dec) of NGC 288\nfov = 0.1  # Field of view (FOV) in degrees\n\n# Perform a search for images overlapping with the specified sky region\nresults = svc.search(pos=(ra, dec), size=fov, format=\"image/fits\")\n\n# Print the number of images found\nprint(len(results))\n\n# Check if any images were found\nif len(results) > 0:\n    # Retrieve the first image\n    image = results[0]\n\n    # Download the image\n    image_data = svc.get_data(image)\n\n    # Save the image to a file\n    with open(\"image.fits\", \"wb\") as f:\n        f.write(image_data)\nelse:\n    print(\"No images found.\")",
                "true_code": "# NGC 288 (a globular cluster)\nra = 13.19     # in decimal degrees\ndec = -26.59   # in decimal degrees\n\nfov = 13/60  # image cutout field of view (in degrees; here 13 arminutes = 0.22 degrees)\n\nimgTable = svc.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()  # uses declination correction",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 6,
                "codebleu": {
                    "codebleu": 0.2656537774468197,
                    "ngram_match_score": 0.01023711607372352,
                    "weighted_ngram_match_score": 0.023392486467178585,
                    "syntax_match_score": 0.3333333333333333,
                    "dataflow_match_score": 0.6956521739130435
                },
                "codebertscore": {
                    "precision": 0.72440105676651,
                    "recall": 0.7866648435592651,
                    "F1": 0.7542501091957092,
                    "F3": 0.7799609303474426
                },
                "codebertscore_rescaled": {
                    "precision": 0.44880211353302,
                    "recall": 0.5733296871185303,
                    "F1": 0.5085002183914185,
                    "F3": 0.5599218606948853
                }
            },
            {
                "ind": 35,
                "gen_code": "# Convert VOTable to Astropy table\nfrom astropy.table import Table\nimgTable = Table(imgTable)\n\n# Print the first few rows of the table\nprint(imgTable[:5])\n\n# Extract the URL for the image cutout\nurl = imgTable['access_url'][0]\n\n# Download the image cutout\nfrom urllib.request import urlretrieve\nurlretrieve(url, 'NGC288.fits')\n\n# Import the FITS image\nfrom astropy.io import fits\nimage = fits.open('NGC288.fits')[0].data\n\n# Display the image\nplt.imshow(image, cmap='gray')\nplt.show()\n\n# Create a color image by combining three FITS images\n# Assuming you have downloaded the FITS images for the g, r, and i bands\nfrom astropy.visualization import make_lupton_rgb\nimage_g = fits.open('NGC288_g.fits')[0].data\nimage_r = fits.open('NGC288_r.fits')[0].data\nimage_i = fits.open('NGC288_i.fits')[0].data\n\n# Create the color image\ncolor_image = make_lupton_rgb(image_g, image_r, image_i, Q=10, stretch=0.5)\n\n# Display the color image\nplt.imshow(color_image, cmap='gray')\nplt.show()",
                "true_code": "print(type(imgTable))\nimgTable",
                "error_ind": 35,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.35152770282234663,
                    "ngram_match_score": 0.0014758140748286537,
                    "weighted_ngram_match_score": 0.11892071150027214,
                    "syntax_match_score": 0.2857142857142857,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.5036824941635132,
                    "recall": 0.8159491419792175,
                    "F1": 0.6228697299957275,
                    "F3": 0.7683160901069641
                },
                "codebertscore_rescaled": {
                    "precision": 0.007364988327026367,
                    "recall": 0.6318982839584351,
                    "F1": 0.24573945999145508,
                    "F3": 0.5366321802139282
                }
            },
            {
                "ind": 37,
                "gen_code": "# Filter the results to only include g-band image stacks\ng_band_images = imgTable[(imgTable['band'] == 'g') & (imgTable['productType'] == 'image')]\ng_band_images",
                "true_code": "# boolean selection for just g-band images\nsel0 = imgTable['obs_bandpass'] == 'g'\n\n# logically add selections for 'Stack' and 'image' product type\nsel = sel0 & ((imgTable['proctype'] == 'Stack') & (imgTable['prodtype'] == 'image')) # basic selection\n\n# filter the above results table\nTable = imgTable[sel] # select\nTable",
                "error_ind": 37,
                "direct_match": false,
                "fuzzy_match": 41,
                "codebleu": {
                    "codebleu": 0.25009135256779386,
                    "ngram_match_score": 0.003993778422999467,
                    "weighted_ngram_match_score": 0.005987016463560547,
                    "syntax_match_score": 0.6153846153846154,
                    "dataflow_match_score": 0.375
                },
                "codebertscore": {
                    "precision": 0.876758873462677,
                    "recall": 0.7848828434944153,
                    "F1": 0.8282808065414429,
                    "F3": 0.7931947708129883
                },
                "codebertscore_rescaled": {
                    "precision": 0.753517746925354,
                    "recall": 0.5697656869888306,
                    "F1": 0.6565616130828857,
                    "F3": 0.5863895416259766
                }
            },
            {
                "ind": 39,
                "gen_code": "# Extract the URL associated with the desired image\nurl = Table['access_url'][0]\nprint(url)",
                "true_code": "row = Table[0]\nurl = row['access_url'] # get the download URL\nprint(url)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 44,
                "codebleu": {
                    "codebleu": 0.20772701340328845,
                    "ngram_match_score": 0.04324227075463215,
                    "weighted_ngram_match_score": 0.04740604259878138,
                    "syntax_match_score": 0.45454545454545453,
                    "dataflow_match_score": 0.2857142857142857
                },
                "codebertscore": {
                    "precision": 0.8885135650634766,
                    "recall": 0.9060298800468445,
                    "F1": 0.8971862196922302,
                    "F3": 0.9042472839355469
                },
                "codebertscore_rescaled": {
                    "precision": 0.7770271301269531,
                    "recall": 0.812059760093689,
                    "F1": 0.7943724393844604,
                    "F3": 0.8084945678710938
                }
            },
            {
                "ind": 41,
                "gen_code": "# Download the image using the URL\nfrom astropy.io import fits\nfrom astropy.utils.data import download_file\n\n# Download the image, and display progress\nimage_file = download_file(url, cache=True, show_progress=True)\n\n# Read the image data from the file\nimage_data = fits.getdata(image_file)\n\n# Display the image\nplt.imshow(image_data, cmap='gray')\nplt.show()",
                "true_code": "gimage = io.fits.getdata(utils.data.download_file(url,cache=True,show_progress=False,timeout=120))",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.24030805174645725,
                    "ngram_match_score": 0.004089349842971759,
                    "weighted_ngram_match_score": 0.10000000000000002,
                    "syntax_match_score": 0.21428571428571427,
                    "dataflow_match_score": 0.6428571428571429
                },
                "codebertscore": {
                    "precision": 0.7566386461257935,
                    "recall": 0.8343636393547058,
                    "F1": 0.7936026453971863,
                    "F3": 0.8258798718452454
                },
                "codebertscore_rescaled": {
                    "precision": 0.5132772922515869,
                    "recall": 0.6687272787094116,
                    "F1": 0.5872052907943726,
                    "F3": 0.6517597436904907
                }
            },
            {
                "ind": 43,
                "gen_code": "import matplotlib.pyplot as plt\nfrom astropy.visualization import make_lupton_rgb\nfrom astropy.visualization import simple_norm\n\nnorm = simple_norm(gimage, 'sqrt', percent=99.9)\nplt.imshow(gimage, cmap='gray', norm=norm, origin='lower')\nplt.show()",
                "true_code": "fig = plt.subplots(figsize=(10,10))\nplt.imshow(np.arcsinh(gimage),cmap='gray',norm=matplotlib.colors.Normalize(vmin=0))\nplt.axis('off');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 11,
                "codebleu": {
                    "codebleu": 0.27453256452204483,
                    "ngram_match_score": 0.008687475782716616,
                    "weighted_ngram_match_score": 0.05372849659117709,
                    "syntax_match_score": 0.2857142857142857,
                    "dataflow_match_score": 0.75
                },
                "codebertscore": {
                    "precision": 0.7816375494003296,
                    "recall": 0.8183828592300415,
                    "F1": 0.7995882630348206,
                    "F3": 0.8145536184310913
                },
                "codebertscore_rescaled": {
                    "precision": 0.5632750988006592,
                    "recall": 0.636765718460083,
                    "F1": 0.5991765260696411,
                    "F3": 0.6291072368621826
                }
            },
            {
                "ind": 45,
                "gen_code": "def get_image(ra, dec, fov, band):\n    # Define the SIA service URL\n    DEF_ACCESS_URL = \"https://datalab.noirlab.edu/sia/des_dr1\"\n    \n    # Create an SIA service instance\n    svc = sia.SIAService(DEF_ACCESS_URL)\n    \n    # Perform the search for images overlapping with the specified sky region\n    imgTable = svc.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n    \n    # Filter the results to obtain the desired band and product type\n    sel0 = imgTable['obs_bandpass'] == band\n    sel = sel0 & ((imgTable['proctype'] == 'Stack') & (imgTable['prodtype'] == 'image'))\n    Table = imgTable[sel]\n    \n    # Extract the URL for the deepest available stacked image\n    row = Table[0]\n    url = row['access_url']\n    \n    # Download the image using the Data Lab's utilities\n    image = io.fits.getdata(utils.data.download_file(url,cache=True,show_progress=False,timeout=120))\n    \n    return image\n\nThis function takes the right ascension (RA), declination (Dec), field of view (FOV), and band as input parameters and returns the deepest available stacked image for the specified location and band. You can use this function to retrieve images for different bands and create a composite color image.",
                "true_code": "# A function to download the deepest available stacked images\ndef download_deep_stack(ra,dec,fov=0.1,band='g'):\n    imgTable = svc.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n    print(\"The full image list contains\", len(imgTable), \"entries\")\n\n    # apply image seletion criteria\n    sel0 = imgTable['obs_bandpass'] == band\n    sel = sel0 & ((imgTable['proctype'] == 'Stack') & (imgTable['prodtype'] == 'image')) # basic selection\n    Table = imgTable[sel] # select\n\n    # if more than one image matches our desired criteria\n    if (len(Table)>0):\n        row = Table[np.argmax(Table['exptime'].data.data.astype('float'))] # pick image with longest exposure time\n        url = row['access_url'] # get the download URL\n        print ('Downloading deepest stacked image...')\n        image = io.fits.getdata(utils.data.download_file(url,cache=True,show_progress=False,timeout=120))\n        print(url)\n\n    # if no images match our criteria\n    else:\n        print ('No image available.')\n        image = None\n        \n    print()\n    return image",
                "error_ind": 45,
                "direct_match": false,
                "fuzzy_match": 35,
                "codebleu": {
                    "codebleu": 0.43172583596399583,
                    "ngram_match_score": 0.21128409223011618,
                    "weighted_ngram_match_score": 0.281502017508633,
                    "syntax_match_score": 0.6756756756756757,
                    "dataflow_match_score": 0.5584415584415584
                },
                "codebertscore": {
                    "precision": 0.7999444007873535,
                    "recall": 0.8403658270835876,
                    "F1": 0.819657027721405,
                    "F3": 0.8361407518386841
                },
                "codebertscore_rescaled": {
                    "precision": 0.599888801574707,
                    "recall": 0.6807316541671753,
                    "F1": 0.6393140554428101,
                    "F3": 0.6722815036773682
                }
            },
            {
                "ind": 47,
                "gen_code": "```python\n# Download r and i band images\nrimage = download_deep_stack(ra, dec, fov=0.1, band='r')\niimage = download_deep_stack(ra, dec, fov=0.1, band='i')\n```\n\n<MARKDOWN>\nOnce the images for all three bands have been successfully downloaded, you can proceed to create a composite color image. To do this, you'll need to scale the images and then combine them using the `make_lupton_rgb` function from `astropy.visualization`. This will produce a visually appealing representation of the target object.\n<CELL END>\n\n```python\n# Create a composite color image\nrgb = make_lupton_rgb(gimage, rimage, iimage, Q=10, stretch=0.5)\nplt.imshow(rgb, origin='lower')\nplt.axis('off')\n```\n\n<MARKDOWN>\nThis concludes the process of creating a color image using the SIA service. You have successfully downloaded the necessary images, combined them into a composite, and visualized the result.\n<CELL END>",
                "true_code": "rimage = download_deep_stack(ra,dec,fov,band='r')\niimage = download_deep_stack(ra,dec,fov,band='i')",
                "error_ind": 47,
                "direct_match": false,
                "fuzzy_match": 18,
                "codebleu": {
                    "codebleu": 0.3228178821062098,
                    "ngram_match_score": 0.0043416468735175285,
                    "weighted_ngram_match_score": 0.12209471671615688,
                    "syntax_match_score": 0.3076923076923077,
                    "dataflow_match_score": 0.8571428571428571
                },
                "codebertscore": {
                    "precision": 0.606086015701294,
                    "recall": 0.9132477641105652,
                    "F1": 0.7286176085472107,
                    "F3": 0.8691973090171814
                },
                "codebertscore_rescaled": {
                    "precision": 0.2121720314025879,
                    "recall": 0.8264955282211304,
                    "F1": 0.4572352170944214,
                    "F3": 0.7383946180343628
                }
            },
            {
                "ind": 49,
                "gen_code": "# Combine the g, r, and i band images into a false-color composite\nrgb_image = make_lupton_rgb(gimage, rimage, iimage, Q=10, stretch=0.5)\n\n# Display the composite image\nplt.imshow(rgb_image, origin='lower')\nplt.axis('off');",
                "true_code": "color_image = make_lupton_rgb(iimage, rimage, gimage, stretch=100, Q=0.1)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 22,
                "codebleu": {
                    "codebleu": 0.47610289964632146,
                    "ngram_match_score": 0.007987276352377327,
                    "weighted_ngram_match_score": 0.039281465090051315,
                    "syntax_match_score": 0.8571428571428571,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.7896143198013306,
                    "recall": 0.9151853919029236,
                    "F1": 0.8477752804756165,
                    "F3": 0.9008591771125793
                },
                "codebertscore_rescaled": {
                    "precision": 0.5792286396026611,
                    "recall": 0.8303707838058472,
                    "F1": 0.6955505609512329,
                    "F3": 0.8017183542251587
                }
            },
            {
                "ind": 51,
                "gen_code": "# Display the false-color image\nplt.figure(figsize=(10,10))\nplt.imshow(color_image, origin='lower')\nplt.axis('off')\nplt.show()",
                "true_code": "fig = plt.figure(figsize=(10,10))\nplt.imshow(color_image)\nplt.axis('off');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 70,
                "codebleu": {
                    "codebleu": 0.2742231651881154,
                    "ngram_match_score": 0.021105340631872645,
                    "weighted_ngram_match_score": 0.05372849659117709,
                    "syntax_match_score": 0.6470588235294118,
                    "dataflow_match_score": 0.375
                },
                "codebertscore": {
                    "precision": 0.9087411165237427,
                    "recall": 0.9612546563148499,
                    "F1": 0.9342605471611023,
                    "F3": 0.9557317495346069
                },
                "codebertscore_rescaled": {
                    "precision": 0.8174822330474854,
                    "recall": 0.9225093126296997,
                    "F1": 0.8685210943222046,
                    "F3": 0.9114634990692139
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.045454545454545456,
            "fuzzy_match": 35.09090909090909,
            "codebleu": 0.379827237473584,
            "syntax_match_score": 0.5624574036803751,
            "codebertscore": 0.8224806460467252,
            "codebertscore_rescaled": 0.6449612920934503,
            "code_success": 0.6818181818181818,
            "total_code_cell_count": 22
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/StarClustersGaiaDR3_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/GalacticStructure/StarClustersGaiaDR3.ipynb",
            "prefix": "gaia_3"
        },
        "model": {
            "name": "llama3.1",
            "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "library": "together"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "# Notebook metadata\n__nbid__ = \"ASTRO-001\"  # Unique identifier for the notebook\n__author__ = \"John Doe, Astronomy Team <johndoe@astronomy.org>\"  # Author's name, team, and email\n__version__ = \"20231201\"  # Version in the format 'yyyymmdd' as of the latest curated date\n__datasets__ = [\"Gaia DR3\"]  # List of relevant datasets used in the notebook\n__keywords__ = [\"star clusters\", \"stars\", \"proper motions\", \"CMD\", \"quiver\", \"animations\"]  # Keywords describing the content",
                "true_code": "__nbid__ = '0017'\n__author__ = 'Leah Fulmer, Astro Data Lab Team <datalab@noirlab.edu>'\n__version__ = '20240603' # yyyymmdd\n__datasets__ = ['gaia_dr3']\n__keywords__ = ['star clusters', 'stars', 'proper motions', 'parallax', 'plot:cmd', 'plot:quiver', 'plot:animation']",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 17,
                "codebleu": {
                    "codebleu": 0.43785643075528735,
                    "ngram_match_score": 0.013236634004481513,
                    "weighted_ngram_match_score": 0.0298557556833345,
                    "syntax_match_score": 0.8333333333333334,
                    "dataflow_match_score": 0.875
                },
                "codebertscore": {
                    "precision": 0.7431001663208008,
                    "recall": 0.811462938785553,
                    "F1": 0.7757784724235535,
                    "F3": 0.8040658235549927
                },
                "codebertscore_rescaled": {
                    "precision": 0.48620033264160156,
                    "recall": 0.622925877571106,
                    "F1": 0.5515569448471069,
                    "F3": 0.6081316471099854
                }
            },
            {
                "ind": 10,
                "gen_code": "# Authentication setup\ndef login():\n    username = input(\"Enter your Data Lab username: \")\n    password = getpass(\"Enter your Data Lab password: \")\n    ac.login(username, password)\n\n# Verify authentication\ndef whoAmI():\n    return ac.whoAmI()\n\n# Optionally authenticate if needed\n# login()\nwhoAmI()",
                "true_code": "#token = ac.login(input(\"Enter user name: (+ENTER) \"),getpass(\"Enter password: (+ENTER) \"))\nac.whoAmI()",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 12,
                "codebleu": {
                    "codebleu": 0.4078058341290764,
                    "ngram_match_score": 0.006414921514603761,
                    "weighted_ngram_match_score": 0.024808415001701823,
                    "syntax_match_score": 0.6,
                    "dataflow_match_score": 0
                },
                "codebertscore": {
                    "precision": 0.7942186594009399,
                    "recall": 0.8365216851234436,
                    "F1": 0.8148214817047119,
                    "F3": 0.8320896625518799
                },
                "codebertscore_rescaled": {
                    "precision": 0.5884373188018799,
                    "recall": 0.6730433702468872,
                    "F1": 0.6296429634094238,
                    "F3": 0.6641793251037598
                }
            },
            {
                "ind": 12,
                "gen_code": "# Define a query to fetch introductory data from the gaia_dr3 database\nquery = \"\"\"\n    SELECT \n        ra, dec, pmra, pmdec, parallax\n    FROM \n        gaiadr3.gaia_source\n    LIMIT \n        100\n\"\"\"\n\n# Execute the query using the queryClient\njob = qc.query(query)\n\n# Fetch the results\nresults = job.get_results()\n\n# Print the results\nprint(results)",
                "true_code": "# Construct query as a string\nquery = \"SELECT * FROM gaia_dr3.gaia_source LIMIT 1\"\n\n# Submit query\nresponse = qc.query(sql=query, fmt='csv')\n\n# Convert output string to to a pandas DataFrame\ndf_init = convert(response,'pandas')\n\n# To view the available columns, include the following command\ndf_init.columns",
                "error_ind": 12,
                "direct_match": false,
                "fuzzy_match": 17,
                "codebleu": {
                    "codebleu": 0.20629093569952142,
                    "ngram_match_score": 0.013605128106514501,
                    "weighted_ngram_match_score": 0.014566133488563688,
                    "syntax_match_score": 0.3684210526315789,
                    "dataflow_match_score": 0.42857142857142855
                },
                "codebertscore": {
                    "precision": 0.7868218421936035,
                    "recall": 0.7842833995819092,
                    "F1": 0.7855505347251892,
                    "F3": 0.7845365405082703
                },
                "codebertscore_rescaled": {
                    "precision": 0.573643684387207,
                    "recall": 0.5685667991638184,
                    "F1": 0.5711010694503784,
                    "F3": 0.5690730810165405
                }
            },
            {
                "ind": 14,
                "gen_code": "def query_star_cluster(cluster_name, radius):\n    # Define the center of the cluster\n    center = SkyCoord.from_name(cluster_name)\n    \n    # Construct the query string\n    query = f\"\"\"\n    SELECT \n        ra, dec, pmra, pmdec, parallax\n    FROM \n        gaia_dr3.gaia_source\n    WHERE \n        CONTAINS(\n            POINT(ra, dec),\n            CIRCLE('{center.ra.deg:.6f}', '{center.dec.deg:.6f}', {radius/3600:.6f})\n        )\n    \"\"\"\n\n    # Submit the query\n    response = qc.query(sql=query, fmt='csv')\n\n    # Convert the output string to a pandas DataFrame\n    df = convert(response, 'pandas')\n\n    return df",
                "true_code": "# Write a query that returns all of the stars surrounding a particular object out to a particular radius \n\ndef input_query(object_name, radius_deg):\n    # SkyCoord.from_name outputs the coordinates of a particular object given its name as a string\n    c = SkyCoord.from_name(object_name)\n    \n    # Construct a Cone Search query\n    query = \"\"\"SELECT * FROM gaia_dr3.gaia_source \n            WHERE (q3c_radial_query(ra, dec, {0}, {1}, %s)\n            AND NOT parallax='Nan')\"\"\".format(c.ra.value,c.dec.value) % (radius_deg)\n    \n    # Submit the query\n    response = qc.query(sql=query, fmt='csv')\n    \n    # Convert the query to a pandas DataFrame\n    df = convert(response,'pandas')\n    \n    # Check the number of objects in your query\n    print(\"The query of %s contains %s objects.\" % (object_name, len(df)))\n    \n    # Return the output DataFrame\n    return df",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 35,
                "codebleu": {
                    "codebleu": 0.33096060162180635,
                    "ngram_match_score": 0.1480137149776169,
                    "weighted_ngram_match_score": 0.18125504809875587,
                    "syntax_match_score": 0.627906976744186,
                    "dataflow_match_score": 0.36666666666666664
                },
                "codebertscore": {
                    "precision": 0.8458631634712219,
                    "recall": 0.8178411722183228,
                    "F1": 0.8316161036491394,
                    "F3": 0.8205595016479492
                },
                "codebertscore_rescaled": {
                    "precision": 0.6917263269424438,
                    "recall": 0.6356823444366455,
                    "F1": 0.6632322072982788,
                    "F3": 0.6411190032958984
                }
            },
            {
                "ind": 16,
                "gen_code": "# Select an astronomical object of interest and a radius in degrees\nobject_name = 'M13'\nradius_deg = 1.0\n\n# Execute the query function to retrieve data on surrounding stars\ndf = input_query(object_name, radius_deg)",
                "true_code": "# Pick your favorite object!\n\n# Define an object\nobject_queried = \"NGC 6281\"\n\n# Define a radius\nradius = 0.5\n\n# Submit the function that returns a queried DataFrame\ndf = input_query(object_queried, radius)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 16,
                "codebleu": {
                    "codebleu": 0.5111169614091502,
                    "ngram_match_score": 0.022233922818300375,
                    "weighted_ngram_match_score": 0.022233922818300375,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8193513751029968,
                    "recall": 0.8179020881652832,
                    "F1": 0.8186260461807251,
                    "F3": 0.8180468678474426
                },
                "codebertscore_rescaled": {
                    "precision": 0.6387027502059937,
                    "recall": 0.6358041763305664,
                    "F1": 0.6372520923614502,
                    "F3": 0.6360937356948853
                }
            },
            {
                "ind": 18,
                "gen_code": "def extract_stellar_properties(df):\n    \"\"\"\n    Extract essential stellar properties from the DataFrame.\n\n    Parameters:\n    df (pandas DataFrame): DataFrame containing the query results.\n\n    Returns:\n    ra (numpy array): Right ascension of the stars.\n    dec (numpy array): Declination of the stars.\n    pmra (numpy array): Proper motion in right ascension.\n    pmdec (numpy array): Proper motion in declination.\n    phot_g_mean_mag (numpy array): Mean G magnitude of the stars.\n    \"\"\"\n    # Extract the right ascension and declination\n    ra = df['ra'].values\n    dec = df['dec'].values\n\n    # Extract the proper motion in right ascension and declination\n    pmra = df['pmra'].values\n    pmdec = df['pmdec'].values\n\n    # Extract the mean G magnitude of the stars\n    phot_g_mean_mag = df['phot_g_mean_mag'].values\n\n    return ra, dec, pmra, pmdec, phot_g_mean_mag\n\n# Apply the function to the DataFrame\nra, dec, pmra, pmdec, phot_g_mean_mag = extract_stellar_properties(df)",
                "true_code": "# Define variables from DataFrame\n# Doing so within a function makes later re-definition very simple\ndef define_variables (df):\n    ra, dec = df[\"ra\"], df[\"dec\"]\n    ra_rad, dec_rad = np.radians(ra), np.radians(dec)\n    pmra, pmdec = df[\"pmra\"], df[\"pmdec\"]\n    parallax = df['parallax']\n    g, g_bp = df[\"phot_g_mean_mag\"], df[\"phot_g_mean_mag\"]-df[\"phot_bp_mean_mag\"]\n    return ra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp\n\n# Submit the function that defines variables from the DataFrame\nra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp = define_variables(df)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.2077962577063901,
                    "ngram_match_score": 0.04572150629006574,
                    "weighted_ngram_match_score": 0.0797305782365107,
                    "syntax_match_score": 0.40384615384615385,
                    "dataflow_match_score": 0.3018867924528302
                },
                "codebertscore": {
                    "precision": 0.7884965538978577,
                    "recall": 0.8062530755996704,
                    "F1": 0.7972759008407593,
                    "F3": 0.804441511631012
                },
                "codebertscore_rescaled": {
                    "precision": 0.5769931077957153,
                    "recall": 0.6125061511993408,
                    "F1": 0.5945518016815186,
                    "F3": 0.6088830232620239
                }
            },
            {
                "ind": 20,
                "gen_code": "# Function to create stationary visualizations\ndef create_stationary_visualizations(ra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp):\n    # Spatial plot\n    plt.figure(figsize=(10, 8))\n    plt.scatter(ra, dec, s=0.5, c=g, cmap='viridis')\n    plt.xlabel('Right Ascension (deg)')\n    plt.ylabel('Declination (deg)')\n    plt.title('Spatial Distribution of Stars')\n    plt.colorbar(label='G Magnitude')\n    plt.show()\n\n    # Quiver plot\n    plt.figure(figsize=(10, 8))\n    plt.scatter(ra, dec, s=0.5, c=g, cmap='viridis')\n    plt.quiver(ra, dec, pmra, pmdec, color='red', scale=1000)\n    plt.xlabel('Right Ascension (deg)')\n    plt.ylabel('Declination (deg)')\n    plt.title('Proper Motions of Stars')\n    plt.colorbar(label='G Magnitude')\n    plt.show()\n\n    # Color-Magnitude Diagram (CMD)\n    plt.figure(figsize=(10, 8))\n    plt.scatter(g_bp, g, s=0.5, c=g, cmap='viridis')\n    plt.xlabel('BP-RP Color')\n    plt.ylabel('G Magnitude')\n    plt.title('Color-Magnitude Diagram')\n    plt.colorbar(label='G Magnitude')\n    plt.show()\n\n# Submit the function that creates stationary visualizations\ncreate_stationary_visualizations(ra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp)",
                "true_code": "# Write a function that outputs spatial and color-magnitude plots for your sampled object\ndef panel_plot(ra, dec, pmra, pmdec, color, mag):\n    fig = plt.figure(figsize=(26,8))\n    \n    # A simple spatial plot\n    ax1 = fig.add_subplot(131)\n    ax1.scatter(ra, dec, marker='.', alpha= 1/np.power(len(df), 0.1))\n    ax1.set_title(\"Spatial Plot\",fontsize=10)\n    ax1.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax1.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A quiver plot (spatial plot with arrows that describe each object's proper motion)\n    ax2 = fig.add_subplot(132)\n    ax2.quiver(ra, dec, pmra, pmdec)\n    ax2.set_title(\"Proper Motions\",fontsize=10)\n    ax2.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax2.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A color-magnitude diagram that exhibits object density\n    ax3 = fig.add_subplot(133)\n    im3 = ax3.hexbin(g_bp, g, bins='log', cmap=plt.cm.viridis, mincnt=1)\n    ax3.set_ylim(max(g), min(g))\n    ax3.set_title(\"Color-Magnitude Diagram\",fontsize=10)\n    ax3.set_xlabel(\"Gaia G-BP Color\",fontsize=10)\n    ax3.set_ylabel(\"Gaia G Magnitude\",fontsize=10)\n    cb = plt.colorbar(im3,label='log(N)')",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 9,
                "codebleu": {
                    "codebleu": 0.24314324603138762,
                    "ngram_match_score": 0.014583797210866882,
                    "weighted_ngram_match_score": 0.015311405706491758,
                    "syntax_match_score": 0.3983739837398374,
                    "dataflow_match_score": 0.5443037974683544
                },
                "codebertscore": {
                    "precision": 0.8450628519058228,
                    "recall": 0.7999447584152222,
                    "F1": 0.8218850493431091,
                    "F3": 0.8042386770248413
                },
                "codebertscore_rescaled": {
                    "precision": 0.6901257038116455,
                    "recall": 0.5998895168304443,
                    "F1": 0.6437700986862183,
                    "F3": 0.6084773540496826
                }
            },
            {
                "ind": 22,
                "gen_code": "# Define a function to adjust magnitude and apply distance limits\ndef adjust_magnitude_and_distance(ra, dec, pmra, pmdec, parallax, g, g_bp, mag_limit, dist_limit):\n    # Apply magnitude limit\n    mag_mask = g < mag_limit\n    \n    # Apply distance limit\n    dist_mask = parallax > dist_limit\n    \n    # Combine masks\n    mask = mag_mask & dist_mask\n    \n    # Adjust magnitude array\n    g_adj = g[mask]\n    \n    # Create SkyCoord object\n    c = SkyCoord(ra=ra[mask]*u.deg, dec=dec[mask]*u.deg, \n                 pm_ra_cosdec=pmra[mask]*u.mas/u.yr, pm_dec=pmdec[mask]*u.mas/u.yr, \n                 distance=1/parallax[mask]*u.kpc)\n    \n    return g_adj, mask, c\n\n# Apply the function\nmag_limit = 18  # magnitude limit\ndist_limit = 0.1  # distance limit in kpc\ng_adj, mask, c = adjust_magnitude_and_distance(ra, dec, pmra, pmdec, parallax, g, g_bp, mag_limit, dist_limit)",
                "true_code": "# Convert variables to SkyCoord object and impose limits on output\n\ndef convert_to_skycoord (g, ra_rad, dec_rad, parallax, dist1, dist2):\n    # Define variables as as an numpy array and SkyCoord object\n    # Note: The SkyCoord object contains data for ra, dec, and parallax\n    mag = np.array(g)\n    scnow = SkyCoord(np.array(ra_rad) * u.rad, np.array(dec_rad) * u.rad, \n                 distance=(np.array(parallax)*u.mas).to(u.pc, u.parallax()))\n\n    # Create a \"mask\" with varying data thresholds (here depending on magnitude and distance)\n    msk = (mag < 16)  & (scnow.distance > dist1*u.pc) & (scnow.distance < dist2*u.pc)\n    \n    # Apply data thresholds to the given magnitude and SkyCoord objects\n    mag = mag[msk]\n    scnow = scnow[msk]\n    \n    # Print the new object count after applying data thresholds\n    print('After the thresholds are applied, this query contains %s objects.' % (len(scnow)))\n    \n    # Return the defined variables\n    return mag, msk, scnow\n    \nmag, msk, scnow = convert_to_skycoord(g, ra_rad, dec_rad, parallax, 1e2, 9e2)\n",
                "error_ind": 22,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.21269697179990024,
                    "ngram_match_score": 0.007827687301975153,
                    "weighted_ngram_match_score": 0.008349469764507624,
                    "syntax_match_score": 0.2972972972972973,
                    "dataflow_match_score": 0.5373134328358209
                },
                "codebertscore": {
                    "precision": 0.7968993186950684,
                    "recall": 0.7596871852874756,
                    "F1": 0.7778484225273132,
                    "F3": 0.7632513046264648
                },
                "codebertscore_rescaled": {
                    "precision": 0.5937986373901367,
                    "recall": 0.5193743705749512,
                    "F1": 0.5556968450546265,
                    "F3": 0.5265026092529297
                }
            },
            {
                "ind": 24,
                "gen_code": "```python\n# Modify a standard colormap to enhance visibility\ncmap = cm.get_cmap('viridis')\ncmap.set_bad(color='white')\n\n# Define a function that maps magnitude to marker size\ndef mag_to_size(mag):\n    return np.power(2.5, 16-mag)\n\n# Set visualization parameters\ncolor = mag\nsize = mag_to_size(mag)\n```\n\n<MARKDOWN>\nNow, utilize the `SkyCoord` object to create a 3D representation of the star cluster. This will involve transforming the coordinates into Cartesian form and then plotting them in a 3D space. To animate the parallax effect, you will need to create a function that updates the view angle and then use the `FuncAnimation` function from `matplotlib.animation` to create the animation.\n\nPlease proceed with implementing the 3D plotting and animation functions.\n<CELL END>\n\n```python\n# Create a 3D representation of the star cluster\nfig = plt.figure(figsize=(8,8))\nax = fig.add_subplot(111, projection='3d')\n\n# Transform the coordinates into Cartesian form\ncartesian = scnow.cartesian\n\n# Plot the stars in 3D space\nax.scatter(cartesian.x.value, cartesian.y.value, cartesian.z.value, c=color, s=size)\n\n# Set the axis limits\nax.set_xlim(-500, 500)\nax.set_ylim(-500, 500)\nax.set_zlim(-500, 500)\n\n# Define a function to update the view angle\ndef update(angle):\n    ax.view_init(azim=angle)\n\n# Create the animation\nani = animation.FuncAnimation(fig, update, frames=range(0, 362, 2), interval=100)\n\n# Display the animation\nplt.show()\n```\n\n<MARKDOWN>\nFinally, combine the stationary visualization and parallax animation into a single function that can be easily executed to display both visualizations.\n<CELL END>\n\n```python\n# Define a function to display both visualizations\ndef display_visualizations(ra, dec, pmra, pmdec, color, mag, g, g_bp):\n    # Display the stationary visualization\n    panel_plot(ra, dec, pmra, pmdec, color, mag)\n    \n    # Display the parallax animation\n    mag, msk, scnow = convert_to_skycoord(g, np.radians(ra), np.radians(dec), parallax, 1e2, 9e2)\n    color = mag\n    size =",
                "true_code": "# Make a special version of the viridis colormap that goes to a darker yellow at the end. \n# This makes it easier to see small points on a white background.\nnewvhsv = colors.rgb_to_hsv(cm.viridis.colors)\nnewvhsv[:,-1] = np.minimum(newvhsv[:,-1], .88)\ndarker_vidiris = colors.ListedColormap(colors.hsv_to_rgb(newvhsv))\n\n# Define a function to represent magnitude with marker size and distance with marker color\n# Here purple will symbolize closer objects, and yellow will symbolize those further away\ndef mag_to_size(mag):\n    unity_rescaled_mag = (np.max(mag) - mag)/np.ptp(mag)\n    return 40*unity_rescaled_mag**2+2\n\n# Save these visualization arguments as 'scatkwargs'\nscatkwargs = dict(s=mag_to_size(mag), alpha=.9, c=scnow.distance, cmap=darker_vidiris)",
                "error_ind": 24,
                "direct_match": false,
                "fuzzy_match": 3,
                "codebleu": {
                    "codebleu": 0.29052711643474793,
                    "ngram_match_score": 0.023987308002009634,
                    "weighted_ngram_match_score": 0.07264496726079149,
                    "syntax_match_score": 0.375,
                    "dataflow_match_score": 0.6904761904761905
                },
                "codebertscore": {
                    "precision": 0.6986023187637329,
                    "recall": 0.7220514416694641,
                    "F1": 0.7101333737373352,
                    "F3": 0.7196359038352966
                },
                "codebertscore_rescaled": {
                    "precision": 0.3972046375274658,
                    "recall": 0.4441028833389282,
                    "F1": 0.4202667474746704,
                    "F3": 0.43927180767059326
                }
            },
            {
                "ind": 26,
                "gen_code": "# Define an animation function to portray the parallax effect of the query results\ndef animate_parallax(scnow, mag, dist1, dist2, object_name):\n    # Create a figure and axis object\n    fig, ax = plt.subplots(figsize=(8, 8))\n\n    # Define the Earth's semimajor axis in AU\n    au = 1.496e11*u.m\n\n    # Calculate the amplitude of the parallax\n    parallax_amp = au / scnow.distance\n\n    # Transition data from Cartesian to spherical coordinates\n    scnow_sph = scnow.cartesian.to_spherical()\n\n    # Initialize the plot with the first frame\n    ax.scatter(scnow.ra.wrap_at(180*u.deg).radian, scnow.dec.radian, **scatkwargs)\n    ax.set_title(\"Parallax Animation of %s\" % object_name, fontsize=14)\n    ax.set_xlabel(\"Right Ascension\", fontsize=12)\n    ax.set_ylabel(\"Declination\", fontsize=12)\n    ax.set_xlim(min(scnow.ra.wrap_at(180*u.deg).radian), max(scnow.ra.wrap_at(180*u.deg).radian))\n    ax.set_ylim(min(scnow.dec.radian), max(scnow.dec.radian))\n\n    # Define the animation function\n    def animate(i):\n        # Calculate the new position of the stars due to parallax\n        new_ra = scnow.ra.wrap_at(180*u.deg).radian + parallax_amp * np.cos(2 * np.pi * i / 365)\n        new_dec = scnow.dec.radian + parallax_amp * np.sin(2 * np.pi * i / 365)\n\n        # Clear the previous frame and plot the new positions\n        ax.clear()\n        ax.scatter(new_ra, new_dec, **scatkwargs)\n        ax.set_title(\"Parallax Animation of %s\" % object_name, fontsize=14)\n        ax.set_xlabel(\"Right Ascension\", fontsize=12)\n        ax.set_ylabel(\"Declination\", fontsize=12)\n        ax.set_xlim(min(scnow.ra.wrap_at(180*u.deg).radian), max(scnow.ra.wrap_at(180*u.deg).radian))\n        ax.set_ylim(min(scnow.dec.radian), max(scnow.dec.radian))\n\n    # Create the animation\n    ani = animation.FuncAnimation(fig, animate, frames=365, interval=50)\n\n    # Display the animation\n    plt.show()\n\n# Call the animation",
                "true_code": "# Write a function to animate the parallax of your sample\n\n# The amplitude describes the distance that markers will move in portraying parallax.\namplitude = 0.6*u.lightyear\nrepr0 = scnow.barycentrictrueecliptic.cartesian\n\ndef animfunc(phase, eclcart_to_spherical, centerstr, ylims, ax):\n    \n    # Converting from Cartesian to spherical coordinates\n    drepr = CartesianRepresentation([np.cos(phase),np.sin(phase),0]*amplitude)\n    rep = repr0 + drepr\n    srep = eclcart_to_spherical(rep)\n    \n    # Creating and defining plot aesthetics\n    ax.cla()\n    ax.set_title(f'Center={centerstr}, Earth Semimajor Axis={amplitude} \\n')\n    # ax.scatter(srep.lon.rad, 90-srep.lat.deg, **scatkwargs)\n    ax.scatter(80.2+srep.lon.rad, 90-srep.lat.deg, **scatkwargs)\n    ax.set_ylim(*ylims)\n    ax.set_yticks(np.linspace(*ax.get_ylim(), 5)[1:])\n    ax.set_yticklabels(['{}'.format(int(90-yl)) for yl in ax.get_yticks()])\n    ax.grid(alpha=0.5)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.23737086140965535,
                    "ngram_match_score": 0.031071880826440666,
                    "weighted_ngram_match_score": 0.07432554330680441,
                    "syntax_match_score": 0.34408602150537637,
                    "dataflow_match_score": 0.5
                },
                "codebertscore": {
                    "precision": 0.7615382671356201,
                    "recall": 0.7695255279541016,
                    "F1": 0.7655110955238342,
                    "F3": 0.7687192559242249
                },
                "codebertscore_rescaled": {
                    "precision": 0.5230765342712402,
                    "recall": 0.5390510559082031,
                    "F1": 0.5310221910476685,
                    "F3": 0.5374385118484497
                }
            },
            {
                "ind": 28,
                "gen_code": "# Define a function to transform coordinates for centering the animation\n\ndef center_coordinates(scnow, object_name):\n    # Calculate the coordinates of the object of interest\n    c = SkyCoord.from_name(object_name)\n    \n    # Calculate the difference between the object's coordinates and the coordinates of the stars\n    delta_ra = scnow.ra - c.ra\n    delta_dec = scnow.dec - c.dec\n    \n    # Convert the differences to radians\n    delta_ra_rad = delta_ra.to(u.rad).value\n    delta_dec_rad = delta_dec.to(u.rad).value\n    \n    # Return the transformed coordinates\n    return delta_ra_rad, delta_dec_rad\n\n# Apply the coordinate transformation\ndelta_ra_rad, delta_dec_rad = center_coordinates(scnow, object_queried)\n\n# Update the animation function with the transformed coordinates\ndef animfunc(phase, eclcart_to_spherical, centerstr, ylims, ax):\n    \n    # Converting from Cartesian to spherical coordinates\n    drepr = CartesianRepresentation([np.cos(phase),np.sin(phase),0]*amplitude)\n    rep = repr0 + drepr\n    srep = eclcart_to_spherical(rep)\n    \n    # Creating and defining plot aesthetics\n    ax.cla()\n    ax.set_title(f'Center={centerstr}, Earth Semimajor Axis={amplitude} \\n')\n    ax.scatter(delta_ra_rad + srep.lon.rad, 90-srep.lat.deg, **scatkwargs)\n    ax.set_ylim(*ylims)\n    ax.set_yticks(np.linspace(*ax.get_ylim(), 5)[1:])\n    ax.set_yticklabels(['{}'.format(int(90-yl)) for yl in ax.get_yticks()])\n    ax.grid(alpha=0.5)\n\n# Create the animation\nfig, ax = plt.subplots()\neclcart_to_spherical = matrix_utilities.rotation_matrix(-23.439291*u.deg, 'z')\ncenterstr = object_queried\nylims = (25, 55)\nani = animation.FuncAnimation(fig, animfunc, frames=np.linspace(0, 2*np.pi, 128),\n                              fargs=(eclcart_to_spherical, centerstr, ylims, ax),\n                              interval=100)\n\n# Display the animation\nplt.show()",
                "true_code": "# Centering the visualization on a given object\ndef eclcart_to_spherical3(rep):\n    icrsrep = SkyCoord(scnow.barycentrictrueecliptic.realize_frame(rep)).icrs.cartesian   \n    rot1 = matrix_utilities.rotation_matrix(object_name.ra, 'z')\n    rot2 = matrix_utilities.rotation_matrix(90*u.deg-object_name.dec, 'y')\n    return icrsrep.transform(rot2 @ rot1).represent_as(SphericalRepresentation)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 6,
                "codebleu": {
                    "codebleu": 0.27902392293239514,
                    "ngram_match_score": 0.0018226762651812325,
                    "weighted_ngram_match_score": 0.014557915749299686,
                    "syntax_match_score": 0.358974358974359,
                    "dataflow_match_score": 0.7407407407407407
                },
                "codebertscore": {
                    "precision": 0.6670703887939453,
                    "recall": 0.7725093960762024,
                    "F1": 0.7159286141395569,
                    "F3": 0.7604888677597046
                },
                "codebertscore_rescaled": {
                    "precision": 0.3341407775878906,
                    "recall": 0.5450187921524048,
                    "F1": 0.43185722827911377,
                    "F3": 0.5209777355194092
                }
            },
            {
                "ind": 30,
                "gen_code": "# Execute the function to generate the stationary plot\npanel_plot(ra, dec, pmra, pmdec, g_bp, g)",
                "true_code": "# Call stationary plot\npanel_plot(scnow.ra, scnow.dec, pmra[msk], pmdec[msk], g_bp[msk], g[msk])",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 64,
                "codebleu": {
                    "codebleu": 0.27008210391636683,
                    "ngram_match_score": 0.030934588294313718,
                    "weighted_ngram_match_score": 0.04939382737115371,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.883120059967041,
                    "recall": 0.827448844909668,
                    "F1": 0.8543785214424133,
                    "F3": 0.8326981067657471
                },
                "codebertscore_rescaled": {
                    "precision": 0.766240119934082,
                    "recall": 0.6548976898193359,
                    "F1": 0.7087570428848267,
                    "F3": 0.6653962135314941
                }
            },
            {
                "ind": 32,
                "gen_code": "# Animation setup\nfig, ax = plt.subplots(figsize=(8,8))\neclcart_to_spherical = eclcart_to_spherical3\n\n# Define the animation parameters\ncenter = SkyCoord.from_name(object_queried)\ncenterstr = object_queried\nphase = np.linspace(0, 2*np.pi, 128, endpoint=False)\nylims = (0, 200)\nani = animation.FuncAnimation(fig, animfunc, frames=phase, fargs=(eclcart_to_spherical, centerstr, ylims, ax), blit=False, interval=100)\n\n# Save the animation to a file\nani.save('parallax_animation.mp4')\n\n# Display the animation\nplt.show()",
                "true_code": "# Call parallax animation\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(projection='polar')\nobject_name = SkyCoord.from_name(object_queried)\ncenterstr3 = object_queried\nylims3 = (0, radius)\n\nanim3 = animation.FuncAnimation(fig, animfunc, np.linspace(0, 2*np.pi, 30),\n                                fargs=(eclcart_to_spherical3, centerstr3, ylims3, ax), \n                                interval=50)\n\nplt.close(fig)\nHTML(anim3.to_html5_video())",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 30,
                "codebleu": {
                    "codebleu": 0.2822219062020289,
                    "ngram_match_score": 0.034723846259808566,
                    "weighted_ngram_match_score": 0.055473302357830816,
                    "syntax_match_score": 0.5625,
                    "dataflow_match_score": 0.47619047619047616
                },
                "codebertscore": {
                    "precision": 0.8633157014846802,
                    "recall": 0.8967188596725464,
                    "F1": 0.8797003030776978,
                    "F3": 0.8932626843452454
                },
                "codebertscore_rescaled": {
                    "precision": 0.7266314029693604,
                    "recall": 0.7934377193450928,
                    "F1": 0.7594006061553955,
                    "F3": 0.7865253686904907
                }
            },
            {
                "ind": 34,
                "gen_code": "# Pick your second-favorite object!\nobject_queried = \"M 13\"\nradius = 0.5\n\n# Submit the function that returns a queried DataFrame\ndf = input_query(object_queried, radius)\n\n# Define variables from DataFrame\nra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp = define_variables(df)\n\n# Call stationary plot\npanel_plot(ra, dec, pmra, pmdec, g_bp, g)\n\n# Convert variables to SkyCoord object and impose limits on output\nmag, msk, scnow = convert_to_skycoord(g, ra_rad, dec_rad, parallax, 1e2, 9e2)\n\n# Call parallax animation\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(projection='polar')\nobject_name = SkyCoord.from_name(object_queried)\ncenterstr3 = object_queried\nylims3 = (0, radius)\n\nanim3 = animation.FuncAnimation(fig, animfunc, np.linspace(0, 2*np.pi, 30),\n                                fargs=(eclcart_to_spherical3, centerstr3, ylims3, ax), \n                                interval=50)\n\nplt.close(fig)\nHTML(anim3.to_html5_video())",
                "true_code": "# Pick your second-favorite object!\n\n# Define object and radius\nobject_queried = \"NGC 6397\"\nradius = 0.1\n\n# Submit query\ndf = input_query(object_queried, radius)",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.5789859250834715,
                    "ngram_match_score": 0.07249005949367622,
                    "weighted_ngram_match_score": 0.34345364084020974,
                    "syntax_match_score": 0.9,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.606403112411499,
                    "recall": 0.8728914856910706,
                    "F1": 0.7156440019607544,
                    "F3": 0.836146354675293
                },
                "codebertscore_rescaled": {
                    "precision": 0.21280622482299805,
                    "recall": 0.7457829713821411,
                    "F1": 0.4312880039215088,
                    "F3": 0.6722927093505859
                }
            },
            {
                "ind": 36,
                "gen_code": "# Define variables from DataFrame\n# Doing so within a function makes later re-definition very simple\ndef define_variables (df):\n    ra, dec = df[\"ra\"], df[\"dec\"]\n    ra_rad, dec_rad = np.radians(ra), np.radians(dec)\n    pmra, pmdec = df[\"pmra\"], df[\"pmdec\"]\n    parallax = df['parallax']\n    g, g_bp = df[\"phot_g_mean_mag\"], df[\"phot_g_mean_mag\"]-df[\"phot_bp_mean_mag\"]\n    return ra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp\n\n# Submit the function that defines variables from the DataFrame\nra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp = define_variables(df)\n\n# Write a function that outputs spatial and color-magnitude plots for your sampled object\ndef panel_plot(ra, dec, pmra, pmdec, color, mag):\n    fig = plt.figure(figsize=(26,8))\n    \n    # A simple spatial plot\n    ax1 = fig.add_subplot(131)\n    ax1.scatter(ra, dec, marker='.', alpha= 1/np.power(len(df), 0.1))\n    ax1.set_title(\"Spatial Plot\",fontsize=10)\n    ax1.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax1.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A quiver plot (spatial plot with arrows that describe each object's proper motion)\n    ax2 = fig.add_subplot(132)\n    ax2.quiver(ra, dec, pmra, pmdec)\n    ax2.set_title(\"Proper Motions\",fontsize=10)\n    ax2.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax2.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A color-magnitude diagram that exhibits object density\n    ax3 = fig.add_subplot(133)\n    im3 = ax3.hexbin(g_bp, g, bins='log', cmap=plt.cm.viridis, mincnt=1)\n    ax3.set_ylim(max(g), min(g))\n    ax3.set_title(\"Color-Magnitude Diagram\",fontsize=10)\n    ax3.set_xlabel(\"Gaia G-BP Color\",fontsize=10)\n    ax3.set_ylabel(\"Gaia G Magnitude\",fontsize=10)\n    cb = plt.colorbar(im3,label='",
                "true_code": "# Define variables\nra, dec, ra_rad, dec_rad, pmra, pmdec, parallax, g, g_bp = define_variables(df)\n\n# Apply thresholds\nmag, msk, scnow = convert_to_skycoord(g, ra_rad, dec_rad, parallax, 1e3, 3e3)\n\n# Define visualization parameters\nscatkwargs = dict(s=mag_to_size(mag), alpha=.9, c=scnow.distance, cmap=darker_vidiris)\namplitude = 0.6*u.lightyear\nrepr0 = scnow.barycentrictrueecliptic.cartesian",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.3136199430225911,
                    "ngram_match_score": 0.07791442520666826,
                    "weighted_ngram_match_score": 0.3220938021682491,
                    "syntax_match_score": 0.36666666666666664,
                    "dataflow_match_score": 0.4878048780487805
                },
                "codebertscore": {
                    "precision": 0.6546875238418579,
                    "recall": 0.7386722564697266,
                    "F1": 0.6941487789154053,
                    "F3": 0.7293163537979126
                },
                "codebertscore_rescaled": {
                    "precision": 0.3093750476837158,
                    "recall": 0.4773445129394531,
                    "F1": 0.38829755783081055,
                    "F3": 0.4586327075958252
                }
            },
            {
                "ind": 38,
                "gen_code": "# Call stationary plot\npanel_plot(scnow.ra, scnow.dec, pmra[msk], pmdec[msk], g_bp[msk], g[msk])\n\nPlease note that the `msk` variable is not defined in the given code snippet. It is assumed that it is defined elsewhere in the code and is used to mask the data. If not, you need to define it before using it.\n\nAlso, the `panel_plot` function is not defined in the given code snippet. It is assumed that it is defined elsewhere in the code. If not, you need to define it before using it.\n\nHere is the complete code for the `panel_plot` function:\n\n# Write a function that outputs spatial and color-magnitude plots for your sampled object\ndef panel_plot(ra, dec, pmra, pmdec, color, mag):\n    fig = plt.figure(figsize=(26,8))\n    \n    # A simple spatial plot\n    ax1 = fig.add_subplot(131)\n    ax1.scatter(ra, dec, marker='.', alpha= 1/np.power(len(df), 0.1))\n    ax1.set_title(\"Spatial Plot\",fontsize=10)\n    ax1.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax1.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A quiver plot (spatial plot with arrows that describe each object's proper motion)\n    ax2 = fig.add_subplot(132)\n    ax2.quiver(ra, dec, pmra, pmdec)\n    ax2.set_title(\"Proper Motions\",fontsize=10)\n    ax2.set_xlabel(\"Right Ascension\",fontsize=10)\n    ax2.set_ylabel(\"Declination\",fontsize=10)\n    \n    # A color-magnitude diagram that exhibits object density\n    ax3 = fig.add_subplot(133)\n    im3 = ax3.hexbin(color, mag, bins='log', cmap=plt.cm.viridis, mincnt=1)\n    ax3.set_ylim(max(mag), min(mag))\n    ax3.set_title(\"Color-Magnitude Diagram\",fontsize=10)\n    ax3.set_xlabel(\"Gaia G-BP Color\",fontsize=10)\n    ax3.set_ylabel(\"Gaia G Magnitude\",fontsize=10)\n    cb = plt.colorbar(im3,label='log(N)')\n\nAnd here is the complete code for the `convert_to_skycoord` function:\n\n",
                "true_code": "# Call stationary plot\npanel_plot(scnow.ra, scnow.dec, pmra[msk], pmdec[msk], g_bp[msk], g[msk])",
                "error_ind": 32,
                "direct_match": false,
                "fuzzy_match": 10,
                "codebleu": {
                    "codebleu": 0.6937356299837877,
                    "ngram_match_score": 0.04160918660181708,
                    "weighted_ngram_match_score": 1.0,
                    "syntax_match_score": 0.9,
                    "dataflow_match_score": 0.8333333333333334
                },
                "codebertscore": {
                    "precision": 0.566776692867279,
                    "recall": 0.9173825979232788,
                    "F1": 0.7006674408912659,
                    "F3": 0.863939642906189
                },
                "codebertscore_rescaled": {
                    "precision": 0.1335533857345581,
                    "recall": 0.8347651958465576,
                    "F1": 0.40133488178253174,
                    "F3": 0.7278792858123779
                }
            },
            {
                "ind": 40,
                "gen_code": "# Call parallax animation\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(projection='polar')\nobject_name = SkyCoord.from_name(object_queried)\ncenterstr3 = object_queried\nylims3 = (0, radius)\n\nanim3 = animation.FuncAnimation(fig, animfunc, np.linspace(0, 2*np.pi, 30),\n                                fargs=(eclcart_to_spherical3, centerstr3, ylims3, ax), \n                                interval=50)\n\nplt.close(fig)\nHTML(anim3.to_html5_video())",
                "true_code": "# Call parallax animation\nfig = plt.figure(figsize=(8, 8))\nax = plt.subplot(projection='polar')\nobject_name = SkyCoord.from_name(object_queried)\ncenterstr3 = object_queried\nylims3 = (0, radius)\n\nanim3 = animation.FuncAnimation(fig, animfunc, np.linspace(0, 2*np.pi, 30),\n                                fargs=(eclcart_to_spherical3, centerstr3, ylims3, ax), \n                                interval=50)\n\nplt.close(fig)\nHTML(anim3.to_html5_video())",
                "error_ind": 32,
                "direct_match": true,
                "fuzzy_match": 100,
                "codebleu": {
                    "codebleu": 1.0,
                    "ngram_match_score": 1.0,
                    "weighted_ngram_match_score": 1.0,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 1.0000001192092896,
                    "recall": 1.0000001192092896,
                    "F1": 1.0000001192092896,
                    "F3": 1.0000001192092896
                },
                "codebertscore_rescaled": {
                    "precision": 1.000000238418579,
                    "recall": 1.000000238418579,
                    "F1": 1.000000238418579,
                    "F3": 1.000000238418579
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.058823529411764705,
            "fuzzy_match": 20.58823529411765,
            "codebleu": 0.3825432145963273,
            "syntax_match_score": 0.5492003438081641,
            "codebertscore": 0.7917361329583561,
            "codebertscore_rescaled": 0.5834722659167122,
            "code_success": 0.5294117647058824,
            "total_code_cell_count": 17
        }
    },
    {
        "notebook": {
            "assignment": "orig_5_colloquial/DwarfGalaxiesInDelveDr2_assignment_colloquial.ipynb",
            "reference": "/Users/saj2765/Desktop/astro/rare-packages-code-gen/notebook_analysis/notebooks-latest/03_ScienceExamples/DwarfGalaxies/DwarfGalaxiesInDelveDr2.ipynb",
            "prefix": "dwarfgalaxies_4"
        },
        "model": {
            "name": "llama3.1",
            "model": "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            "library": "together"
        },
        "result": [
            {
                "ind": 1,
                "gen_code": "# Define global variables for metadata\nNOTEBOOK_ID = \"DELVE_DR2_Exploration\"\nAUTHOR = \"Your Name\"\nVERSION = \"1.0\"\nDATASETS = [\"DELVE DR2 Survey\"]\nKEYWORDS = [\"dwarf galaxies\", \"astronomy\", \"galaxy evolution\", \"DELVE DR2\"]\n\n# Print metadata for reference\nprint(\"Notebook Metadata:\")\nprint(f\"  Notebook ID: {NOTEBOOK_ID}\")\nprint(f\"  Author: {AUTHOR}\")\nprint(f\"  Version: {VERSION}\")\nprint(f\"  Datasets: {', '.join(DATASETS)}\")\nprint(f\"  Keywords: {', '.join(KEYWORDS)}\")",
                "true_code": "__nbid__ = '0007'\n__author__ = 'Jonah Medoff <jmedoff@uchicago.edu>, Alice Jacques <alice.jacques@noirlab.edu>'\n__version__ = '20240620' # yyyymmdd\n__datasets__ = ['delve_dr2']\n__keywords__ = ['science example', 'dwarf galaxies'] ",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 6,
                "codebleu": {
                    "codebleu": 0.4289061384483702,
                    "ngram_match_score": 0.005203300368769517,
                    "weighted_ngram_match_score": 0.011856660123276007,
                    "syntax_match_score": 0.7894736842105263,
                    "dataflow_match_score": 0.9090909090909091
                },
                "codebertscore": {
                    "precision": 0.6856727600097656,
                    "recall": 0.6942939758300781,
                    "F1": 0.6899564266204834,
                    "F3": 0.6934221386909485
                },
                "codebertscore_rescaled": {
                    "precision": 0.37134552001953125,
                    "recall": 0.38858795166015625,
                    "F1": 0.3799128532409668,
                    "F3": 0.386844277381897
                }
            },
            {
                "ind": 10,
                "gen_code": "# Define the query parameters\nra_center = 189.58\ndec_center = -40.89\nradius = 1.0  # degrees\ng_min, g_max = 15, 24\nr_min, r_max = 15, 24\ni_min, i_max = 15, 24\ncolor_index_min, color_index_max = -1, 1\n\n# Construct the SQL query string\nquery = f\"\"\"\nSELECT ra, dec, g, r, i\nFROM delve_dr2\nWHERE q3c_radial_query(ra, dec, {ra_center}, {dec_center}, {radius})\n  AND g BETWEEN {g_min} AND {g_max}\n  AND r BETWEEN {r_min} AND {r_max}\n  AND i BETWEEN {i_min} AND {i_max}\n  AND (g - r) BETWEEN {color_index_min} AND {color_index_max}\n  AND (r - i) BETWEEN {color_index_min} AND {color_index_max}\n\"\"\"\n\n# Execute the query using the Data Lab query client\nresponse = qc.query(query)\n\n# Extract the data from the response\ndata = response.data\n\n# Convert the data to a NumPy array\ndata_array = np.array(data)",
                "true_code": "ra = 189.58\ndec = -40.89\n\n# Create the query string; SQL keyword capitalized for clarity\n\nquery =\\\n\"\"\"SELECT ra,dec,mag_auto_g,mag_auto_r,mag_auto_i\n   FROM delve_dr2.objects\n   WHERE q3c_radial_query(ra, dec, 189.58, -40.89, 0.5) AND\n         mag_auto_g BETWEEN 14 AND 25 AND\n         (mag_auto_g - mag_auto_r) BETWEEN -0.4 AND 0.4\"\"\".format(ra, dec)",
                "error_ind": 10,
                "direct_match": false,
                "fuzzy_match": 22,
                "codebleu": {
                    "codebleu": 0.28388163462886906,
                    "ngram_match_score": 0.014058093834917795,
                    "weighted_ngram_match_score": 0.041922990135103894,
                    "syntax_match_score": 0.45454545454545453,
                    "dataflow_match_score": 0.625
                },
                "codebertscore": {
                    "precision": 0.7594667673110962,
                    "recall": 0.817318320274353,
                    "F1": 0.7873312830924988,
                    "F3": 0.8111395239830017
                },
                "codebertscore_rescaled": {
                    "precision": 0.5189335346221924,
                    "recall": 0.634636640548706,
                    "F1": 0.5746625661849976,
                    "F3": 0.6222790479660034
                }
            },
            {
                "ind": 12,
                "gen_code": "# Execute the query synchronously and fetch the data into a pandas DataFrame\njob = qc.query(query)\ndata = job.get_results()",
                "true_code": "%time\nR = qc.query(sql=query,fmt='pandas') # R is a pandas DataFrame",
                "error_ind": 12,
                "direct_match": false,
                "fuzzy_match": 39,
                "codebleu": {
                    "codebleu": 0.20717664869274907,
                    "ngram_match_score": 0.057259987315337754,
                    "weighted_ngram_match_score": 0.10910894511799621,
                    "syntax_match_score": 0.09090909090909091,
                    "dataflow_match_score": 0.5714285714285714
                },
                "codebertscore": {
                    "precision": 0.8087319135665894,
                    "recall": 0.8508965969085693,
                    "F1": 0.8292786478996277,
                    "F3": 0.8464832901954651
                },
                "codebertscore_rescaled": {
                    "precision": 0.6174638271331787,
                    "recall": 0.7017931938171387,
                    "F1": 0.6585572957992554,
                    "F3": 0.6929665803909302
                }
            },
            {
                "ind": 14,
                "gen_code": "# Verify the number of objects returned and inspect the first few entries\nprint(\"Number of objects returned:\", len(R))\nprint(\"First few rows of data:\")\nprint(R.head())",
                "true_code": "print(\"Number of objects:\", R.shape[0])\nprint(R.head())",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 43,
                "codebleu": {
                    "codebleu": 0.4399119263479262,
                    "ngram_match_score": 0.01851974703879588,
                    "weighted_ngram_match_score": 0.12574334296829354,
                    "syntax_match_score": 0.6153846153846154,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.8002855777740479,
                    "recall": 0.8793907761573792,
                    "F1": 0.8379755020141602,
                    "F3": 0.8707833886146545
                },
                "codebertscore_rescaled": {
                    "precision": 0.6005711555480957,
                    "recall": 0.7587815523147583,
                    "F1": 0.6759510040283203,
                    "F3": 0.7415667772293091
                }
            },
            {
                "ind": 16,
                "gen_code": "# Spatial density plot\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Define the grid size\ngrid_size = 0.01\n\n# Create a 2D histogram of RA and Dec\nH, xedges, yedges = np.histogram2d(R['ra'], R['dec'], bins=(np.arange(189.38, 189.78, grid_size), np.arange(-41.39, -40.39, grid_size)))\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Use pcolormesh to create a density plot\nim = ax.pcolormesh(xedges, yedges, H.T, cmap='Blues')\n\n# Set the title and labels\nax.set_title('Spatial Density of Blue Stars')\nax.set_xlabel('RA')\nax.set_ylabel('Dec')\n\n# Add a colorbar\nfig.colorbar(im, ax=ax)\n\n# Show the plot\nplt.show()",
                "true_code": "fig = plt.figure(figsize=(7,6))\nplt.hexbin(R['ra'], R['dec'],gridsize=200)\nplt.xlabel('RA')\nplt.ylabel('Dec')\nplt.colorbar(label='number of objects per spatial bin');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 14,
                "codebleu": {
                    "codebleu": 0.32529240525391073,
                    "ngram_match_score": 0.0023897302920903593,
                    "weighted_ngram_match_score": 0.018476860420522198,
                    "syntax_match_score": 0.696969696969697,
                    "dataflow_match_score": 0.5833333333333334
                },
                "codebertscore": {
                    "precision": 0.6685904264450073,
                    "recall": 0.7930835485458374,
                    "F1": 0.7255353331565857,
                    "F3": 0.7785860896110535
                },
                "codebertscore_rescaled": {
                    "precision": 0.33718085289001465,
                    "recall": 0.5861670970916748,
                    "F1": 0.4510706663131714,
                    "F3": 0.5571721792221069
                }
            },
            {
                "ind": 18,
                "gen_code": "def detect_overdensities(ra, dec, sigma_small=0.01, sigma_large=0.05, threshold=0.1):\n    # Create a 2D histogram of the spatial distribution\n    H, xedges, yedges = np.histogram2d(ra, dec, bins=200)\n\n    # Convolve the histogram with a small Gaussian kernel\n    kernel_small = convolution.Gaussian2DKernel(sigma_small)\n    convolved_small = convolution.convolve(H, kernel_small)\n\n    # Convolve the histogram with a large Gaussian kernel\n    kernel_large = convolution.Gaussian2DKernel(sigma_large)\n    convolved_large = convolution.convolve(H, kernel_large)\n\n    # Subtract the large kernel from the small kernel\n    diff = convolved_small - convolved_large\n\n    # Clip the result to remove negative values\n    clipped = np.clip(diff, 0, None)\n\n    # Normalize the result\n    normalized = clipped / np.max(clipped)\n\n    # Apply a threshold to the normalized result\n    thresholded = np.where(normalized > threshold, normalized, 0)\n\n    return thresholded\n\n# Apply the function to the data\noverdensity_map = detect_overdensities(R['ra'], R['dec'])\n\n# Visualize the overdensity map\nplt.imshow(overdensity_map, cmap='hot', origin='lower')\nplt.colorbar(label='Overdensity')\nplt.show()",
                "true_code": "def dwarf_filter (ra,dec,fwhm_small=2.0,fwhm_big=20):\n\n    \"\"\"Differential convolution with 2D Gaussian kernels.\n    \n       Based on Koposov et al. (2008).\n       Code by Ken Mighell and Mike Fitzpatrick.\n       Minor edits by RN.\n       \n       Parameters\n       ----------\n       ra, dec : float or array\n           RA & Dec in degrees.\n    \n       fwhm_small, fwhm_big : float\n           Full-width half maximum sizes of the small and big Gaussian kernels\n           to use in convolution, in arcminutes.\n    \"\"\"\n    \n    x, y = ra, dec\n\n    print(\"Computing differential convolution .... \",)\n\n    # Information about declination (y) [degrees]\n    ymean = (y.min() + y.max()) / 2.0\n    ydiff_arcmin = (y.max() - y.min()) * 60.0 # convert from degrees to arcmin\n\n    # Information about right ascension (x) [degrees in time]:\n    xdiff = x.max() - x.min() # angular separation [degrees (time)] \n    xmean = (x.min() + x.max()) / 2.0\n\n    # convert from degrees in time to separation in angular degrees:\n    xdiff_angular = (x.max() - x.min()) * np.cos(ymean*(np.pi/180.0))\n\n    # convert from degress to arcmin\n    xdiff_angular_arcmin = xdiff_angular * 60.0 \n\n    # Get the number of one-arcmin pixels in the X and Y directions:\n    nx = np.rint(xdiff_angular_arcmin).astype('int')\n    ny = np.rint(ydiff_arcmin).astype('int')\n\n    # Create a two-dimensional histogram of the raw counts:\n    Counts, xedges, yedges  = np.histogram2d (x, y, (nx,ny) )\n    extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n    raw_hist = np.rot90(Counts).copy() # hack around Pythonic weirdness\n\n    # Make the small and big Gaussian kernels with a standard deviation\n    # of the given FWHM in arcmin^2 pixels.\n    kernel_small = convolution.Gaussian2DKernel(fwhm_small/2.35,factor=1)\n    kernel_big = convolution.Gaussian2DKernel(fwhm_big/2.35,factor=1)\n\n    # Compute the differential convolution kernels.\n    conv_big = convolution.convolve(raw_hist, kernel_big)\n    conv_small = convolution.convolve(raw_hist, kernel_small)\n    conv_delta = conv_small - conv_big\n    delta = conv_delta.copy()\n\n    # Compute statistics and the floor\n    mean = np.mean(delta, dtype='float64')\n    sigma = np.std(delta, dtype='float64')\n    sigmaRaw = np.std(raw_hist,dtype='float64')\n    median = np.median(delta) # not used\n    floor = mean\n\n    print('dwarf_filter: mean = {:g}  sigma = {:g} sigmaRaw = {:g}'.format(mean, sigma, sigmaRaw))\n\n    clipped = delta.copy()\n    clipped[delta < floor] = floor\n\n    # Return the computed fields.\n    return raw_hist, extent, delta, clipped, sigma",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 6,
                "codebleu": {
                    "codebleu": 0.16736022684449883,
                    "ngram_match_score": 0.006879376899283419,
                    "weighted_ngram_match_score": 0.011786838199092842,
                    "syntax_match_score": 0.4416243654822335,
                    "dataflow_match_score": 0.20915032679738563
                },
                "codebertscore": {
                    "precision": 0.7787967324256897,
                    "recall": 0.7149304747581482,
                    "F1": 0.7454982399940491,
                    "F3": 0.7208418250083923
                },
                "codebertscore_rescaled": {
                    "precision": 0.5575934648513794,
                    "recall": 0.4298609495162964,
                    "F1": 0.49099647998809814,
                    "F3": 0.44168365001678467
                }
            },
            {
                "ind": 20,
                "gen_code": "# Run the dwarf filter\nraw_hist, extent, delta, clipped, dsigma = dwarf_filter(R['ra'], R['dec'], fwhm_small=2.0, fwhm_big=20)",
                "true_code": "%time\nsmall_k, big_k = 2., 20.  # kernel sizes in arcminutes\nraw, extent, delta, clipped, dsigma = dwarf_filter(R['ra'],R['dec'],fwhm_small=small_k,fwhm_big=big_k)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 66,
                "codebleu": {
                    "codebleu": 0.2694031072284493,
                    "ngram_match_score": 0.21081220624616526,
                    "weighted_ngram_match_score": 0.20013355600096513,
                    "syntax_match_score": 0.2777777777777778,
                    "dataflow_match_score": 0.3888888888888889
                },
                "codebertscore": {
                    "precision": 0.9041139483451843,
                    "recall": 0.8662968277931213,
                    "F1": 0.88480144739151,
                    "F3": 0.8699355721473694
                },
                "codebertscore_rescaled": {
                    "precision": 0.8082278966903687,
                    "recall": 0.7325936555862427,
                    "F1": 0.76960289478302,
                    "F3": 0.7398711442947388
                }
            },
            {
                "ind": 22,
                "gen_code": "plt.figure(figsize=(7,6))\nplt.imshow(clipped, extent=extent, cmap='inferno', origin='lower')\nplt.colorbar(label='Spatial density')\nplt.xlabel('RA')\nplt.ylabel('Dec')\nplt.title('Convolved 2D histogram of stars')\nplt.show()",
                "true_code": "fig, ax = plt.subplots(figsize=(7,6))\nim = plt.imshow(clipped)\nplt.xlabel('pixel')\nplt.ylabel('pixel')\nplt.colorbar(label='relative spatial density after convolution');",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.29047619047619044,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.7333333333333333,
                    "dataflow_match_score": 0.42857142857142855
                },
                "codebertscore": {
                    "precision": 0.8526930809020996,
                    "recall": 0.8907183408737183,
                    "F1": 0.8712910413742065,
                    "F3": 0.8867639303207397
                },
                "codebertscore_rescaled": {
                    "precision": 0.7053861618041992,
                    "recall": 0.7814366817474365,
                    "F1": 0.7425820827484131,
                    "F3": 0.7735278606414795
                }
            },
            {
                "ind": 25,
                "gen_code": "# Calculate statistics for the clipped data\nmean, median, std = stats.sigma_clipped_stats(clipped, sigma=3.0)\n\n# Define the threshold and box size for peak detection\nthreshold = 3.0 * std\nbox_size = 2 * int(small_k / 60.0)  # convert arcminutes to pixels\n\n# Detect peaks in the clipped data\npeaks = find_peaks(clipped, threshold, box_size=box_size)\n\n# Convert peak positions from pixels to celestial coordinates\npeaks_table = []\nfor peak in peaks:\n    ra_peak = extent[0] + peak[1] * (extent[1] - extent[0]) / clipped.shape[1]\n    dec_peak = extent[2] + peak[0] * (extent[3] - extent[2]) / clipped.shape[0]\n    peaks_table.append([ra_peak, dec_peak])\n\n# Print the detected peaks\nprint(\"Detected peaks:\")\nfor peak in peaks_table:\n    print(f\"RA: {peak[0]}, Dec: {peak[1]}\")",
                "true_code": "# find peaks\nmean, median, std = stats.sigma_clipped_stats(clipped,sigma=3.0,maxiters=5)\nprint(mean, median, std)\ntbl = find_peaks(clipped,median+3,box_size=small_k*2)\n\n# add ra & dec positions of peaks found\na, b = extent[:2]\nxvec = np.arange(a,b,(b-a)/clipped.shape[1])\na, b = extent[2:]\nyvec = np.arange(a,b,(b-a)/clipped.shape[0])\n\ntbl['ra'] = xvec[tbl['x_peak']]\ntbl['dec'] = yvec[-tbl['y_peak']-1]\nprint(tbl)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 13,
                "codebleu": {
                    "codebleu": 0.18036046383717208,
                    "ngram_match_score": 0.029196618626207156,
                    "weighted_ngram_match_score": 0.07249733756281734,
                    "syntax_match_score": 0.19117647058823528,
                    "dataflow_match_score": 0.42857142857142855
                },
                "codebertscore": {
                    "precision": 0.7979394793510437,
                    "recall": 0.7994230389595032,
                    "F1": 0.7986806035041809,
                    "F3": 0.7992744445800781
                },
                "codebertscore_rescaled": {
                    "precision": 0.5958789587020874,
                    "recall": 0.5988460779190063,
                    "F1": 0.5973612070083618,
                    "F3": 0.5985488891601562
                }
            },
            {
                "ind": 27,
                "gen_code": "# Show the identified density peaks\nfig, ax = plt.subplots(figsize=(7,6))\nim = plt.imshow(clipped)\nplt.xlabel('pixel')\nplt.ylabel('pixel')\nplt.colorbar(label='relative spatial density after convolution')\nplt.scatter(tbl['x_peak'],tbl['y_peak'],s=tbl['peak_value']*10,marker='x',color='red',alpha=0.5)\nplt.show()",
                "true_code": "ecs = ['w'] # color of box frame\nax.scatter(tbl['x_peak'],tbl['y_peak'],marker='s',s=tbl['peak_value']*50,c='none',edgecolors=ecs,lw=3) # keeps writing to previous ax\nfig  # repeats (the updated) figure",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 25,
                "codebleu": {
                    "codebleu": 0.1933637346816628,
                    "ngram_match_score": 0.011433361115787456,
                    "weighted_ngram_match_score": 0.012021577610863726,
                    "syntax_match_score": 0.5833333333333334,
                    "dataflow_match_score": 0.16666666666666666
                },
                "codebertscore": {
                    "precision": 0.7745345830917358,
                    "recall": 0.8000187873840332,
                    "F1": 0.7870704531669617,
                    "F3": 0.7973951697349548
                },
                "codebertscore_rescaled": {
                    "precision": 0.5490691661834717,
                    "recall": 0.6000375747680664,
                    "F1": 0.5741409063339233,
                    "F3": 0.5947903394699097
                }
            },
            {
                "ind": 29,
                "gen_code": "```python\n# Setup the SIA service\nservice_url = \"https://datalab.noirlab.edu/sia\"\nsia_service = sia.SIAService(service_url)\n\n# Function to plot image cutouts\ndef plot_cutouts(ra, dec, size=60):\n    fig, ax = plt.subplots(1, len(ra), figsize=(len(ra)*3, 3))\n    for i, (r, d) in enumerate(zip(ra, dec)):\n        pos = sia.SkyCoord(ra=r, dec=d, frame='icrs', unit='deg')\n        result_table = sia_service.search(pos, size, verbosity=2)\n        image_url = result_table['url'][0]\n        image_data = download_file(image_url)\n        image = fits.getdata(image_data)\n        ax[i].imshow(image, cmap='gray')\n        ax[i].set_title(f'RA={r:.2f}, Dec={d:.2f}')\n    plt.show()\n\n# Retrieve and plot image cutouts around the peaks\nplot_cutouts(tbl['ra'], tbl['dec'])\n```\n\n<MARKDOWN>\n# CM diagrams of all stars around the peaks\nTo further analyze the properties of the identified overdensity peaks, we should create color-magnitude (CM) diagrams for all stars within a certain radius around these peaks. This will help us understand the stellar populations associated with these potential ultrafaint dwarf galaxy candidates. We'll start by defining a function to create CM diagrams using the `matplotlib` library, and then apply this function to the data surrounding each peak.\n<CELL END>\n\n```python\n# Function to create CM diagrams\ndef plot_cm_diagram(ra, dec, radius=0.1):\n    mask = (R['ra'] - ra)**2 + (R['dec'] - dec)**2 < radius**2\n    stars = R[mask]\n    plt.scatter(stars['mag_auto_g'] - stars['mag_auto_r'], stars['mag_auto_g'])\n    plt.xlabel('g-r')\n    plt.ylabel('g')\n    plt.title(f'CM Diagram around RA={ra:.2f}, Dec={dec:.2f}')\n    plt.show()\n\n# Create CM diagrams for all stars around the peaks\nfor r, d in zip(tbl['ra'], tbl['dec']):\n    plot_cm_diagram(r, d)\n```\n\n<MARKDOWN>\n# Save your results to a local file\nFinally, we should save our results to a local file for future reference and further analysis. We'll use",
                "true_code": "# set up SIA and image table\nDEF_ACCESS_URL = \"https://datalab.noirlab.edu/sia/nsa\"\nsvc_nsa = sia.SIAService(DEF_ACCESS_URL)\nra = 189.58\ndec = -40.89\nfov = 0.1\n\nimgTable = svc_nsa.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n   \n# multi panel image plotter\ndef plot_images(images,geo=None,panelsize=5,titles=list('gri'),cmap=plt.cm.gray_r):\n    if geo is None:\n        geo = (len(images),1)  # ncols, nrows\n        \n    fig = plt.figure(figsize=(geo[0]*panelsize,geo[1]*panelsize))\n    for j,img in enumerate(images):\n        ax = fig.add_subplot(geo[1],geo[0],j+1)\n        ax.imshow(img,origin='lower',interpolation='none',cmap=cmap,norm=plt.mpl.colors.PowerNorm(0.1))\n        ax.set_title('{:s}'.format(titles[j]))\n        plt.axis('off')",
                "error_ind": 29,
                "direct_match": false,
                "fuzzy_match": 6,
                "codebleu": {
                    "codebleu": 0.21099806383909137,
                    "ngram_match_score": 0.0028640170067452523,
                    "weighted_ngram_match_score": 0.012575225136600511,
                    "syntax_match_score": 0.34579439252336447,
                    "dataflow_match_score": 0.4827586206896552
                },
                "codebertscore": {
                    "precision": 0.715796172618866,
                    "recall": 0.7644227743148804,
                    "F1": 0.7393107414245605,
                    "F3": 0.7592648863792419
                },
                "codebertscore_rescaled": {
                    "precision": 0.43159234523773193,
                    "recall": 0.5288455486297607,
                    "F1": 0.4786214828491211,
                    "F3": 0.5185297727584839
                }
            },
            {
                "ind": 31,
                "gen_code": "# Get images for the white box\nfor i in range(len(tbl)):\n    ra = tbl['ra'][i]\n    dec = tbl['dec'][i]\n    fov = 0.1\n    imgTable = svc_nsa.search((ra,dec), (fov/np.cos(dec*np.pi/180), fov), verbosity=2).to_table()\n    images = []\n    for band in ['g', 'r', 'i']:\n        img = fits.getdata(download_file(imgTable[imgTable['band'] == band]['url'][0], cache=True))\n        images.append(img)\n    plot_images(images, geo=(1,3), titles=['g', 'r', 'i'], cmap=plt.cm.gray_r)\n    plt.show()",
                "true_code": "#There is an astrometric offset in the false-color image, so these constants are used to move the images around\n#Right now we have it set so that the g and i images are moved 8 pixels to the left\na=0\nb=8",
                "error_ind": 31,
                "direct_match": false,
                "fuzzy_match": 2,
                "codebleu": {
                    "codebleu": 0.2532289012063292,
                    "ngram_match_score": 0.005599757876912195,
                    "weighted_ngram_match_score": 0.007315846948404604,
                    "syntax_match_score": 0.0,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.6314529776573181,
                    "recall": 0.6648415923118591,
                    "F1": 0.647717297077179,
                    "F3": 0.6613446474075317
                },
                "codebertscore_rescaled": {
                    "precision": 0.26290595531463623,
                    "recall": 0.32968318462371826,
                    "F1": 0.2954345941543579,
                    "F3": 0.3226892948150635
                }
            },
            {
                "ind": 33,
                "gen_code": "# Retrieve and plot the g-band image\ng_img_url = imgTable['get_image'][0]\ng_img_file = download_file(g_img_url, cache=True)\ng_img_data = fits.getdata(g_img_file)\ng_img_data = g_img_data[200:600, 200:600]  # Adjust dimensions\ng_img_data = g_img_data / (imgTable['exposure'][0] * 10**(-0.4*imgTable['zeropoint'][0]))  # Normalize\n\n# Retrieve and plot the r-band image\nr_img_url = imgTable['get_image'][1]\nr_img_file = download_file(r_img_url, cache=True)\nr_img_data = fits.getdata(r_img_file)\nr_img_data = r_img_data[200:600, 200:600]  # Adjust dimensions\nr_img_data = r_img_data / (imgTable['exposure'][1] * 10**(-0.4*imgTable['zeropoint'][1]))  # Normalize\n\n# Retrieve and plot the i-band image\ni_img_url = imgTable['get_image'][2]\ni_img_file = download_file(i_img_url, cache=True)\ni_img_data = fits.getdata(i_img_file)\ni_img_data = i_img_data[200:600, 200:600]  # Adjust dimensions\n# Approximate exposure time and zeropoint for i-band if necessary\ni_img_data = i_img_data / (imgTable['exposure'][2] * 10**(-0.4*imgTable['zeropoint'][2]))  # Normalize\n\n# Plot the images\nimages = [g_img_data, r_img_data, i_img_data]\nplot_images(images, geo=(1,3), titles=['g', 'r', 'i'], cmap=plt.cm.gray_r)",
                "true_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='311551') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'g'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni1 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage1 = i1[0:1362, b:1233]\n#Normalization\n#image1 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=85, expnum=188187, ccdnum=16\nzp=31.514652\nimage1 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]",
                "error_ind": 33,
                "direct_match": false,
                "fuzzy_match": 5,
                "codebleu": {
                    "codebleu": 0.15990326327143836,
                    "ngram_match_score": 0.002701950025131376,
                    "weighted_ngram_match_score": 0.0052964490579083525,
                    "syntax_match_score": 0.3181818181818182,
                    "dataflow_match_score": 0.31343283582089554
                },
                "codebertscore": {
                    "precision": 0.7428120970726013,
                    "recall": 0.7129495143890381,
                    "F1": 0.7275744676589966,
                    "F3": 0.7158273458480835
                },
                "codebertscore_rescaled": {
                    "precision": 0.48562419414520264,
                    "recall": 0.42589902877807617,
                    "F1": 0.45514893531799316,
                    "F3": 0.431654691696167
                }
            },
            {
                "ind": 35,
                "gen_code": "```python\n# r-band image\nsel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='311551') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'r'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni2 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage2 = i2[0:1362, b:1233]\n#Normalization\n#image2 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=85, expnum=188187, ccdnum=16\nzp=31.514652\nimage2 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]\n```\n\n<MARKDOWN>\nLastly, plot the i-band image. Ensure the image is accessed, opened, and normalized correctly, and make any necessary adjustments to the dimensions to maintain spatial alignment with the other band images.\n<CELL END>\n\n```python\n# i-band image\nsel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='311551') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'i'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni3 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage3 = i3[0:1362, b:1233]\n#Normalization\n#image3 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=85, expnum=188187, ccdnum=16\nzp=",
                "true_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='313152') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'r')) \n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni2 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage2 = i2[0:1362, 0:1233-b]\n#Normalization\n#image2 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=85, expnum=188186, ccdnum=16\nzp=31.66765\nimage2 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]",
                "error_ind": 35,
                "direct_match": false,
                "fuzzy_match": 59,
                "codebleu": {
                    "codebleu": 0.6389130613639313,
                    "ngram_match_score": 0.31852318316012884,
                    "weighted_ngram_match_score": 0.8486624396914988,
                    "syntax_match_score": 0.9325842696629213,
                    "dataflow_match_score": 0.45588235294117646
                },
                "codebertscore": {
                    "precision": 0.9024745225906372,
                    "recall": 0.964397132396698,
                    "F1": 0.9324089288711548,
                    "F3": 0.9578250050544739
                },
                "codebertscore_rescaled": {
                    "precision": 0.8049490451812744,
                    "recall": 0.928794264793396,
                    "F1": 0.8648178577423096,
                    "F3": 0.9156500101089478
                }
            },
            {
                "ind": 37,
                "gen_code": "# Plot the i-band image\nsel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='314784') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'i'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni3 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage3 = i3[0:1362, b:1233]\n#Normalization\n#image3 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=85, expnum=188185, ccdnum=16\nzp=31.833\nimage3 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]\n\n# Plot the images\nimages = [image1, image2, image3]\nplot_images(images, geo=(1,3), titles=['g', 'r', 'i'])",
                "true_code": "sel = (imgTable['proctype'].astype(str)=='InstCal') & (imgTable['prodtype'].astype(str)=='image') & (imgTable['access_estsize'].astype(str)=='307960') & \\\n    (startswith(imgTable['obs_bandpass'].astype(str),'i'))\n#print(imgTable[sel][0])\n\nrow = imgTable[sel][0]\nurl = row['access_url'] # get the download URL\nfilename = download_file(url,cache=True,show_progress=False,timeout=120)\nhdu = fits.open(filename)[0]\ni3 = hdu.data\nhdr = hdu.header\nwcs = WCS(hdr)\n#Dimensions of each image need to be equal\nimage3 = i3[0:1362, b:1233]\n#Normalization\n#image3 *= (10.0**(0.4*(30.0 - zpt)))/exptime\n#from header, exptime=20, expnum=294524, ccdnum=60\n#Note: the expnum and ccdnum for the i image did not produce a zeropoint, \n#so we estimated a zeropoint of 31.0, which worked well to produce a proper false-color image.\nzp=31.0\nimage3 *= (10.0**(0.4*(30.0-zp)))/hdr[\"EXPTIME\"]",
                "error_ind": 37,
                "direct_match": false,
                "fuzzy_match": 79,
                "codebleu": {
                    "codebleu": 0.7896038507863032,
                    "ngram_match_score": 0.5919466402380149,
                    "weighted_ngram_match_score": 0.5778323992708344,
                    "syntax_match_score": 0.9886363636363636,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9449113607406616,
                    "recall": 0.9262708425521851,
                    "F1": 0.9354982376098633,
                    "F3": 0.9281018376350403
                },
                "codebertscore_rescaled": {
                    "precision": 0.8898227214813232,
                    "recall": 0.8525416851043701,
                    "F1": 0.8709964752197266,
                    "F3": 0.8562036752700806
                }
            },
            {
                "ind": 39,
                "gen_code": "# Create a false-color 3-band image\n# Subtract the median from each image for optimal scaling\nimage1 -= np.median(image1)\nimage2 -= np.median(image2)\nimage3 -= np.median(image3)\n\n# Create the false-color image\nrgb = make_lupton_rgb(image1, image2, image3, Q=10, stretch=0.5)\n\n# Plot the false-color image alongside the individual bands\nfig, ax = plt.subplots(1, 4, figsize=(20, 5))\nax[0].imshow(image1, cmap='gray_r')\nax[0].set_title('g-band')\nax[1].imshow(image2, cmap='gray_r')\nax[1].set_title('r-band')\nax[2].imshow(image3, cmap='gray_r')\nax[2].set_title('i-band')\nax[3].imshow(rgb)\nax[3].set_title('False-color')\nplt.show()\n\nPlease note that the provided code snippet is a direct continuation of the previous code blocks, specifically the ones related to image processing and plotting.",
                "true_code": "bands = list('gri')\nimages=[image1, image2, image3]\nimages = [im-np.median(im) for im in images] # subtract median from all images for better scaling\nimages += [make_lupton_rgb(*images[::-1],stretch=1)] # add a 3-color composite image\nplot_images(images,geo=(4,1),titles=bands+['False-color 3-band image'])",
                "error_ind": 39,
                "direct_match": false,
                "fuzzy_match": 4,
                "codebleu": {
                    "codebleu": 0.18256418879273462,
                    "ngram_match_score": 0.006785427707752319,
                    "weighted_ngram_match_score": 0.018925872917731606,
                    "syntax_match_score": 0.25,
                    "dataflow_match_score": 0.45454545454545453
                },
                "codebertscore": {
                    "precision": 0.7405297756195068,
                    "recall": 0.8114163279533386,
                    "F1": 0.774354100227356,
                    "F3": 0.8037227392196655
                },
                "codebertscore_rescaled": {
                    "precision": 0.48105955123901367,
                    "recall": 0.6228326559066772,
                    "F1": 0.5487082004547119,
                    "F3": 0.607445478439331
                }
            },
            {
                "ind": 41,
                "gen_code": "def peak_query(ra, dec):\n    query = \"\"\"\n    SELECT ra, dec, mag_auto_g, mag_auto_r, mag_auto_i\n    FROM delve_dr2.objects\n    WHERE q3c_radial_query(ra, dec, {:.2f}, {:.2f}, 0.0833333)\n    \"\"\".format(ra, dec)\n    return query\n\nThis function takes the RA and Dec of a peak as input and returns a SQL query string that targets stars within a 5 arcmin radius of that peak. The query retrieves the RA, Dec, and photometric data in the g, r, and i bands for these stars.",
                "true_code": "def makequery(ra0,dec0,radius0):\n    query_template = \"\"\"\nSELECT ra,dec,mag_auto_g,mag_auto_r,mag_auto_i FROM delve_dr2.objects\n  WHERE q3c_radial_query(ra, dec, {0}, {1}, {2})\n    AND mag_auto_g BETWEEN 14 AND 25\"\"\" \n    query = query_template.format(ra0,dec0,radius0)\n    \n    return query",
                "error_ind": 41,
                "direct_match": false,
                "fuzzy_match": 30,
                "codebleu": {
                    "codebleu": 0.32099747335519835,
                    "ngram_match_score": 0.07468025823787741,
                    "weighted_ngram_match_score": 0.2285404044136852,
                    "syntax_match_score": 0.23076923076923078,
                    "dataflow_match_score": 0.75
                },
                "codebertscore": {
                    "precision": 0.7739340662956238,
                    "recall": 0.8563579320907593,
                    "F1": 0.8130624294281006,
                    "F3": 0.8473338484764099
                },
                "codebertscore_rescaled": {
                    "precision": 0.5478681325912476,
                    "recall": 0.7127158641815186,
                    "F1": 0.6261248588562012,
                    "F3": 0.6946676969528198
                }
            },
            {
                "ind": 43,
                "gen_code": "# Create the query string\nquery = makequery(tbl['ra'][0],tbl['dec'][0],5)\n\n# Execute the query and load the results into a pandas DataFrame\n%time\nR_peak = qc.query(sql=query,fmt='pandas')\n\n# Display the first few rows\nprint(R_peak.head())",
                "true_code": "query0 = makequery(tbl['ra'][0],tbl['dec'][0], 5./60.) # center ra & dec\nR0 = qc.query(sql=query0,fmt='pandas')\nprint(R0.head()) # a pandas method",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 28,
                "codebleu": {
                    "codebleu": 0.35728626654330686,
                    "ngram_match_score": 0.016789125215525624,
                    "weighted_ngram_match_score": 0.03201406061582137,
                    "syntax_match_score": 0.7692307692307693,
                    "dataflow_match_score": 0.6111111111111112
                },
                "codebertscore": {
                    "precision": 0.8450068831443787,
                    "recall": 0.8925588130950928,
                    "F1": 0.8681321144104004,
                    "F3": 0.8875641226768494
                },
                "codebertscore_rescaled": {
                    "precision": 0.6900137662887573,
                    "recall": 0.7851176261901855,
                    "F1": 0.7362642288208008,
                    "F3": 0.7751282453536987
                }
            },
            {
                "ind": 45,
                "gen_code": "# Compute color\nR0['g-r'] = R0['mag_auto_g'] - R0['mag_auto_r']\nprint(R0.head())",
                "true_code": "R0['g_r'] = R0['mag_auto_g'] - R0['mag_auto_r']\nprint( R0.head())",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 87,
                "codebleu": {
                    "codebleu": 0.6774020516253755,
                    "ngram_match_score": 0.2984745896009823,
                    "weighted_ngram_match_score": 0.41113361690051975,
                    "syntax_match_score": 1.0,
                    "dataflow_match_score": 1.0
                },
                "codebertscore": {
                    "precision": 0.9265420436859131,
                    "recall": 0.9650931358337402,
                    "F1": 0.9454247355461121,
                    "F3": 0.9610942006111145
                },
                "codebertscore_rescaled": {
                    "precision": 0.8530840873718262,
                    "recall": 0.9301862716674805,
                    "F1": 0.8908494710922241,
                    "F3": 0.922188401222229
                }
            },
            {
                "ind": 47,
                "gen_code": "def plot_cmd(ax, x, y, title=None, xlim=None, ylim=None):\n    ax.scatter(x, y, s=5)\n    ax.set_xlabel('g-r')\n    ax.set_ylabel('g')\n    if title is not None:\n        ax.set_title(title)\n    if xlim is not None:\n        ax.set_xlim(xlim)\n    if ylim is not None:\n        ax.set_ylim(ylim)\n\nThis function takes a matplotlib axes object `ax`, x and y data, and optional parameters for title, x-axis limits, and y-axis limits. It creates a scatter plot of the color-magnitude diagram and labels the axes. If a title is provided, it is added to the plot. If x-axis or y-axis limits are provided, they are set for the plot.",
                "true_code": "def plotpanel(axid,x,y,title='',xlim=(-1,2),ylim=(25.2,14)):\n    ax = fig.add_subplot(axid)\n    ax.scatter(x,y,marker='.',s=10, alpha=0.8)\n    ax.set_xlabel(x.name)\n    ax.set_ylabel(y.name)\n    ax.set_xlim(xlim)\n    ax.set_ylim(ylim)\n    ax.set_title(title)",
                "error_ind": 47,
                "direct_match": false,
                "fuzzy_match": 11,
                "codebleu": {
                    "codebleu": 0.30194840364998765,
                    "ngram_match_score": 0.0028743682177043654,
                    "weighted_ngram_match_score": 0.026658376817028855,
                    "syntax_match_score": 0.4782608695652174,
                    "dataflow_match_score": 0.7
                },
                "codebertscore": {
                    "precision": 0.7325212955474854,
                    "recall": 0.8478901982307434,
                    "F1": 0.785994827747345,
                    "F3": 0.834743320941925
                },
                "codebertscore_rescaled": {
                    "precision": 0.4650425910949707,
                    "recall": 0.6957803964614868,
                    "F1": 0.5719896554946899,
                    "F3": 0.6694866418838501
                }
            },
            {
                "ind": 49,
                "gen_code": "fig = plt.figure(figsize=(8,6))\nplotpanel(111,R0['g_r'],R0['mag_auto_g'],title='CMD of stars around peak')\nfig",
                "true_code": "fig = plt.figure(figsize=(12,5.5))\nplotpanel(121,R0['g_r'],R0['mag_auto_g'],'white box, {:d} objects'.format(len(R0)))",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 68,
                "codebleu": {
                    "codebleu": 0.3237921871346103,
                    "ngram_match_score": 0.050712153369465586,
                    "weighted_ngram_match_score": 0.06985342056580097,
                    "syntax_match_score": 0.2857142857142857,
                    "dataflow_match_score": 0.8888888888888888
                },
                "codebertscore": {
                    "precision": 0.8949135541915894,
                    "recall": 0.8966268301010132,
                    "F1": 0.8957693576812744,
                    "F3": 0.8964552879333496
                },
                "codebertscore_rescaled": {
                    "precision": 0.7898271083831787,
                    "recall": 0.7932536602020264,
                    "F1": 0.7915387153625488,
                    "F3": 0.7929105758666992
                }
            },
            {
                "ind": 52,
                "gen_code": "R0.to_csv('centaurus_I_photometry.csv', index=False)",
                "true_code": "outfile = 'cen1.csv'\nR0.to_csv(outfile,index=False)",
                "error_ind": null,
                "direct_match": false,
                "fuzzy_match": 50,
                "codebleu": {
                    "codebleu": 0.3333333333333333,
                    "ngram_match_score": 0,
                    "weighted_ngram_match_score": 0,
                    "syntax_match_score": 0.3333333333333333,
                    "dataflow_match_score": 0.0
                },
                "codebertscore": {
                    "precision": 0.8621319532394409,
                    "recall": 0.8382824659347534,
                    "F1": 0.8500398993492126,
                    "F3": 0.8406078815460205
                },
                "codebertscore_rescaled": {
                    "precision": 0.7242639064788818,
                    "recall": 0.6765649318695068,
                    "F1": 0.7000797986984253,
                    "F3": 0.681215763092041
                }
            }
        ],
        "result_summary": {
            "direct_match": 0.0,
            "fuzzy_match": 30.318181818181817,
            "codebleu": 0.33345925097006535,
            "syntax_match_score": 0.49122877977961826,
            "codebertscore": 0.8123957325111736,
            "codebertscore_rescaled": 0.6247914650223472,
            "code_success": 0.5454545454545454,
            "total_code_cell_count": 22
        }
    }
]
